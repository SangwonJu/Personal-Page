[
  {
    "objectID": "data_analytics/FWA.html",
    "href": "data_analytics/FWA.html",
    "title": "Sangwon Ju's Personal Page",
    "section": "",
    "text": "%%capture\n!pip install nltk\n!pip install konlpy\n%%capture\n!pip install -U pandas-profiling\n%%capture\n!pip install seaborn\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotnine as pn\nfrom plotnine import *\n\n!pip install jsonlines\n\nRequirement already satisfied: jsonlines in /usr/local/lib/python3.7/dist-packages (3.0.0)\nRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.2.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (3.10.0.2)\n\n\nimport requests\nimport json\nimport jsonlines\nimport re\nimport pprint\n%%capture\n!sudo apt-get install -y fonts-nanum\n!sudo fc-cache -fv\n!rm ~/.cache/matplotlib -rf\n\n# jupyter notebook 내 그래프를 바로 그리기 위한 설정\n%matplotlib inline\n\n# unicode minus를 사용하지 않기 위한 설정 (minus 깨짐현상 방지)\nplt.rcParams['axes.unicode_minus'] = False\nplt.rcParams['font.family'] = 'NanumGothic'\n%%capture\n!pip install dfply\nfrom dfply import *\nfrom google.colab import auth\nauth.authenticate_user()\n\nimport gspread\nfrom google.auth import default\ncreds, _ = default()\n\ngc = gspread.authorize(creds)\nfrom IPython.display import Image\n\nImage(filename='/1.png') \n\n\n\n\n\nImage(filename='/2.png') \n\n\n\n\n\nImage(filename='/3.png') \n\n\n\n\n\nImage(filename='/4.png') \n\n\n\n\n\nImage(filename='/5.png') \n\n\n\n\n\nImage(filename='/6.png') \n\n\n\n\n\nImage(filename='/7.png') \n\n\n\n\n\nImage(filename='/8.png') \n\n\n\n\n\nImage(filename='/9.png') \n\n\n\n\n\nImage(filename='/10.png')"
  },
  {
    "objectID": "data_analytics/FWA.html#analysis-1-text-mining-covid-19-이전과-이후-유연근무제에-대한-프레임은-어떻게-형성되어져-있는가",
    "href": "data_analytics/FWA.html#analysis-1-text-mining-covid-19-이전과-이후-유연근무제에-대한-프레임은-어떻게-형성되어져-있는가",
    "title": "Sangwon Ju's Personal Page",
    "section": "03/ Analysis 1 – Text Mining – COVID-19 이전과 이후 유연근무제에 대한 프레임은 어떻게 형성되어져 있는가?",
    "text": "03/ Analysis 1 – Text Mining – COVID-19 이전과 이후 유연근무제에 대한 프레임은 어떻게 형성되어져 있는가?\n유연근무제의 확산이 과연 사람들이 유연근무제에 대해서 가지는 인식을 긍정적으로 변화시켰는가? \nCOVID-19 이후 유연근무제에 대한 프레임 혹은 사회적 인식이 어떠한지 확인하기 위해서 빅카인즈(Big Kinds)를 활용하여 주요 신문들에 올라온 기사들에 대한 텍스트 분석을 진행하고 이를 통해 유의미한 인사이트를 도출 할 수 있는지를 확인해보고자 한다. 기사를 활용하여 전반적인 사회적인 인식을 확인하는데 한계가 존재하나 이후 통계청의 설문조사 데이터와 비교하여 어떤 차이가 존재하는지를 확인해보고자 한다.\n####- 텍스트 마이닝을 활용한 빅데이터 텍스트 분석\n\n기술통계 분석\n1. 빈도표 계산 및 말뭉치 등을 활용한 시각화 단어가 몇번 출현했는 지수(Count)를 기반으로 하여 텍스트를 표현 - BoW: 단어의 순서를 고려하지 않고 단어 출현 빈도에만 집중 - DTM (Document-Term Matrix): 문서단어행렬, 다수의 문서에서 등장하는 단어들의 빈도를 행렬로 표현하는 방식 - TF-IDF (Term Frequency - Inverse Document Frequency): 단어 빈도 - 역 문서 빈도  총 문서 수 대비 적게 등장한 단어가 중요한 단어  특정 문서 안에서 많이 등장한다고 해도 중요도가 올라가지는 않음  > TF: 특정 문서 D에서 특정 단어 T의 등장 횟수  DF: 특정 단어 T가 등장한 문서의 수  IDF: DF에 반비례 하는 수. ln(총문서수/(DF))  TF-IDF: TF * IDF 희귀하면서도 특정 텍스트에서 자주 사용된 단어 (TF)는 그 텍스트에서 중요함 2. 단어간 혹은 기사간 상관관계 - 동시 출현(Co-Occurrence) 단어 분석 문장 혹은 기사에 함께 사용된 단어는 어떤 단어일지 분석하는 것. 단어의 “맥락”을 파악하기 위하여 어떤 단어들이 함께 쓰였는지를 알아야 함. 의미를 가진 단어(명사, 동사, 형용사)등을 추출하여 어떤 단어들이 함께 빈번하게 쓰였는지 분석해보는게 필요함. 3. 연관 규칙 분석 (Association Rules) - 장바구니 분석 Apriori Algorithm(Agrawal et al., 1993): 어떤 단어가 다른 단어들과의 연관규칙을 가지는지를 추출 하는 방식\n\n\n토픽 모델링\n토픽 모델링은 문서와 단어로 구성된 행렬(DTM)을 기반으로 문서에 잠재되어 (Latent)있다고 가정된 토픽의 등장확률을 추정하는 일련의 통계적 텍스트 처리기법을 일컫는다. (Blei, 2014; Blei and Lafferty, 2007;Blei, Ng and Jordan, 2003) DTM을 활용하여 주제-확률 분포, 단어-확률 분포를 구한뒤 잠재 주제를 찾는 LDA나 Singular Value Decomposition을 통해 차원 축소를 하는 방법이 있다.\n\n\nLDA(Latent Dirichlet Allocation): 이 문서에서는 어떤 주제들이 오가고 있을까?  PLSA를 조건부 확률로 확장시킨 기법으로 잠재 주제의 확률적 분포에 대한 PLSA의 한계점을 보완한 모델이다. LDA모델은 무작위로 섞여있는 대량의 문서에서 단어들의 패턴을 추론하여 각 토픽의 특성을 도출하는데 용이하며, 텍스트 데이터의 의미구조를 파악하기에 적합한 방법 중 하나이다.  한 문서는 여러가지 토픽으로 이루어지고, 토픽은 여러 단어를 혼합하여 구성된다.   1개의 토픽은 여러 단어(서로 다른 확률을 가진)로 구성. 1개의 단어는 여러 토픽에서 서로 다른 확률을 가짐.  delta는 문장이 각 토픽에 등장할 확률, beta는 단어가 각 토픽에 등장할 확률\n\nfyi) 디리클레 분포(Dirichlet distribution):  베타분포를 다변량으로 확장한 것으로 다변량 베타분포라고 볼 수 있음. (K가 2일때 베타분포) LDA 토픽 모델링으로 예를 들면, 한 문서에 대한 토픽의 분포는 k개의 토픽의 확률 (\\(p_k\\))로 표현할 수 있음.  문서에서 각 단어에 대한 토픽을 샘플을 할때 이 토픽의 분포는 Multinomial 분포를 가정하게 됨. dirichlet 분포의 샘플링 된 k차원 벡터는 합이 1을 만족하기 때문에, multinomial 분포의 모수(\\(p_k\\))에 사용될 수 있음 -> 분포의 분포를 표현.\n\\[f(x_1, x_2, \\cdots, x_K) = \\frac{1}{\\mathrm{B}(\\boldsymbol\\alpha)} \\prod_{i=1}^K x_i^{\\alpha_i - 1} \\]\n\\[ \\mathrm{B}(\\boldsymbol\\alpha) = \\frac{\\prod_{i=1}^K \\Gamma(\\alpha_i)} {\\Gamma\\bigl(\\sum_{i=1}^K \\alpha_i\\bigr)}\\]\n제한조건: \\[ \\sum_{i=1}^{K} x_i = 1 \\]\nhttps://donghwa-kim.github.io/distributions.html (참고)\n\n자료수집 \n우리나라 COVID-19 최초 발생월인 2020년 2월부터 2021년 12월까지의 ‘유연근무’혹은 ’탄력근무’ 혹은 ’원격근무’를 포함하고 있는 정치부, 사회부 언론기사 제목 11,334건을 한국언론진흥재단(BIGKINDS)에서 수집. (경제부 기사들은 특정기업이 유연근무를 사용하기 시작하였음을 홍보하는 기사들이 많아 제외하였음)\n\na. 데이터 불러오기\nworksheet = gc.open('NewsResult_20200201-20211202 (1)').sheet1\nrows = worksheet.get_all_values()\nbigkinds=pd.DataFrame.from_records(rows)\nbigkinds.columns=bigkinds.iloc[0]\nbigkinds=bigkinds.drop(bigkinds.index[0])\n\nimport pandas_profiling\nbigkinds.profile_report()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb. 기술 통계 분석\n\n시기 별 기사의 수\n\n\nfrom datetime import datetime \nnumber=bigkinds >> group_by(X.일자) >> summarize(count=n(X.일자))\nnumber.head(10)\n\n\n\n\n\n  \n    \n      \n      일자\n      count\n    \n  \n  \n    \n      0\n      20200201\n      1\n    \n    \n      1\n      20200202\n      1\n    \n    \n      2\n      20200203\n      5\n    \n    \n      3\n      20200204\n      8\n    \n    \n      4\n      20200205\n      7\n    \n    \n      5\n      20200206\n      48\n    \n    \n      6\n      20200207\n      15\n    \n    \n      7\n      20200208\n      2\n    \n    \n      8\n      20200209\n      3\n    \n    \n      9\n      20200210\n      3\n    \n  \n\n\n\n\n# list 내포\nkdate = [ datetime.strptime(d, '%Y%m%d') for d in number[\"일자\"] ]\n\nhead(kdate)\nnumber['date'] = kdate\nkdate1 = [datetime.strftime(d, '%Y%m') for d in number[\"date\"] ]\n\nnumber['date1'] = kdate1\nnumber.head(10)\nnumber2=number[number.일자.astype(\"int64\")<20211131] >> select([\"date1\",\"count\"])  >> rename(num=\"count\") >> group_by('date1') >> summarise(num=X.num.sum())\n\nfig=plt.figure(figsize = (10,7))\n\nplt.plot(number[\"date\"], number[\"count\"],color='blue', label=str(\"기사\"))\nplt.title(\"일별 유연근무제 관련 기사 수\",fontsize=20)\nplt.style.use(\"default\")\nplt.rc('font', family='NanumBarunGothic') \n\nplt.legend(fontsize=20)\nplt.xticks(rotation=75,fontsize=10)\nplt.yticks(fontsize=10)\n\nax = fig.add_subplot(1, 1, 1)\nax.set_xlabel(\"일별\", fontsize=\"15\")\nax.set_ylabel(\"기사 건수\", fontsize=\"15\")\nplt.show()\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n  if sys.path[0] == '':\n\n\n\n\n\n\nfig2=plt.figure(figsize = (10,7))\nax = fig2.add_subplot(1, 1, 1)\nax.set_xlabel(\"기사 건수\", fontsize=\"15\")\nax.set_ylabel(\"월별\", fontsize=\"15\")\n\nplt.plot(number2[\"date1\"], number2[\"num\"],color='red', label=str(\"기사\"))\nplt.title(\"월별 유연근무제 관련 기사 수\",fontsize=20)\nplt.style.use(\"default\")\nplt.rc('font', family='NanumBarunGothic') \n\nplt.legend(fontsize=20)\nplt.xticks(rotation=75,fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()\n\n\n\n\n\n텍스트 전처리\n\n\n# 토큰화\narticle=bigkinds >> select(\"제목\") >> rename(title=\"제목\")\nprint(article[\"title\"].head(10))\narticle[\"title\"]=article[\"title\"].astype(str)\narticle.shape #11334개의 기사\n\n1                                     동화약품, 가족친화 기업 재인증\n2               집단감염 취약한 콜센터 찾은 안경덕 고용부 장관 \"방역수칙 준수\" 당부\n3                  환풍기 타고 확산? 전파력 5배 오미크론, 재택치료 빈틈 파고드나\n4                                 [팀장시각]서로 위로하는 코로나 분투기\n5                        새 판 짜는 완성차 노조 MZ세대 품을까 [비즈360]\n6                           “재택치료? 가족들 번갈아가며 확진되란 건가요?”\n7                    5000명대 확진에 자영업자들 “다시 거리두기 격상되나” 한숨\n8                   전면등교 후 인천 학생 자가격리자 5천명 폭등 돌봄공백 '비상'\n9     \"가구를 통해 건강한 세상 만들겠다\" 유해물질 소음 진동 걱정없는 책상 [환경표지 ...\n10               김인호 서울시의회 의장, 코로나 확산세 관련 서울시에 적극 대응 요청\nName: title, dtype: object\n\n\n(11334, 1)\n\n\ndef text_preprocess(text):\n    \"\"\"\n    텍스트 전처리\n    1. span tag 삭재\n    2. br tag 삭제\n    3. 영어, 한글, 숫자, 온점 제외 삭제\n    4. 온점을 구분으로 문장 구분\n    \"\"\"\n    text = re.sub(\"(<span class='quot[0-9]'>|</span>|<br/>|<br />|([^0-9가-힣A-Za-z. ]))\",\"\",text)\n    return [sen.strip() for sen in text.split('.') if sen.strip()]\ndf = pd.DataFrame(index=np.arange(1,article.shape[0]+1), columns=['title'])\n# 정규표현식으로 불필요한 부분 제거\nfor i in np.arange(1,article.shape[0]+1):\n  df[\"title\"][i]=text_preprocess(article[\"title\"][i])\n\ndf\n\n\n\n\n\n  \n    \n      \n      title\n    \n  \n  \n    \n      1\n      [동화약품 가족친화 기업 재인증]\n    \n    \n      2\n      [집단감염 취약한 콜센터 찾은 안경덕 고용부 장관 방역수칙 준수 당부]\n    \n    \n      3\n      [환풍기 타고 확산 전파력 5배 오미크론 재택치료 빈틈 파고드나]\n    \n    \n      4\n      [팀장시각서로 위로하는 코로나 분투기]\n    \n    \n      5\n      [새 판 짜는 완성차 노조 MZ세대 품을까 비즈360]\n    \n    \n      ...\n      ...\n    \n    \n      11330\n      [정부 신종코로나 사망자 치사율 축소 논란 글로벌 대유행 가능성도]\n    \n    \n      11331\n      [신종코로나 확산 사태로 가장 먼저 재택근무 시행하는 업계는]\n    \n    \n      11332\n      [지옥철서 신종코로나 옮길라 문지방 출퇴근 지시한 제약회사]\n    \n    \n      11333\n      [여주시 신종 코로나 선제적 대응위해 보건소 선별진료소 운영]\n    \n    \n      11334\n      [태안군 6번 확진자 접촉 관내 2인 음성 판정]\n    \n  \n\n11334 rows × 1 columns\n\n\n\nsentence_arr = []\nfor i in np.arange(1,article.shape[0]):\n    text=df.title[i][0] \n    sentence_arr.insert(0,text)\n\npprint.pprint(sentence_arr[1:10])\n\n['지옥철서 신종코로나 옮길라 문지방 출퇴근 지시한 제약회사',\n '신종코로나 확산 사태로 가장 먼저 재택근무 시행하는 업계는',\n '정부 신종코로나 사망자 치사율 축소 논란 글로벌 대유행 가능성도',\n '경찰인재개발원 필수 인력만 남고 근무 장소 변경 허용',\n '격리 시설 직원들 하소연 유치원서 자녀 보내지 말라네요',\n '오늘은 이런 경향2월4일 재탕 후퇴 미흡  20대 총선보다 부실한 주거공약',\n '신종 코로나 16번째 확진자 발생 태국 여행한 42세 한국인 여성',\n '신종 코로나 확진 1명 추가 태국 여행 뒤 증상 발현',\n '우한 폐렴 비상오락가락하는 정부 기준 자가격리도 잇단 혼선']\n\n\ncheck = ['탄력', '재택', '유연']\nmatching1 = [s for s in sentence_arr if \"유연\" in s] \nmatching2 = [s for s in sentence_arr if \"재택\" in s] \nmatching3 = [s for s in sentence_arr if \"탄력\" in s] \nmatching =matching1 + matching2 + matching3 \nmatching=list(set(matching))\n\nprint(len(matching))\ntype(matching)\n# 1226개의 기사 제목\n\n1226\n\n\nlist\n\n\n한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소(morpheme) 단위로 형태소 토큰화(morpheme tokenization)를 수행하게 됨을 뜻한다. 여기선 이 중에서 Okt와 꼬꼬마를 통해서 토큰화를 수행한다.  참고: https://wikidocs.net/21698\nfrom konlpy.tag import *\nkkma = Kkma()  \nokt = Okt()  \n\nOKT\n\nokt_list=[]\nfor title in matching:\n  tokenized3=okt.pos(title)\n  okt_list.insert(len(okt_list)+1,tokenized3)\n\nokt_list[:3]\n\n[[('코로나', 'Noun'),\n  ('19', 'Number'),\n  ('우려', 'Noun'),\n  ('에', 'Josa'),\n  ('유엔', 'Noun'),\n  ('본부', 'Noun'),\n  ('직원', 'Noun'),\n  ('3000', 'Number'),\n  ('명', 'Noun'),\n  ('3', 'Number'),\n  ('주간', 'Noun'),\n  ('재택근무', 'Noun'),\n  ('돌입', 'Noun')],\n [('재택근무', 'Noun'),\n  ('중', 'Noun'),\n  ('아이', 'Noun'),\n  ('도', 'Josa'),\n  ('보육', 'Noun'),\n  ('하', 'Suffix'),\n  ('라', 'Josa'),\n  ('고요', 'Noun'),\n  ('긴급', 'Noun'),\n  ('보육', 'Noun'),\n  ('청원', 'Noun'),\n  ('갑론', 'Noun'),\n  ('을', 'Josa'),\n  ('박', 'Noun')],\n [('KBS', 'Alpha'),\n  ('본관', 'Noun'),\n  ('3', 'Number'),\n  ('층', 'Noun'),\n  ('직원', 'Noun'),\n  ('1', 'Number'),\n  ('명', 'Noun'),\n  ('확진', 'Noun'),\n  ('필수', 'Noun'),\n  ('인력', 'Noun'),\n  ('제외', 'Noun'),\n  ('재택근무', 'Noun')]]\n\n\nokt_morphs_list=[]\nfor title in matching:\n  tokenized4=okt.morphs(title)\n  okt_morphs_list.insert(len(okt_morphs_list)+1,tokenized4)\n\nokt_morphs_list[:3]\n\n[['코로나',\n  '19',\n  '우려',\n  '에',\n  '유엔',\n  '본부',\n  '직원',\n  '3000',\n  '명',\n  '3',\n  '주간',\n  '재택근무',\n  '돌입'],\n ['재택근무',\n  '중',\n  '아이',\n  '도',\n  '보육',\n  '하',\n  '라',\n  '고요',\n  '긴급',\n  '보육',\n  '청원',\n  '갑론',\n  '을',\n  '박'],\n ['KBS', '본관', '3', '층', '직원', '1', '명', '확진', '필수', '인력', '제외', '재택근무']]\n\n\n\n꼬꼬마\n\nkkma_list=[]\nfor title in matching:\n  tokenized=kkma.pos(title)\n  kkma_list.insert(len(kkma_list)+1,tokenized)\n\nkkma_list[:5]\n\n[[('코로나', 'NNG'),\n  ('19', 'NR'),\n  ('우려', 'NNG'),\n  ('에', 'JKM'),\n  ('유엔', 'NNG'),\n  ('본부', 'NNG'),\n  ('직원', 'NNG'),\n  ('3000', 'NR'),\n  ('명', 'NNM'),\n  ('3', 'NR'),\n  ('주간', 'NNG'),\n  ('재택근무', 'NNG'),\n  ('돌입', 'NNG')],\n [('재택근무', 'NNG'),\n  ('중', 'NNB'),\n  ('아이', 'NNG'),\n  ('도', 'JX'),\n  ('보육', 'NNG'),\n  ('하', 'XSV'),\n  ('라', 'ECD'),\n  ('고요', 'NNG'),\n  ('긴급', 'NNG'),\n  ('보육', 'NNG'),\n  ('청원', 'NNG'),\n  ('갑론을박', 'NNG')],\n [('KBS', 'OL'),\n  ('본관', 'NNG'),\n  ('3', 'NR'),\n  ('층', 'NNG'),\n  ('직원', 'NNG'),\n  ('1', 'NR'),\n  ('명', 'NNM'),\n  ('확', 'MAG'),\n  ('질', 'VV'),\n  ('ㄴ', 'ETD'),\n  ('필수', 'NNG'),\n  ('인력', 'NNG'),\n  ('제외', 'NNG'),\n  ('재택근무', 'NNG')],\n [('서울', 'NNG'),\n  ('LS', 'OL'),\n  ('용', 'NNG'),\n  ('산', 'NNG'),\n  ('타워', 'NNG'),\n  ('직장인', 'NNG'),\n  ('확', 'MAG'),\n  ('진', 'NNG'),\n  ('판정', 'NNG'),\n  ('임직원', 'NNG'),\n  ('재택근무', 'NNG')],\n [('코로나', 'NNG'),\n  ('시대', 'NNG'),\n  ('재택근무', 'NNG'),\n  ('개인', 'NNG'),\n  ('시간', 'NNG'),\n  ('늘', 'VV'),\n  ('었', 'EPT'),\n  ('지만', 'ECE'),\n  ('일', 'NNG'),\n  ('생활', 'NNG'),\n  ('분리', 'NNG'),\n  ('어렵', 'VV'),\n  ('어', 'ECS')]]\n\n\nkkma_morphs_list=[]\nfor title in matching:\n  tokenized1=kkma.morphs(title)\n  kkma_morphs_list.insert(len(kkma_morphs_list)+1,tokenized1)\n\nkkma_morphs_list[:5]\n\n[['코로나',\n  '19',\n  '우려',\n  '에',\n  '유엔',\n  '본부',\n  '직원',\n  '3000',\n  '명',\n  '3',\n  '주간',\n  '재택근무',\n  '돌입'],\n ['재택근무', '중', '아이', '도', '보육', '하', '라', '고요', '긴급', '보육', '청원', '갑론을박'],\n ['KBS',\n  '본관',\n  '3',\n  '층',\n  '직원',\n  '1',\n  '명',\n  '확',\n  '질',\n  'ㄴ',\n  '필수',\n  '인력',\n  '제외',\n  '재택근무'],\n ['서울', 'LS', '용', '산', '타워', '직장인', '확', '진', '판정', '임직원', '재택근무'],\n ['코로나', '시대', '재택근무', '개인', '시간', '늘', '었', '지만', '일', '생활', '분리', '어렵', '어']]\n\n\n딱히 차이가 없으므로 OKT로만 분석 진행.|\n\n불용어 제거  불용어 리스트: https://www.ranks.nl/stopwords/korean\n\nworksheet2 = gc.open('stopwords').sheet1\nrows2 = worksheet2.get_all_values()\nstopwords=pd.DataFrame.from_records(rows2)\nstopwords=pd.Series.tolist(stopwords[0])\nokt_morphs_list_stop=[]\nfor words in okt_morphs_list:\n  tokenized=[]\n  for word in words:\n    if not word in stopwords:\n      tokenized.insert(len(tokenized)+1,word)\n  okt_morphs_list_stop.insert(len(okt_morphs_list_stop)+1,tokenized)\n\nokt_morphs_list_stop[:5]\n\n[['코로나', '19', '우려', '유엔', '본부', '직원', '3000', '명', '3', '주간', '재택근무', '돌입'],\n ['재택근무', '중', '도', '보육', '라', '고요', '긴급', '보육', '청원', '갑론', '박'],\n ['KBS', '본관', '3', '층', '직원', '1', '명', '확진', '필수', '인력', '제외', '재택근무'],\n ['서울', 'LS', '용산', '타워', '직장인', '확진', '판정', '임', '직원', '재택근무'],\n ['코로나', '시대', '재택근무', '개인', '늘었지만', '생활', '분리', '어려워']]\n\n\nkkma_morphs_list_stop=[]\nfor words in kkma_morphs_list:\n  tokenized=[]\n  for word in words:\n    if not word in stopwords:\n      tokenized.insert(len(tokenized)+1,word)\n  kkma_morphs_list_stop.insert(len(kkma_morphs_list_stop)+1,tokenized)\n\nkkma_morphs_list_stop[:5]\n\n[['코로나', '19', '우려', '유엔', '본부', '직원', '3000', '명', '3', '주간', '재택근무', '돌입'],\n ['재택근무', '중', '도', '보육', '라', '고요', '긴급', '보육', '청원', '갑론을박'],\n ['KBS',\n  '본관',\n  '3',\n  '층',\n  '직원',\n  '1',\n  '명',\n  '확',\n  '질',\n  'ㄴ',\n  '필수',\n  '인력',\n  '제외',\n  '재택근무'],\n ['서울', 'LS', '용', '산', '타워', '직장인', '확', '진', '판정', '임직원', '재택근무'],\n ['코로나', '시대', '재택근무', '개인', '늘', '었', '생활', '분리', '어렵']]\n\n\n\nWord Cloud\n\nfrom wordcloud import WordCloud, STOPWORDS\nimport nltk as nltk\ntotal_okt= []\nfor element in okt_morphs_list_stop:\n  total_okt+=element\ntotal_okt_over2=pd.Series(total_okt)[pd.Series(total_okt).str.len()>=2]\ncount_okt=pd.DataFrame(total_okt).value_counts().rename_axis('unique_values').reset_index(name='counts')\ncount_okt.columns=[\"word\",\"counts\"]\n\ncount_okt2=count_okt >> mask(X.word.str.len() >=2)\ncount_okt2=count_okt2.reset_index().iloc[:,1:]\ncount_okt2.head(60)\n\n\n\n\n\n  \n    \n      \n      word\n      counts\n    \n  \n  \n    \n      0\n      재택근무\n      968\n    \n    \n      1\n      코로나\n      365\n    \n    \n      2\n      19\n      191\n    \n    \n      3\n      재택\n      163\n    \n    \n      4\n      직원\n      148\n    \n    \n      5\n      확산\n      86\n    \n    \n      6\n      근무\n      85\n    \n    \n      7\n      기업\n      83\n    \n    \n      8\n      확진\n      75\n    \n    \n      9\n      출근\n      57\n    \n    \n      10\n      확대\n      53\n    \n    \n      11\n      시행\n      46\n    \n    \n      12\n      진자\n      41\n    \n    \n      13\n      유연근무제\n      41\n    \n    \n      14\n      유연\n      41\n    \n    \n      15\n      직장\n      40\n    \n    \n      16\n      콜센터\n      40\n    \n    \n      17\n      공무원\n      38\n    \n    \n      18\n      연장\n      38\n    \n    \n      19\n      실시\n      34\n    \n    \n      20\n      거리\n      33\n    \n    \n      21\n      감염\n      33\n    \n    \n      22\n      전환\n      33\n    \n    \n      23\n      정부\n      32\n    \n    \n      24\n      포스코\n      32\n    \n    \n      25\n      두기\n      31\n    \n    \n      26\n      공공기관\n      31\n    \n    \n      27\n      권고\n      30\n    \n    \n      28\n      도입\n      30\n    \n    \n      29\n      폐쇄\n      30\n    \n    \n      30\n      직장인\n      29\n    \n    \n      31\n      단계\n      28\n    \n    \n      32\n      회식\n      27\n    \n    \n      33\n      회사\n      27\n    \n    \n      34\n      삼성\n      27\n    \n    \n      35\n      출퇴근\n      27\n    \n    \n      36\n      돌입\n      26\n    \n    \n      37\n      해야\n      26\n    \n    \n      38\n      LG\n      26\n    \n    \n      39\n      사업\n      25\n    \n    \n      40\n      국회\n      25\n    \n    \n      41\n      하는\n      25\n    \n    \n      42\n      서울\n      24\n    \n    \n      43\n      대응\n      23\n    \n    \n      44\n      금지\n      23\n    \n    \n      45\n      비상\n      23\n    \n    \n      46\n      분산\n      22\n    \n    \n      47\n      그룹\n      21\n    \n    \n      48\n      방역\n      20\n    \n    \n      49\n      지원\n      20\n    \n    \n      50\n      에도\n      20\n    \n    \n      51\n      활용\n      20\n    \n    \n      52\n      전원\n      19\n    \n    \n      53\n      강화\n      19\n    \n    \n      54\n      업무\n      19\n    \n    \n      55\n      임산부\n      19\n    \n    \n      56\n      본사\n      19\n    \n    \n      57\n      KT\n      19\n    \n    \n      58\n      신청\n      18\n    \n    \n      59\n      비대\n      18\n    \n  \n\n\n\n\ntotal_okt_over2 # 9467개\ntotal_okt_over3=[]\nfor element in total_okt_over2:\n  if element not in [\"재택근무\",\"유연근무제\",\"19\",\"재택\",\"해야\",\"진자\",\"비대\"]:\n    total_okt_over3.insert(0,element)\n\noktplot=nltk.Text(total_okt_over3,name=\"Test\")\nfig=plt.figure(figsize = (10,5))\nax = fig.add_subplot(1, 1, 1)\nplt.title(\"키워드 빈도별 그래프\",fontsize=20)\noktplot.plot(50)\nplt.show(ax)\n\n\n\n\n\ndata=oktplot.vocab().most_common(50)\nplt.figure(figsize = (10,5))\npath=\"/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\"\nwc=WordCloud(font_path=path,relative_scaling=0.2,background_color=\"white\",width=1200, height=800).generate_from_frequencies(dict(data))\n\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()\n\n\n\n\n\n분석의 문제점  제목기반 분석이라 의미있는 내용을 뽑아낼 수 없었음. 맥락이 제거된 빈도기반 분석으로 어떤 맥락에서 사용되었는지 알수가 없었음. 의미있는 인사이트를 찾을수는 없었으나 공무원, 공공기관, 포스코, LG 등 공공영역이나 대기업 위주로 유연근무제가 시행된다는 사실을 확인할 수 있었음. 콜센터와 같은 밀집된 곳에서 시행하는 업무의 경우, 유연근무제를 통해 감염을 확산을 저지하려는 시도가 있었지 않았나 추측해 보았음.\nTF-IDF\n\nfrom collections import defaultdict\n\nvectorizer = TfidfVectorizer()\ntdm = vectorizer.fit_transform(sentence_arr)\n\nword_count = pd.DataFrame({\n    '단어': vectorizer.get_feature_names(),\n    '빈도': tdm.sum(axis=0).flat\n})\n\n/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n\n\n\nword_count.sort_values(\"빈도\",ascending=False).reset_index(drop=True).head(30)\n\n\n\n\n\n  \n    \n      \n      단어\n      빈도\n    \n  \n  \n    \n      0\n      코로나19\n      248.149943\n    \n    \n      1\n      코로나\n      225.877234\n    \n    \n      2\n      확진\n      189.862035\n    \n    \n      3\n      재택근무\n      166.912066\n    \n    \n      4\n      확진자\n      141.297835\n    \n    \n      5\n      거리두기\n      134.722720\n    \n    \n      6\n      직원\n      116.244045\n    \n    \n      7\n      폐쇄\n      82.505198\n    \n    \n      8\n      수도권\n      79.311515\n    \n    \n      9\n      사회적\n      77.250924\n    \n    \n      10\n      방역\n      64.115543\n    \n    \n      11\n      콜센터\n      63.758580\n    \n    \n      12\n      감염\n      60.624583\n    \n    \n      13\n      발생\n      59.834789\n    \n    \n      14\n      3단계\n      54.067897\n    \n    \n      15\n      정부\n      53.735398\n    \n    \n      16\n      확산\n      51.893703\n    \n    \n      17\n      서울\n      51.615911\n    \n    \n      18\n      비상\n      48.585535\n    \n    \n      19\n      1명\n      47.710836\n    \n    \n      20\n      국회\n      45.337426\n    \n    \n      21\n      백신\n      44.223253\n    \n    \n      22\n      신규\n      43.779173\n    \n    \n      23\n      추가\n      43.749493\n    \n    \n      24\n      집단감염\n      43.617216\n    \n    \n      25\n      검사\n      40.211961\n    \n    \n      26\n      마스크\n      38.943360\n    \n    \n      27\n      음성\n      37.046574\n    \n    \n      28\n      격상\n      35.974340\n    \n    \n      29\n      재택\n      35.499295\n    \n  \n\n\n\n\n\n\nc. 동시 출현(Co-Occurrence) \n참고: https://bab2min.tistory.com/598\n# 2글자 이상의 단어로 한정 / 의미없는 숫자 제거\ncooccur=[]\nfor elements in okt_morphs_list_stop:\n  new_elements=[]\n  for i in elements:\n    if i not in [\"재택근무\",\"유연\"]:\n      text = re.sub(r'[a-zA-Z0-9]',' ',i).strip()\n      if len(text)>=2:\n        new_elements.append(text)\n  cooccur.append(new_elements)\ncount = {}   #동시출현 빈도가 저장될 dict\nfor line in cooccur:\n    words = line \n    for i, a in enumerate(words):\n        for b in words[i+1:]:\n            if a == b: continue   #같은 단어의 경우는 세지 않음\n            if a > b: \n              a, b = b, a   #A, B와 B, A가 다르게 세어지는것을 막기 위해 항상 a < b로 순서 고정\n            count[a, b] = count.get((a, b), 0) + 1   #실제로 센다\ndef dict_to_df(df):\n        data_df = pd.DataFrame({'keys': df.keys(), 'features': df.values()})\n        data_df['word1'] = data_df['keys'].apply(lambda x: x[0])\n        data_df['word2'] = data_df['keys'].apply(lambda x: x[1])\n        return data_df[['word1','word2','features']]\n\ncooccur_df.sort_values(\"features\",ascending=False).head(10)\n\n\n\n\n\n  \n    \n      \n      word1\n      word2\n      features\n    \n  \n  \n    \n      884\n      거리\n      두기\n      89\n    \n    \n      98\n      코로나\n      확산\n      62\n    \n    \n      24\n      직원\n      확진\n      52\n    \n    \n      65\n      근무\n      재택\n      46\n    \n    \n      94\n      근무\n      유연\n      39\n    \n    \n      770\n      직원\n      코로나\n      36\n    \n    \n      174\n      코로나\n      확진\n      34\n    \n    \n      585\n      근무\n      분산\n      32\n    \n    \n      1238\n      건물\n      폐쇄\n      30\n    \n    \n      745\n      감염\n      직원\n      27\n    \n  \n\n\n\n\n\ncooccur_df=dict_to_df(count)\ncooccur_df.features.describe()\n\ncount    9559.000000\nmean        2.456219\nstd         2.635716\nmin         1.000000\n25%         1.000000\n50%         2.000000\n75%         3.000000\nmax        89.000000\nName: features, dtype: float64\n\n\n\n\nd. 네트워크 그래프\nimport networkx as nx\nimport operator\nimport matplotlib.colors as mcolors\nimport matplotlib.cm as cm\ncooccur_df_major=cooccur_df >> mask(X.features>=13)\n\n# generate sample graph\nplt.figure(figsize = (9,9),facecolor='k')\nplt.rcParams['font.sans-serif'] = ['NanumBarunGothic'] \ng = nx.from_pandas_edgelist(cooccur_df_major, 'word1', 'word2')\n\n\n# centrality\ndeg_centrality = nx.degree_centrality(g)\ncentrality = np.fromiter(deg_centrality.values(), float)\n# plot\npos = nx.kamada_kawai_layout(g,scale=3)\nnx.draw(g, pos, node_color=centrality,with_labels=True)\nplt.title(\"유연근무제 기사제목 분석\",size=15)\nplt.cool()\n\n\nsizes = centrality / np.max(centrality) * 200\nnormalize = mcolors.Normalize(vmin=centrality.min(), vmax=centrality.max())\ncolormap = cm.cool\n\nscalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\nscalarmappaple.set_array(centrality)\n\nplt.colorbar(scalarmappaple,shrink=0.3)\n\nplt.show()\n\n\n\n\n\n\n\ndef dict_to_df_1(df):\n        data_df = pd.DataFrame({'keys': df.keys(), 'features': df.values()})\n        data_df['word1'] = data_df['keys']\n        return data_df[['word1','features']]\n\ndict_to_df_1(deg_centrality).sort_values(\"features\",ascending=False)[1:20]\n\n\n\n\n\n  \n    \n      \n      word1\n      features\n    \n  \n  \n    \n      5\n      코로나\n      0.101266\n    \n    \n      10\n      기업\n      0.088608\n    \n    \n      34\n      본사\n      0.075949\n    \n    \n      44\n      경력\n      0.075949\n    \n    \n      6\n      근무\n      0.075949\n    \n    \n      1\n      확진\n      0.050633\n    \n    \n      48\n      금지\n      0.050633\n    \n    \n      57\n      단계\n      0.037975\n    \n    \n      7\n      재택\n      0.037975\n    \n    \n      16\n      시행\n      0.037975\n    \n    \n      36\n      거리\n      0.037975\n    \n    \n      18\n      아기\n      0.037975\n    \n    \n      73\n      국회\n      0.037975\n    \n    \n      33\n      감염\n      0.037975\n    \n    \n      55\n      구로\n      0.025316\n    \n    \n      26\n      전환\n      0.025316\n    \n    \n      66\n      구글\n      0.025316\n    \n    \n      42\n      시차\n      0.025316\n    \n    \n      41\n      폐쇄\n      0.025316\n    \n  \n\n\n\n\n\n\n\n분석 실패 요인 및 느낀점\n\n(진행하더라도 유의미한 분석결과가 나오지 않을 것으로 예상되어) 토픽 모델링은 진행하지 않았음\n빈도기반 텍스트 마이닝 분석은 그러한 단어가 어떤 맥락에서 형성되었는지 알 수 없고 어떠한 의미를 가지는지를 이해하는데 있어서 어려움이 있다.\n신문 기사 제목들이 서로 응집성을 가지지 않고 산발적으로 나타나는 경우가 다수였기 때문에 적절한 분석이 진행되지 못한 것으로 보임.\n이후 보다 의미있는 분석을 위해서는 신문 기사 내용들을 활용을 하거나, 다른 텍스트 원천을 활용하는 것이 보다 효과적인 분석에 있어서 필요할 것으로 보임."
  },
  {
    "objectID": "data_analytics/FWA.html#analysis-2-descriptive-statistics-유연근무제도가-초기-정책의-목적을-어느정도-수행하고-있는가-공공영역-유연근무제에-대한-인식이-민간영역-근무제에-대한-인식과-큰-차이를-보이는가",
    "href": "data_analytics/FWA.html#analysis-2-descriptive-statistics-유연근무제도가-초기-정책의-목적을-어느정도-수행하고-있는가-공공영역-유연근무제에-대한-인식이-민간영역-근무제에-대한-인식과-큰-차이를-보이는가",
    "title": "Sangwon Ju's Personal Page",
    "section": "03/ Analysis 2 – Descriptive Statistics  유연근무제도가 초기 정책의 목적을 어느정도 수행하고 있는가?  공공영역 유연근무제에 대한 인식이 민간영역 근무제에 대한 인식과 큰 차이를 보이는가?",
    "text": "03/ Analysis 2 – Descriptive Statistics  유연근무제도가 초기 정책의 목적을 어느정도 수행하고 있는가?  공공영역 유연근무제에 대한 인식이 민간영역 근무제에 대한 인식과 큰 차이를 보이는가?\n\n1. 경제활동인구조사 (2015~2021) \n\n\n경제활동인구조사: 통계종류지정통계/조사통계 -계속여부: 계속통계 -작성목적: 국민의 경제활동(취업, 실업, 노동력 등) 특성을 조사함으로써 거시경제 -분석과 인력자원의 개발정책 수립에 필요한 기초 자료를 제공 -작성주기:월  -작성체계: 조사원(면접조사)→지방통계청(사무소)→통계청  -공표범위: 시도 -공표주기: 월 -특이점: 2017년 9월 조사부터 복수응답가능\n\n\nfrom mizani.breaks import date_breaks, minor_breaks\nfrom mizani.formatters import date_format\nimport matplotlib.font_manager as fm\npath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' \nfont = fm.FontProperties(fname=path, size=13)\n\na. 유연근무제 활용여부\nyes=pd.read_json(\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7099S/2/1/20211204112805_1&prdSe=M&startPrdDe=201508&endPrdDe=202108\")\nno=pd.read_json(\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7099S/2/1/20211204112931_1&prdSe=M&startPrdDe=201508&endPrdDe=202108\")\npj_usege=yes >> bind_rows(no, join='outer') >> select(X.PRD_DE,X.C1_NM,X.DT)\npj_usege=pj_usege.reset_index(drop=True)\n\nplt.figure()\npn.options.figure_size = (8,6)\n(ggplot(pj_usege, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(0,22001),breaks= np.arange(0,22001,2000))\n    + geom_line() \n    + geom_point(pj_usege,aes(x='factor(PRD_DE)',y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"참여 여부\")\n    + scale_color_manual(values=(\"blue\",\"red\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=0, nudge_y=1000,size=13,color=\"black\")\n    + ggtitle('임금 근로자 중 유연근무제 참여 인원 수\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697391465)>\n\n\n\n\nb. 성별 유연근무제 활용현황\nlink_list=[]\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7103S/2/1/20211204135633&prdSe=M&startPrdDe=\"\nfor i in range(201508,202109,100):\n  link_list.append(link+str(i))\npj_gender=pd.read_json(link_list[0])\nfor i in link_list[1:]:\n  pj_gender = pj_gender >> bind_rows(pd.read_json(i), join='outer')\npj_gender=pj_gender.reset_index(drop=True)\npj_gender2=pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(~X.C1_NM==\"계\") >>  mask(~X.C2_NM==\"계\")\npj_gender2=pj_gender2.reset_index(drop=True)\npj_total=pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT)  >> mask(~X.C1_NM==\"계\") >> mask(X.C2_NM==\"계\")\n\npj_total\n\n\n\n\n\n  \n    \n      \n      PRD_DE\n      C1_NM\n      C2_NM\n      DT\n    \n  \n  \n    \n      3\n      201508\n      남자\n      계\n      11006.6\n    \n    \n      6\n      201508\n      여자\n      계\n      8467.9\n    \n    \n      12\n      201608\n      남자\n      계\n      11085.6\n    \n    \n      15\n      201608\n      여자\n      계\n      8657.6\n    \n    \n      21\n      201708\n      남자\n      계\n      11188.2\n    \n    \n      24\n      201708\n      여자\n      계\n      8817.9\n    \n    \n      30\n      201808\n      남자\n      계\n      11171.3\n    \n    \n      33\n      201808\n      여자\n      계\n      8873.7\n    \n    \n      39\n      201908\n      남자\n      계\n      11395.7\n    \n    \n      42\n      201908\n      여자\n      계\n      9163.3\n    \n    \n      48\n      202008\n      남자\n      계\n      11361.3\n    \n    \n      51\n      202008\n      여자\n      계\n      9084.6\n    \n    \n      57\n      202108\n      남자\n      계\n      11516.6\n    \n    \n      60\n      202108\n      여자\n      계\n      9475.9\n    \n  \n\n\n\n\n\npj_total2=pj_total >> select(~X.C2_NM) >> spread(X.PRD_DE, X.DT) >> select(~X.C1_NM)\npj_total2.index=[\"남자\",\"여자\"]\npj_total2.transpose() >> mutate(ratio=np.round(X.남자/(X.남자+X.여자),2),배수 =np.round(X.남자/(X.여자),2) )\n# 총 경제활동 인원 대비 남성 비율 / 점차 줄어드는 중 \n\n\n\n\n\n  \n    \n      \n      남자\n      여자\n      ratio\n      배수\n    \n  \n  \n    \n      201508\n      11006.6\n      8467.9\n      0.57\n      1.30\n    \n    \n      201608\n      11085.6\n      8657.6\n      0.56\n      1.28\n    \n    \n      201708\n      11188.2\n      8817.9\n      0.56\n      1.27\n    \n    \n      201808\n      11171.3\n      8873.7\n      0.56\n      1.26\n    \n    \n      201908\n      11395.7\n      9163.3\n      0.55\n      1.24\n    \n    \n      202008\n      11361.3\n      9084.6\n      0.56\n      1.25\n    \n    \n      202108\n      11516.6\n      9475.9\n      0.55\n      1.22\n    \n  \n\n\n\n\n\nplt.figure()\npn.options.figure_size = (8,6)\n(ggplot(pj_total, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(6000,15001),breaks= np.arange(0,22001,2000))\n    + geom_line() \n    + geom_point(pj_total,aes(x='factor(PRD_DE)',y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"성별\")\n    + scale_color_manual(values=(\"blue\",\"red\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=0, nudge_y=500,size=13,color=\"black\")\n    + ggtitle('조사대상 성별 임금 근로자 수\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697419985)>\n\n\n\nplt.figure()\npn.options.figure_size = (14,6)\n(ggplot(pj_gender2, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C2_NM\",color=\"C2_NM\")) \n    + facet_wrap('C1_NM')\n    + scale_y_continuous(limits=(0,14001),breaks= np.arange(0,22001,2000))\n    + geom_line() \n    + geom_point(pj_gender2, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C2_NM\",color=\"C2_NM\"))\n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"참여 여부\")\n    + scale_color_manual(values=(\"blue\",\"red\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=0, nudge_y=1000,size=13,color=\"black\")\n    + ggtitle('임금 근로자 중 성별 유연근무제 참여 인원 수\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697654101)>\n\n\n# 성별 경제활동 참여 인구 대비 유연근무제 참여자 비율 \nratio_total=(pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"계\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,3)*100,ratio_notuse=np.round(X.notused/X.계,3)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_male=(pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"남자\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,3)*100,ratio_notuse=np.round(X.notused/X.계,3)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_female=(pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"여자\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,3)*100,ratio_notuse=np.round(X.notused/X.계,3)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio=pd.concat([ratio_total,ratio_male,ratio_female], keys=[\"전체\",\"남성\",\"여성\"]).reset_index() >> select(~X.level_1) >> rename(성별=\"level_0\") \n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(ratio, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"성별\",color=\"성별\")) \n    + scale_y_continuous(limits=(0,20),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(ratio, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"성별\",color=\"성별\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"성별\")\n    + scale_color_manual(values=(\"#619CFF\",\"#F8766D\",\"gray\"))\n    + geom_text(aes(label=\"ratio_use\"),nudge_x=0, nudge_y=+0.5,size=10,color=\"black\",format_string='{}%')\n    + ggtitle('성별 총 임금근로자 대비 유연근무제 참여 인원 수\\n(자료 출처: 통계청 경제활동인구조사)'))    \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696383501)>\n\n\npj_age_2021=pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.PRD_DE==202108) >> mask(~X.C1_NM==\"계\") >>mask(~X.C2_NM==\"계\")\n# 2021년 기준 유연근무제 참여집단과 비참여집단 비교\npj_2021=pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.PRD_DE==202108) \n\nplt.figure()\npn.options.figure_size = (10,6)\ndodge_text = position_dodge(width=0.9)\n(ggplot(pj_2021,aes(x='C1_NM',y=\"DT\",fill=\"C1_NM\",group=\"C1_NM\")) \n    + scale_y_continuous(limits=(0,22000),breaks= np.arange(0,22001,2000))\n    + geom_bar(stat='identity',position = position_dodge(width = 0.9)) \n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"유형 별\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(fill=\"성별\")\n    + facet_wrap('C2_NM')\n    + scale_fill_manual(values=(\"gray\",\"#619CFF\",\"#F8766D\"))\n    + geom_text(aes(label='DT'), position=dodge_text,size=10, va='bottom', format_string='{}')\n    + ggtitle('임금 근로자 중 성별 유연근무제 참여 인원 수 (2021)\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697263013)>\n\n\n\n\nc. 연령 별 유연근무제 사용 유형\nlink_list=[]\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7105S/2/1/20211204160618&prdSe=M&startPrdDe=\"\nfor i in range(201508,202109,100):\n  link_list.append(link+str(i))\npj_age=pd.read_json(link_list[0])\nfor i in link_list[1:]:\n  pj_age = pj_age >> bind_rows(pd.read_json(i), join='outer')\nratio_age_total=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"계\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_15=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"15 - 29세\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_30=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"30 - 39세\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_40=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"40 - 49세\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_50=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"50 - 59세\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_60=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"60세이상\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age=pd.concat([ratio_age_total,ratio_age_15,ratio_age_30,ratio_age_40,ratio_age_50,ratio_age_60], keys=[\"전체\",\"15 - 29세\",\"30 - 39세\",\"40 - 49세\",\"50 - 59세\",\"60세이상\"]).reset_index() >> select(~X.level_1) >> rename(연령별=\"level_0\") \nratio_age[\"ratio_use\"]=np.round(ratio_age[\"ratio_use\"].astype(np.float64),2)\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(ratio_age, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"연령별\",color=\"연령별\")) \n    + scale_y_continuous(limits=(0,25),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(ratio_age, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"연령별\",color=\"연령별\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"연령 별\")\n    + geom_text(aes(label=\"ratio_use\"),nudge_x=0, nudge_y=+0.8,size=8,color=\"black\",format_string='{}%')\n    + ggtitle('연령별 총 임금근로자 대비 유연근무제 참여 인원 비율\\n(자료 출처: 통계청 경제활동인구조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8731672718093)>\n\n\npj_age_2021=pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.PRD_DE==202108) >> mask(~X.C1_NM==\"계\") >>mask(~X.C2_NM==\"계\")\n\nplt.figure()\npn.options.figure_size = (12,6)\ndodge_text = position_dodge(width=0.9)\n(ggplot(pj_age_2021,aes(x='C1_NM',y=\"DT\",fill=\"C1_NM\",group=\"C1_NM\")) \n    + scale_y_continuous(limits=(0,6000),breaks= np.arange(0,22001,2000))\n    + geom_bar(stat='identity',position = position_dodge(width = 0.9)) \n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"유형 별\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(fill=\"연령별\")\n    + facet_wrap('C2_NM')\n    + geom_text(aes(label='DT'), position=dodge_text,size=10, va='bottom', format_string='{}') \n    + scale_fill_manual(values=(\"#4a4e4d\",\"#0e9aa7\" ,\"orange\",\"#f6cd61\",\"#f9caa7\"))\n    + ggtitle('임금 근로자 중 연령별 유연근무제 참여 인원 수 (2021)\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696667145)>\n\n\n\n\nd. 혼인상태별 유연근무제 활용현황\nlink_marriage_list=[]\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7104S/2/1/20211204164055&prdSe=M&startPrdDe=\"\nfor i in range(201508,202109,100):\n  link_marriage_list.append(link+str(i))\npj_marriage=pd.read_json(link_marriage_list[0])\nfor i in link_marriage_list[1:]:\n  pj_marriage = pj_marriage >> bind_rows(pd.read_json(i), join='outer')\nratio_marriage_total=(pj_marriage >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"계\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_marriage_no=(pj_marriage >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"미혼\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_marriage_yes=(pj_marriage >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"기혼\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_marriage=pd.concat([ratio_marriage_total,ratio_marriage_yes,ratio_marriage_no], keys=[\"전체\",\"기혼\",\"미혼\"]).reset_index() >> select(~X.level_1) >> rename(결혼=\"level_0\") \nratio_marriage[\"ratio_use\"]=np.round(ratio_marriage[\"ratio_use\"].astype(np.float64),2)\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(ratio_marriage, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"결혼\",color=\"결혼\")) \n    + scale_y_continuous(limits=(0,18),breaks= np.arange(0,101,3))\n    + geom_line() \n    + geom_point(ratio_marriage, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"결혼\",color=\"결혼\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"혼인 여부\")\n    + scale_color_manual(values=(\"#619CFF\",\"#F8766D\",\"gray\"))\n    + annotate(\"text\", x=6.5, y=17.91, label=\"17.91%\", size=12,color=\"black\")\n    + annotate(\"text\", x=6.5, y=16.93, label=\"16.93%\", size=12,color=\"black\")\n    + annotate(\"text\", x=6.5, y=16, label=\"16.35%\", size=12,color=\"black\")\n    + ggtitle('혼인 유형 별 임금근로자 대비 유연근무제 참여 인원 수\\n(자료 출처: 통계청 경제활동인구조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696204773)>\n\n\npj_marriage_2021=pj_marriage >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.PRD_DE==202108) >> mask(~X.C1_NM==\"계\")\n\nplt.figure()\npn.options.figure_size = (10,6)\ndodge_text = position_dodge(width=0.9)\n(ggplot(pj_marriage_2021,aes(x='C1_NM',y=\"DT\",fill=\"C1_NM\",group=\"C1_NM\")) \n    + scale_y_continuous(limits=(0,15000),breaks= np.arange(0,22001,2000))\n    + geom_bar(stat='identity',position = position_dodge(width = 0.9)) \n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"유형 별\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(fill=\"연령별\")\n    + facet_wrap('C2_NM')\n    + geom_text(aes(label='DT'), position=dodge_text,size=10, va='bottom', format_string='{}')\n    + scale_fill_manual(values=(\"#619CFF\",\"#F8766D\"))\n    + ggtitle('임금 근로자 중 성별 유연근무제 참여 인원 수 (2021)\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696952981)>\n\n\n\n\ne. 유연근무제 활용형태(복수응답)\nlink_type_list=[]\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7100S/2/1/20211204170759&prdSe=M&startPrdDe=\"\nfor i in range(201508,202109,100):\n  link_type_list.append(link+str(i))\npj_type=pd.read_json(link_type_list[0])\nfor i in link_type_list[1:]:\n  pj_type = pj_type >> bind_rows(pd.read_json(i), join='outer')\nratio_type=pj_type >> mask(X.ITM_NM_ENG==\"ratio\") >> select(X.PRD_DE,X.C1_NM,X.DT)\nratio_type['C1_NM']=pd.Categorical(ratio_type['C1_NM'], ordered=True,categories=['근로시간단축근무제','시차출퇴근제','선택적 근무시간제','재택 및 원격근무제','탄력적 근무제','기타유형(재량근무 등)'])\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(ratio_type,aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + geom_line() \n    + scale_y_continuous(limits=(-1,50),breaks= np.arange(0,101,10))\n    + geom_point(ratio_type, aes(x='factor(PRD_DE)', y=\"DT\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"유연근무 유형\")\n    + scale_color_manual(values=(\"#4a4e4d\",\"#0e9aa7\" ,\"#f9caa7\",\"red\",\"#f6cd61\",\"green\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=0, nudge_y=+1,size=8,color=\"black\",format_string='{}%')\n    + geom_vline(xintercept=5+(4/12),linetype=\"dashed\")\n    + ggtitle('유연근무제 참여 유형별 비율\\n(자료 출처: 통계청 경제활동인구조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696647101)>\n\n\n\n\n유연근무제의 사용 현황 정리 (통계청 경제활동인구조사)\n\nCOVID-19과 상관 없이 인식 개선으로 유연근무제 사용 인원 수는 지속적으로 증가하여 왔음.\n예상했던 것 과는 달리 남성들이 유연근무제를 사용하는 비율이 여성이 사용하는 비율보다 높았음. (2021년 8월 기준 남성이 18.2%, 여성이 15.2%)\n유연근무제를 가장 많이 사용하는 계층은 30대 였으며 그 다음으로 40대 20대 50대 순이다. 60세 이상 집단의 경우 거의 사용하지 않았는데 50대 이상 집단과 비교하였을 때 큰 차이가 나타나고 있는 것을 확인할 수 있다.\nCOVID-19 이전까지 기혼집단이 유연근무제를 많이 사용하였으나, 이후로는 미혼집단이 오히려 더 많이 사용하고 있는 것으로 보인다.(2020년 8월 기준 미혼집단이 17.91%, 기혼집단이 16.35%)\nCOVID-19까지는 재택 및 원격 근무제(공간적 유연) 선택 비율이 가장 낮고 시차출퇴근 선택자들의 비율이 가장 높았으나, 2021년 기준 재택 및 원격 근무제 선택 비중이 가장 높은 것으로 확인된다. \n유연근무제가 원래 일 가정 갈등 정책의 하위 정책으로 분류되어진 상황에서 여성들에 비해 남성들이 더 많이 사용하고 있다는 점, 미혼 집단의 사용율이 오히려 높다는 점에서 초기의 정책 목표를 달성하였다고 보기 어려운 부분이 있다.\n\n\n\n\n2. 공직생활실태조사 (2017~2020)\n\n지금부터의 분석은 2017~2020년 한국행정연구원이 (주)리서치앤리서치에 의뢰하여 실시한 5개년도의 ‘공직생활 실태조사’ 자료를 활용하여 분석한 것이다.  - 정부의 인적자원관리 현황과 공무원의 인식을 파악하기 위한 목적으로 조사시점기준 46개 중앙행정기관 및 17개 광역자치단체 소속 일반직 공무원을 대상으로 진행  층화 집락 추출 방식을 활용하여 부차모집단별 추출된 각 표본 과/팀에서 10명내외를 계통추출  - 표본의 크기는 각년도 말일 기준으로 모집단을 모비율 추정의 목표 오차(95% 신뢰수준 오차의 한계)인 2%∼3%를 만족하도록 구성  - 확률표본 수집 후 E-mail 웹 조사를 사용하였음.\n\n# 반복작업의 어려움으로 파이썬용 함수를 만들었음.\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/417/DT_417002N_011/2/1/20211204203850&prdSe=Y&startPrdDe=\"\n\ndef kosis(link,a,b):\n  link_list=[]\n  for i in range(int(a),int(b)+1,1):\n    new_link=link+str(i)\n    link_list.append(new_link)\n  \n  df= pd.read_json(link_list[0])\n  if len(link_list)>=2:\n    for i in link_list[1:]:\n      df = df >> bind_rows(pd.read_json(i), join='outer')\n  result=df.reset_index(drop=True)    \n  return result  \npj_gov=kosis(link,2017,2020)\n\na. 성별 정부조직 유연근무제 사용 비율\npj_gov=pj_gov>>mask(X.C2_NM==\"있다\")\npj_gov_gender=pj_gov >> mask((X.C1_NM==\"남성\")|(X.C1_NM==\"여성\")|(X.C1_NM==\"전체\"))\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_gender, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(50,80),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_gender, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"성별\")\n    + scale_color_manual(values=(\"#619CFF\",\"#F8766D\",\"gray\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('성별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697292525)>\n\n\n\n\nb. 연령 별 정부조직 유연근무제 사용 비율\npj_gov_age=pj_gov >> mask((X.C1_NM==\"20대\")|(X.C1_NM==\"30대\")|(X.C1_NM==\"40대\")|(X.C1_NM==\"50대 이상\")|(X.C1_NM==\"전체\"))\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_age, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(42,85),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_age, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"연령대별\")\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('연령대별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762698177993)>\n\n\n\n\nc. 직급 별 정부조직 유연근무제 사용 비율\npj_gov_rank=pj_gov >> mask((X.C1_NM==\"1~4급\")|(X.C1_NM==\"5급\")|(X.C1_NM==\"6~7급\")|(X.C1_NM==\"8~9급\"))\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_rank, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(42,85),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_rank, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"직급별\")\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('직급별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697124449)>\n\n\n\n\nd. 소속조직 수준 별 정부조직 유연근무제 사용 비율\npj_gov_level=pj_gov >> mask((X.C1_NM==\"광역자치단체\")|(X.C1_NM==\"중앙행정기관\"))\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_level, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(42,85),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_level, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"소속조직 수준별\")\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('소속조직 수준별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696037269)>\n\n\n\n\ne. 재직기간별 유연근무제 사용 비율\npj_gov_length=pj_gov >> mask((X.C1_NM==\"5년 이하\")|(X.C1_NM==\"6~10년\")|(X.C1_NM==\"11~15년\")|(X.C1_NM==\"16~20년\")|(X.C1_NM==\"21~25년\")|(X.C1_NM==\"26년 이상\")  )\npj_gov_length[\"C1_NM\"]=pd.Categorical(pj_gov_length[\"C1_NM\"], ordered=True,categories=[\"5년 이하\",\"6~10년\",\"11~15년\",\"16~20년\",\"21~25년\",\"26년 이상\"])\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_length, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(42,80),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_length, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"재직기간별\")\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('재직기간별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696138673)>\n\n\n\n\n정부조직 유연근무제의 특징 정리 (한국행정연구원 공직생활실태조사)\n\nCOVID-19이전까지 유연근무제의 사용이 꾸준히 감소하던 추세였다가, 발생 이후 급증함.\n전체기간에서 민간 및 공공기관 인구를 모두 포함해서 조사한 경제활동인구조사와 비교 시 정부조직 공무원들은 유연근무제를 더욱 약 2배 정도 많이 사용하고 있는 것으로 확인되었음.\n\n정부조직에서는 경제활동인구조사와는 달리 남성들이 유연근무제를 사용하는 비율이 여성이 사용하는 비율보다 낮았음. (2020년 기준 남성이 72.4%, 여성이 75.5%) 20대의 경우 정부조직에서 COVID-19 이전까지 유연근무제를 가장 적게 사용하던 연령대였으나, COVID-19이후 가장 많이 사용하는 연령대로 변화하였음. (2019년 47.5% 2020년 79.6%) 낮은 연령대의 공무원들이 유연근무제를 사용하지 못했던 원인에 대해서 깊이 있게 고찰해볼 필요가 존재함.(눈치가 보여서, 사용 못하였음… or 2015년 자체부서평가의 시행으로 잠시 올라갔다가 다시 떨어지는 추세)\n이러한 경향성은 직급별, 재직기간별 분석 자료를 통해 분석하였을 때 더욱 뚜렷하게 드러나는데, COVID-19이전까지는 하더라도 유연근무제가 재직기간이 길수록 직급이 높을 수록 훨씬 더 많이 사용하는 경향성이 있는 것으로 보였는데, 2020년 데이터에서는 직급 별 유연근무제 사용 비율이 큰 차이가 없었고, 재직기간이 5년 미만인 공무원들이 79%로 다른 세대에 비해서 월등하게 높은 유연근무제 사용율을 보이고 있는 것을 확인할 수 있었음.\n공공영역 유연근무제의 확산을 위해서는 유연근무제를 사용할 수 있는 조직적, 관리자적 지원이 필수적(Choi, 2017)이라는 이전 연구결과를 통해 미루어 보았을 때 유연근무제의 확산을 위해서 이후 소위 조직 내 입지가 적은 구성원들이 자유롭게 사용할 수 있는 분위기를 형성하기 위한 정책적 노력이 필요할 것으로 보인다."
  },
  {
    "objectID": "data_analytics/FWA.html#analysis-3-decision-tree-random-forest-정부조직-유연근무제의-참여-요인은-무엇인가-그러한-참여-요인들을-활용해서-유연근무제를-더-사용가능한-집단들을-예측하는-것이-가능한가",
    "href": "data_analytics/FWA.html#analysis-3-decision-tree-random-forest-정부조직-유연근무제의-참여-요인은-무엇인가-그러한-참여-요인들을-활용해서-유연근무제를-더-사용가능한-집단들을-예측하는-것이-가능한가",
    "title": "Sangwon Ju's Personal Page",
    "section": "03/ Analysis 3 – Decision Tree / Random Forest  정부조직 유연근무제의 참여 요인은 무엇인가?  그러한 참여 요인들을 활용해서 유연근무제를 더 사용가능한 집단들을 예측하는 것이 가능한가?",
    "text": "03/ Analysis 3 – Decision Tree / Random Forest  정부조직 유연근무제의 참여 요인은 무엇인가?  그러한 참여 요인들을 활용해서 유연근무제를 더 사용가능한 집단들을 예측하는 것이 가능한가?\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n공직생활실태조사 (2017년~2020년) 데이터 활용하여 병합함\n\ngc = gspread.authorize(GoogleCredentials.get_application_default())\n\nworksheet3 = gc.open('kipa_pre').sheet1\nrows1 = worksheet3.get_all_values()\nkipa_pre=pd.DataFrame.from_records(rows1)\nkipa_pre.columns=kipa_pre.iloc[0,:]\nkipa_pre=kipa_pre.iloc[1:,1:]\n\nkipa_pre\n\n\n\n\n\n  \n    \n      \n      year\n      fwa\n      smartwork\n      gender\n      age\n      work_year\n      rank\n      marriage\n      children\n      workamount\n      extrawork\n      orglevel\n      promotion_1\n      promotion_2\n      promotion_3\n      transform_1\n      transform_2\n      tranform_3\n      culture_per_1\n      culture_per_2\n      culture_tra_1\n      culture_tra_2\n      culture_sta_1\n      culture_sta_2\n      culture_par_1\n      culture_par_2\n      mng_support_1\n      mng_support_2\n      mng_support_3\n    \n  \n  \n    \n      1\n      2017\n      0\n      1\n      1\n      4\n      6\n      2\n      1\n      0\n      4\n      30\n      2\n      4\n      4\n      3\n      4\n      3\n      4\n      4\n      4\n      4\n      4\n      3\n      4\n      4\n      4\n      4\n      5\n      5\n    \n    \n      2\n      2017\n      1\n      0\n      1\n      2\n      3\n      3\n      1\n      1\n      4\n      25\n      2\n      2\n      2\n      2\n      4\n      3\n      3\n      5\n      5\n      5\n      5\n      5\n      5\n      5\n      5\n      3\n      2\n      2\n    \n    \n      3\n      2017\n      1\n      0\n      2\n      3\n      6\n      3\n      1\n      1\n      4\n      8\n      2\n      4\n      3\n      4\n      4\n      3\n      4\n      4\n      4\n      4\n      4\n      4\n      5\n      4\n      5\n      4\n      4\n      4\n    \n    \n      4\n      2017\n      1\n      1\n      1\n      2\n      2\n      2\n      1\n      1\n      5\n      20\n      1\n      2\n      3\n      3\n      2\n      2\n      2\n      2\n      2\n      2\n      2\n      2\n      2\n      2\n      3\n      2\n      2\n      2\n    \n    \n      5\n      2017\n      0\n      1\n      1\n      4\n      6\n      1\n      1\n      0\n      4\n      18\n      2\n      3\n      3\n      3\n      3\n      2\n      2\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      3\n      2\n      3\n      3\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      15563\n      2020\n      1\n      1\n      1\n      3\n      2\n      4\n      0\n      0\n      4\n      3\n      1\n      4\n      4\n      4\n      4\n      3\n      4\n      4\n      4\n      4\n      4\n      3\n      3\n      4\n      3\n      5\n      4\n      4\n    \n    \n      15564\n      2020\n      1\n      1\n      1\n      3\n      4\n      1\n      0\n      1\n      3\n      3\n      1\n      4\n      4\n      4\n      5\n      4\n      5\n      5\n      5\n      5\n      5\n      4\n      5\n      5\n      4\n      4\n      5\n      5\n    \n    \n      15565\n      2020\n      1\n      1\n      1\n      2\n      1\n      4\n      0\n      1\n      5\n      2\n      1\n      1\n      1\n      1\n      5\n      5\n      5\n      3\n      3\n      3\n      3\n      3\n      3\n      3\n      3\n      5\n      1\n      1\n    \n    \n      15566\n      2020\n      1\n      1\n      1\n      3\n      3\n      1\n      0\n      1\n      4\n      4\n      1\n      4\n      4\n      4\n      2\n      1\n      1\n      4\n      4\n      2\n      4\n      2\n      2\n      4\n      4\n      4\n      4\n      4\n    \n    \n      15567\n      2020\n      0\n      1\n      1\n      4\n      5\n      2\n      0\n      1\n      4\n      4\n      1\n      3\n      3\n      4\n      3\n      3\n      3\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      3\n      3\n      3\n    \n  \n\n15567 rows × 29 columns\n\n\n\n\n결측치 확인\n\n\nkipa_pre.isnull().sum() # 없음\n\n0\nyear             0\nfwa              0\nsmartwork        0\ngender           0\nage              0\nwork_year        0\nrank             0\nmarriage         0\nchildren         0\nworkamount       0\nextrawork        0\norglevel         0\npromotion_1      0\npromotion_2      0\npromotion_3      0\ntransform_1      0\ntransform_2      0\ntranform_3       0\nculture_per_1    0\nculture_per_2    0\nculture_tra_1    0\nculture_tra_2    0\nculture_sta_1    0\nculture_sta_2    0\nculture_par_1    0\nculture_par_2    0\nmng_support_1    0\nmng_support_2    0\nmng_support_3    0\ndtype: int64\n\n\ngender=pd.DataFrame(kipa_pre['gender'].value_counts())\ngender[\"성별\"]=[\"남자\",\"여자\"]\ngender.columns=[\"value\",\"gender\"]\n\nplt.figure()\npn.options.figure_size = (4,6)\n(ggplot(gender,aes(x='gender',y=\"value\",fill=\"gender\"))\n    + geom_bar(stat='identity',position = position_dodge(width = 0.9)) \n    + theme_classic() \n    + ylab(\"인원 (명)\")\n    + xlab(\"성별\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(fill=\"성별\")\n    + scale_fill_manual(values=(\"#619CFF\",\"#F8766D\"))\n    + geom_text(aes(label='value'),size=10, va='bottom', format_string='{:,}')\n    + ggtitle('조사대상 공무원 성별 인원\\n(자료 출처: 2017~2020 한국행정연구원 공직생활실태조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8753139113205)>\n\n\nkipa_pre['gender']=pd.Categorical(kipa_pre['gender'].str.replace(\"1\",\"0\").str.replace(\"2\",\"1\"))\n\n형 변환\n\nfor i in [\"year\",\"fwa\",\"smartwork\",\"age\",\"work_year\",\"rank\",\"marriage\",\"children\",\"orglevel\"]:\n  kipa_pre[i]=pd.Categorical(kipa_pre[i])\nkipa_pre[\"extrawork\"]=kipa_pre[\"extrawork\"].astype(np.float)\n\n# 초과근무 시간별 인원\nplt.figure(figsize = (10,5))\nplt.hist(kipa_pre[\"extrawork\"],bins=20)\nplt.title(\"초과 근무 시간별 공무원 (수)\")\nplt.show()\n\n\n\n\nfor i in kipa_pre.columns:\n  if i not in [\"year\",\"fwa\",\"smartwork\",\"gender\",\"age\",\"work_year\",\"rank\",\"marriage\",\"children\",\"orglevel\",\"extrawork\"]:\n    kipa_pre[i]=pd.Categorical(kipa_pre[i], ordered=True)\n\n기술통계 요약\n\nimport pandas_profiling\nkipa_pre.profile_report()\n\n변수들 간 연관성 확인: Correlation Matrix and Plot 범주형 변수간 연관성 확인을 진행하기 위해 Cramer’s V correlation 분석 진행. 참고: 크래머 V계수(Cramér’s V)는 카이 제곱 독립성 검정의 효과 크기 측정. 두 카테고리형 필드가 얼마나 강력하게 연관되는지를 측정. 0에서 1까지의 값을 가짐. 0.6 이상시 강력하게 연관 0.2~0.6까지 다소 연관되어 있음.  –> 전반적으로 유연근무제와 밀접하게 연관되어 있지는 않은 것으로 보인다.\n\n #연속형 변수의 제외\ndata=kipa_pre >> select(~X.extrawork,   ~X.work_year)\nfrom sklearn import preprocessing\n\nlabel = preprocessing.LabelEncoder()\ndata_encoded = pd.DataFrame() \n\nfor i in data.columns :\n  data_encoded[i]=label.fit_transform(data[i])\n# Building of the Cramer's V function\nfrom scipy.stats import chi2_contingency\n\ndef cramers_V(var1,var2) :\n  crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) # Cross table building\n  stat = chi2_contingency(crosstab)[0] # Keeping of the test statistic of the Chi2 test\n  obs = np.sum(crosstab) # Number of observations\n  mini = min(crosstab.shape)-1 # Take the minimum value between the columns and the rows of the cross table\n  return (stat/(obs*mini))\nrows= []\nfor var1 in data_encoded:\n  col = []\n  for var2 in data_encoded :\n    cramers =cramers_V(data_encoded[var1], data_encoded[var2]) # Cramer's V test\n    col.append(round(cramers,3)) # Keeping of the rounded value of the Cramer's V  \n  rows.append(col)\ncramers_results = np.array(rows)\ndf = pd.DataFrame(cramers_results, columns = data_encoded.columns, index =data_encoded.columns)\n\ndf\n\nplt.figure(figsize = (13,13))\nwith sns.axes_style(\"white\"):\n  ax = sns.heatmap(df,vmin=0., vmax=1, square=True,cbar_kws={\"shrink\": .5},cmap=\"BuPu\",annot=True, annot_kws={\"size\": 6})\nplt.show()\n\n\n\n\n\n유연근무제 참여여부에 대한 예측모형 (Decision Tree, Random Forest)\n\n\n!pip install graphviz\n\nRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n\n\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as mt\n\n# sklearn 모듈의 tree import\nfrom sklearn import tree\ndata2=kipa_pre[kipa_pre[\"year\"]<=2019]\ndata2=data2 >> select(~X.year)\n\ndata2.iloc[:,2:]\n\n\n\n\n\n  \n    \n      \n      gender\n      age\n      work_year\n      rank\n      marriage\n      children\n      workamount\n      extrawork\n      orglevel\n      promotion_1\n      promotion_2\n      promotion_3\n      transform_1\n      transform_2\n      tranform_3\n      culture_per_1\n      culture_per_2\n      culture_tra_1\n      culture_tra_2\n      culture_sta_1\n      culture_sta_2\n      culture_par_1\n      culture_par_2\n      mng_support_1\n      mng_support_2\n      mng_support_3\n    \n  \n  \n    \n      1\n      0\n      4\n      6\n      2\n      1\n      0\n      4\n      30.0\n      2\n      4\n      4\n      3\n      4\n      3\n      4\n      4\n      4\n      4\n      4\n      3\n      4\n      4\n      4\n      4\n      5\n      5\n    \n    \n      2\n      0\n      2\n      3\n      3\n      1\n      1\n      4\n      25.0\n      2\n      2\n      2\n      2\n      4\n      3\n      3\n      5\n      5\n      5\n      5\n      5\n      5\n      5\n      5\n      3\n      2\n      2\n    \n    \n      3\n      1\n      3\n      6\n      3\n      1\n      1\n      4\n      8.0\n      2\n      4\n      3\n      4\n      4\n      3\n      4\n      4\n      4\n      4\n      4\n      4\n      5\n      4\n      5\n      4\n      4\n      4\n    \n    \n      4\n      0\n      2\n      2\n      2\n      1\n      1\n      5\n      20.0\n      1\n      2\n      3\n      3\n      2\n      2\n      2\n      2\n      2\n      2\n      2\n      2\n      2\n      2\n      3\n      2\n      2\n      2\n    \n    \n      5\n      0\n      4\n      6\n      1\n      1\n      0\n      4\n      18.0\n      2\n      3\n      3\n      3\n      3\n      2\n      2\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      3\n      2\n      3\n      3\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      11224\n      0\n      4\n      6\n      1\n      1\n      0\n      5\n      2.0\n      2\n      4\n      4\n      4\n      3\n      3\n      3\n      4\n      3\n      4\n      3\n      3\n      3\n      3\n      3\n      3\n      3\n      3\n    \n    \n      11225\n      0\n      4\n      6\n      1\n      1\n      1\n      3\n      3.0\n      2\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      3\n      3\n      3\n      3\n    \n    \n      11226\n      0\n      4\n      6\n      1\n      1\n      0\n      3\n      3.0\n      2\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      5\n      5\n    \n    \n      11227\n      0\n      4\n      6\n      1\n      1\n      0\n      3\n      2.0\n      2\n      3\n      3\n      3\n      3\n      3\n      3\n      4\n      4\n      4\n      3\n      4\n      4\n      4\n      4\n      3\n      3\n      4\n    \n    \n      11228\n      0\n      4\n      6\n      1\n      1\n      0\n      3\n      2.0\n      2\n      4\n      4\n      4\n      3\n      3\n      3\n      3\n      2\n      2\n      2\n      3\n      3\n      3\n      3\n      3\n      3\n      3\n    \n  \n\n11228 rows × 26 columns\n\n\n\nDT_label=data2 >> select(X.fwa)\nDT_data=data2.iloc[:,2:]\ntrain_data,test_data,train_label,test_label=train_test_split(DT_data,DT_label,test_size=0.2, random_state=41)\n# DT 객체 생성 및 훈련\ndt_clf = tree.DecisionTreeClassifier()\ndt_clf.fit(train_data,train_label)\n\n# 예측값 저장\npred_label = dt_clf.predict(test_data)\n\n# Train 데이터 대상 학습결과 평가 - 확인용\nprint('Train_Accuracy: ', np.round(dt_clf.score(train_data, train_label)),'\\n')\n\nTrain_Accuracy:  1.0 \n\n\n\n\n# Test 데이터 데상 학습결과 평가 \naccuracy = mt.accuracy_score(test_label, pred_label)\naccuracy\n#전반적으로 정확도가 높지는 않은 것으로 보인다. \n\n0.5894924309884239\n\n\n전반적으로 정확도가 높지는 않은 것으로 보인다.  원인: 파이썬의 사이킷런은 범주형 변수를 예측변수로 사용할 수 있으나 순서형 범주 변수들을 인식하지 못해 이를 각각 따로 따로 반영하는 문제가 있다. 원핫코딩을 통해서 해결할 수 있다는 의견도 있으나 완벽한 해결책은 아니다.\n따라서, 지금부터의 분석은 범주형, 순서형, 연속형 예측변수를 활용할 수 있는 R의 패키지를 활용해서 분석을 진행하였다.\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png"
  },
  {
    "objectID": "data_analytics/index.html",
    "href": "data_analytics/index.html",
    "title": "Exploratory Data Analysis (2021-1) [in Korean]",
    "section": "",
    "text": "“Exploratory Data Analysis (2021-1) [in Korean]”"
  },
  {
    "objectID": "data_analytics/unemployment_index.html",
    "href": "data_analytics/unemployment_index.html",
    "title": "Analysis 2: Unemployment index",
    "section": "",
    "text": "Data retrieved from KOSIS (Korean Statistical Information Service).\nAgenda1: examining seasonal and monthly disparities in unemployment index to estimate the variance using longitudinal data.\nAgenda2: visualizing gender inequalities in unemployment status to identify the degree of change in unemployment index affected by seasonal and monthly disparities and to identify the degree of change in unemployment index affected by last three regimes.\nAgenda3: predicting to figure out whethter the trends in seasonal and monthly disparities maintain by utilizing ARIMA algorithm.\n\n\n\n\n\nCode\npacman::p_load(\"jsonlite\",\n               \"tidyverse\",\n               \"forecast\",\n               \"ggfortify\",\n               \"forecast\",\n               \"httr\",\n               \"sleekts\",\n               \"lubridate\",\n               \"stats\",\n               \"smooth\",\n               \"ghibli\",\n               \"plyr\",\n               \"scales\",\n               \"formattable\",\n               \"knitr\",\n               \"showtext\",\n               \"kableExtra\",\n               \"IRdisplay\",\n               \"glue\",\n               \"echarts4r\",\n               \"plotly\",\n               \"magrittr\")\n\n\n\n\n\n\n\nCode\nfont_add_google(name=\"Noto Serif\")\nshowtext_auto()"
  },
  {
    "objectID": "data_analytics/unemployment_index.html#importing-data",
    "href": "data_analytics/unemployment_index.html#importing-data",
    "title": "Analysis 2: Unemployment index",
    "section": "- Importing data",
    "text": "- Importing data\n\n\nCode\n# auto inporting function\ntotal=fromJSON(\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DA7001S/2/1/20211110114643_1&prdSe=M&newEstPrdCnt=142\")\nmale=fromJSON(\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DA7001S/2/1/20211110114643_2&prdSe=M&newEstPrdCnt=142\")\nfemale=fromJSON(\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DA7001S/2/1/20211110114643_3&prdSe=M&newEstPrdCnt=142\")\n\ntotal %>% \n    full_join(male) %>% \n    full_join(female) -> unemployment_data\n\n\n\n\nCode\nunemployment_data %T>% \n    glimpse() %>% \n    head(5) %>% \n    kbl() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\nRows: 426\nColumns: 16\n$ TBL_NM        <chr> \"성별 경제활동인구 총괄\", \"성별 경제활동인구 총괄\", \"성…\n$ PRD_DE        <chr> \"201009\", \"201010\", \"201011\", \"201012\", \"201101\", \"20110…\n$ TBL_ID        <chr> \"DT_1DA7001S\", \"DT_1DA7001S\", \"DT_1DA7001S\", \"DT_1DA7001…\n$ ITM_NM        <chr> \"실업률\", \"실업률\", \"실업률\", \"실업률\", \"실업률\", \"실업…\n$ ITM_NM_ENG    <chr> \"Unemployment rate\", \"Unemployment rate\", \"Unemployment …\n$ ITM_ID        <chr> \"T80\", \"T80\", \"T80\", \"T80\", \"T80\", \"T80\", \"T80\", \"T80\", …\n$ UNIT_NM       <chr> \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"…\n$ ORG_ID        <chr> \"101\", \"101\", \"101\", \"101\", \"101\", \"101\", \"101\", \"101\", …\n$ UNIT_NM_ENG   <chr> \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"%\", \"…\n$ C1_OBJ_NM     <chr> \"성별\", \"성별\", \"성별\", \"성별\", \"성별\", \"성별\", \"성별\", …\n$ C1_OBJ_NM_ENG <chr> \"By gender\", \"By gender\", \"By gender\", \"By gender\", \"By …\n$ DT            <chr> \"3.4\", \"3.3\", \"3\", \"3.5\", \"3.8\", \"4.5\", \"4.3\", \"3.7\", \"3…\n$ PRD_SE        <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"…\n$ C1            <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"…\n$ C1_NM         <chr> \"계\", \"계\", \"계\", \"계\", \"계\", \"계\", \"계\", \"계\", \"계\", \"…\n$ C1_NM_ENG     <chr> \"Total\", \"Total\", \"Total\", \"Total\", \"Total\", \"Total\", \"T…\n\n\n\n\n \n  \n    TBL_NM \n    PRD_DE \n    TBL_ID \n    ITM_NM \n    ITM_NM_ENG \n    ITM_ID \n    UNIT_NM \n    ORG_ID \n    UNIT_NM_ENG \n    C1_OBJ_NM \n    C1_OBJ_NM_ENG \n    DT \n    PRD_SE \n    C1 \n    C1_NM \n    C1_NM_ENG \n  \n \n\n  \n    성별 경제활동인구 총괄 \n    201009 \n    DT_1DA7001S \n    실업률 \n    Unemployment rate \n    T80 \n    % \n    101 \n    % \n    성별 \n    By gender \n    3.4 \n    M \n    0 \n    계 \n    Total \n  \n  \n    성별 경제활동인구 총괄 \n    201010 \n    DT_1DA7001S \n    실업률 \n    Unemployment rate \n    T80 \n    % \n    101 \n    % \n    성별 \n    By gender \n    3.3 \n    M \n    0 \n    계 \n    Total \n  \n  \n    성별 경제활동인구 총괄 \n    201011 \n    DT_1DA7001S \n    실업률 \n    Unemployment rate \n    T80 \n    % \n    101 \n    % \n    성별 \n    By gender \n    3 \n    M \n    0 \n    계 \n    Total \n  \n  \n    성별 경제활동인구 총괄 \n    201012 \n    DT_1DA7001S \n    실업률 \n    Unemployment rate \n    T80 \n    % \n    101 \n    % \n    성별 \n    By gender \n    3.5 \n    M \n    0 \n    계 \n    Total \n  \n  \n    성별 경제활동인구 총괄 \n    201101 \n    DT_1DA7001S \n    실업률 \n    Unemployment rate \n    T80 \n    % \n    101 \n    % \n    성별 \n    By gender \n    3.8 \n    M \n    0 \n    계 \n    Total"
  },
  {
    "objectID": "data_analytics/unemployment_index.html#clensing-data",
    "href": "data_analytics/unemployment_index.html#clensing-data",
    "title": "Analysis 2: Unemployment index",
    "section": "- Clensing data",
    "text": "- Clensing data\n\n\nCode\nunemployment_data$C1_NM_ENG %>% table()\n\n\n.\nFemale   Male  Total \n   142    142    142 \n\n\nCode\nunemployment_data %>% \n    transmute(Month=PRD_DE,Gender=ordered(C1_NM_ENG,levels=c(\"Total\",\"Male\",\"Female\")),                                          Unemployment_Rate=DT) %>% \n    tidyr::spread(key=\"Month\",value=\"Unemployment_Rate\") %>% \n    kbl() %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\n\n\n \n  \n    Gender \n    201009 \n    201010 \n    201011 \n    201012 \n    201101 \n    201102 \n    201103 \n    201104 \n    201105 \n    201106 \n    201107 \n    201108 \n    201109 \n    201110 \n    201111 \n    201112 \n    201201 \n    201202 \n    201203 \n    201204 \n    201205 \n    201206 \n    201207 \n    201208 \n    201209 \n    201210 \n    201211 \n    201212 \n    201301 \n    201302 \n    201303 \n    201304 \n    201305 \n    201306 \n    201307 \n    201308 \n    201309 \n    201310 \n    201311 \n    201312 \n    201401 \n    201402 \n    201403 \n    201404 \n    201405 \n    201406 \n    201407 \n    201408 \n    201409 \n    201410 \n    201411 \n    201412 \n    201501 \n    201502 \n    201503 \n    201504 \n    201505 \n    201506 \n    201507 \n    201508 \n    201509 \n    201510 \n    201511 \n    201512 \n    201601 \n    201602 \n    201603 \n    201604 \n    201605 \n    201606 \n    201607 \n    201608 \n    201609 \n    201610 \n    201611 \n    201612 \n    201701 \n    201702 \n    201703 \n    201704 \n    201705 \n    201706 \n    201707 \n    201708 \n    201709 \n    201710 \n    201711 \n    201712 \n    201801 \n    201802 \n    201803 \n    201804 \n    201805 \n    201806 \n    201807 \n    201808 \n    201809 \n    201810 \n    201811 \n    201812 \n    201901 \n    201902 \n    201903 \n    201904 \n    201905 \n    201906 \n    201907 \n    201908 \n    201909 \n    201910 \n    201911 \n    201912 \n    202001 \n    202002 \n    202003 \n    202004 \n    202005 \n    202006 \n    202007 \n    202008 \n    202009 \n    202010 \n    202011 \n    202012 \n    202101 \n    202102 \n    202103 \n    202104 \n    202105 \n    202106 \n    202107 \n    202108 \n    202109 \n    202110 \n    202111 \n    202112 \n    202201 \n    202202 \n    202203 \n    202204 \n    202205 \n    202206 \n  \n \n\n  \n    Total \n    3.4 \n    3.3 \n    3 \n    3.5 \n    3.8 \n    4.5 \n    4.3 \n    3.7 \n    3.2 \n    3.3 \n    3.3 \n    3 \n    3 \n    2.9 \n    2.9 \n    3 \n    3.5 \n    4.2 \n    3.7 \n    3.5 \n    3.1 \n    3.2 \n    3.1 \n    3 \n    2.9 \n    2.8 \n    2.8 \n    2.9 \n    3.4 \n    3.9 \n    3.5 \n    3.2 \n    3 \n    3.1 \n    3.1 \n    3 \n    2.7 \n    2.7 \n    2.6 \n    3 \n    3.4 \n    4.5 \n    3.9 \n    3.8 \n    3.5 \n    3.5 \n    3.4 \n    3.3 \n    3.1 \n    3.2 \n    3 \n    3.3 \n    3.7 \n    4.5 \n    4 \n    3.9 \n    3.7 \n    3.8 \n    3.6 \n    3.4 \n    3.2 \n    3.1 \n    3 \n    3.2 \n    3.7 \n    4.9 \n    4.2 \n    3.9 \n    3.6 \n    3.6 \n    3.5 \n    3.6 \n    3.5 \n    3.3 \n    3.1 \n    3.2 \n    3.7 \n    4.9 \n    4.1 \n    4.2 \n    3.6 \n    3.8 \n    3.4 \n    3.6 \n    3.3 \n    3.2 \n    3.1 \n    3.3 \n    3.7 \n    4.6 \n    4.5 \n    4.1 \n    4 \n    3.7 \n    3.7 \n    4 \n    3.6 \n    3.5 \n    3.2 \n    3.4 \n    4.5 \n    4.7 \n    4.3 \n    4.4 \n    4 \n    4 \n    3.9 \n    3 \n    3.1 \n    3 \n    3.1 \n    3.4 \n    4.1 \n    4.1 \n    4.2 \n    4.2 \n    4.5 \n    4.3 \n    4 \n    3.1 \n    3.6 \n    3.7 \n    3.4 \n    4.1 \n    5.7 \n    4.9 \n    4.3 \n    4 \n    4 \n    3.8 \n    3.2 \n    2.6 \n    2.7 \n    2.8 \n    2.6 \n    3.5 \n    4.1 \n    3.4 \n    3 \n    3 \n    3 \n    3 \n  \n  \n    Male \n    3.6 \n    3.5 \n    3.3 \n    3.7 \n    3.9 \n    4.5 \n    4.4 \n    4 \n    3.4 \n    3.4 \n    3.6 \n    3.3 \n    3.3 \n    3.2 \n    3.1 \n    3.2 \n    3.6 \n    4.1 \n    3.9 \n    3.6 \n    3.2 \n    3.4 \n    3.3 \n    3.2 \n    3.1 \n    2.9 \n    3 \n    3.3 \n    3.6 \n    4.1 \n    3.6 \n    3.3 \n    3.1 \n    3.2 \n    3.4 \n    3.3 \n    2.9 \n    2.9 \n    2.8 \n    3.1 \n    3.5 \n    4.2 \n    3.9 \n    3.8 \n    3.4 \n    3.5 \n    3.3 \n    3.5 \n    3.3 \n    3.3 \n    3.1 \n    3.4 \n    3.8 \n    4.3 \n    4 \n    3.8 \n    3.7 \n    3.9 \n    3.8 \n    3.5 \n    3.4 \n    3.1 \n    3.2 \n    3.3 \n    3.7 \n    4.7 \n    4.4 \n    4 \n    3.7 \n    3.8 \n    3.7 \n    3.8 \n    3.7 \n    3.3 \n    3.1 \n    3.1 \n    3.7 \n    4.7 \n    4.1 \n    4.3 \n    3.7 \n    3.9 \n    3.6 \n    3.8 \n    3.6 \n    3.4 \n    3.3 \n    3.5 \n    3.7 \n    4.3 \n    4.6 \n    4.2 \n    4.2 \n    3.8 \n    3.8 \n    4.2 \n    3.8 \n    3.6 \n    3.4 \n    3.7 \n    4.4 \n    4.5 \n    4.4 \n    4.6 \n    4.3 \n    4.2 \n    3.9 \n    3.2 \n    3.4 \n    3.2 \n    3.3 \n    3.3 \n    3.9 \n    4 \n    4.2 \n    4.2 \n    4.6 \n    4.3 \n    4 \n    3 \n    3.7 \n    3.8 \n    3.4 \n    3.7 \n    5 \n    4.7 \n    4.2 \n    4 \n    4 \n    3.8 \n    3.3 \n    2.7 \n    2.8 \n    2.8 \n    2.6 \n    3.1 \n    3.5 \n    3.2 \n    2.9 \n    2.8 \n    2.9 \n    2.9 \n  \n  \n    Female \n    3.3 \n    3 \n    2.5 \n    3.2 \n    3.6 \n    4.5 \n    4.1 \n    3.3 \n    2.9 \n    3.1 \n    2.9 \n    2.6 \n    2.7 \n    2.5 \n    2.5 \n    2.8 \n    3.3 \n    4.3 \n    3.5 \n    3.2 \n    2.9 \n    2.9 \n    2.7 \n    2.7 \n    2.6 \n    2.6 \n    2.4 \n    2.4 \n    3.1 \n    3.6 \n    3.3 \n    3 \n    2.9 \n    2.8 \n    2.7 \n    2.6 \n    2.4 \n    2.4 \n    2.4 \n    2.8 \n    3.4 \n    4.8 \n    3.8 \n    3.8 \n    3.7 \n    3.6 \n    3.4 \n    3.1 \n    2.9 \n    3 \n    2.9 \n    3.3 \n    3.7 \n    4.8 \n    4.1 \n    4 \n    3.8 \n    3.7 \n    3.4 \n    3.2 \n    2.9 \n    3 \n    2.8 \n    3.1 \n    3.6 \n    5 \n    4 \n    3.9 \n    3.5 \n    3.4 \n    3.2 \n    3.3 \n    3.4 \n    3.3 \n    3.1 \n    3.3 \n    3.8 \n    5.2 \n    4.2 \n    4 \n    3.4 \n    3.6 \n    3.2 \n    3.3 \n    2.9 \n    2.9 \n    2.9 \n    3 \n    3.8 \n    5 \n    4.4 \n    4 \n    3.7 \n    3.6 \n    3.6 \n    3.8 \n    3.5 \n    3.3 \n    3 \n    3.1 \n    4.5 \n    5 \n    4.1 \n    4.1 \n    3.7 \n    3.7 \n    3.7 \n    2.8 \n    2.8 \n    2.8 \n    2.7 \n    3.4 \n    4.4 \n    4.2 \n    4.4 \n    4.2 \n    4.5 \n    4.4 \n    4.1 \n    3.2 \n    3.4 \n    3.5 \n    3.5 \n    4.6 \n    6.7 \n    5.2 \n    4.4 \n    4.1 \n    4 \n    3.9 \n    3.1 \n    2.5 \n    2.5 \n    2.7 \n    2.6 \n    4 \n    4.9 \n    3.6 \n    3.2 \n    3.2 \n    3.2 \n    3.2"
  },
  {
    "objectID": "data_analytics/unemployment_index.html#unemployment-rate-of-total-population",
    "href": "data_analytics/unemployment_index.html#unemployment-rate-of-total-population",
    "title": "Analysis 2: Unemployment index",
    "section": "- Unemployment rate of total population",
    "text": "- Unemployment rate of total population\n\n\nCode\nunemp_total %>% \n    autoplot() + \n    theme_classic()+\n    theme(text=element_text(family=\"Noto Serif\",size=12)) -> p\n\nggplotly(p) %>% \n    layout(title = list(text = paste0(\n        'Unemployment rate of economically active population (2010~2022)',\n        '<br>',\n        '<sup>',\n        'Korean Population and Housing Census (retrieved from KOSIS) (Jan, 2010 ~ June, 2022)','</sup>'),\n        x = 0,\n        font=list(size=16)))\n\n\n\n\n\n\n\n- Time-series smoothing\n\n\nCode\n# 3RSSH Twice. 4253H Twice smoothing\nsmooth_3RSSH=function(data){ \n  smooth3RSS=smooth(data, kind=\"3RSS\") \n  n=length(data) \n  smooth3RSSH=smooth3RSS \n  \n  for (i in 2:(n-1)) {\n    smooth3RSSH[i] <- smooth3RSS[i-1]/4 + smooth3RSS[i]/2 + smooth3RSS[i+1]/4}\n    \n    smooth3RSSH[1] <- smooth3RSS[1]; \n    smooth3RSSH[n] <- smooth3RSS[n] \n    rough=data-smooth3RSSH \n    roughH=rough \n  \n    smooth3RSS2=smooth(rough,kind=\"3RSS\") \n  \n  for (i in 2:(n-1)) {\n    roughH[i] <- smooth3RSS2[i-1]/4 + smooth3RSS2[i]/2 + smooth3RSS2[i+1]/4}\n  \n    roughH[1] <- smooth3RSS2[1]; \n    roughH[n] <- smooth3RSS2[n] \n    out=smooth3RSSH+roughH \n    out=as.vector(out) \n    return(out)} \n\n\n\n\nCode\n# Data clensing\nsmooth=tibble(\n    ym(total$PRD_DE),as.numeric(total$DT),smooth_3RSSH(as.numeric(total$DT)),\n    sleek(as.numeric(total$DT)))\n\nnames(smooth)=c(\"year\",\"Default\",\"3RSSH Twice\",\"4253H Twice\")\n\ndatebreaks <- seq(as.Date(\"2010-01-01\"), as.Date(\"2022-12-01\"), by=\"6 month\")\n\n\n\n\nCode\nsmooth %>% \n    tidyr::gather(\"Default\",\n                  \"3RSSH Twice\",\n                  \"4253H Twice\",\n                  key = \"variable\",\n                  value=\"value\") %>%\n    mutate(type=factor(variable,\n                           levels=c(\"Default\",\n                                    \"3RSSH Twice\",\n                                    \"4253H Twice\"))) %>% \n    ggplot(aes(x=year,y=value,color=type, group = 1,\n               text=paste('Smoothing Type:', type,\n                     '<br>Time: ', format(zoo::as.yearmon(year),\"%Y/%m\"),\n                     '<br>Rate (%): ', formattable::percent(value/100)))) +\n    geom_line(aes(x=year,y=value),size=1) +\n    geom_point(size=2)+\n    theme_classic() +\n    labs(color=\"Smoothing Methods\",\n         y=\"Unimployment Index(%)\")+\n    scale_x_date(breaks=datebreaks,labels=date_format(\"%Y/%m\"))+\n    theme(text=element_text(family=\"Noto Serif\",size=12),\n          axis.text.x = element_text(angle=30, hjust=1),\n          axis.title.x=element_blank()) -> p1\n\nggplotly(p1,tooltip=\"text\") %>% \n    layout(title = list(text = paste0(\n        'Unemployment Rate of economically active population with smoothing',\n        '<br>',\n        '<sup>',\n        'Source: Korean Population and Housing Census (retrieved from KOSIS) (Jan, 2010 ~ June, 2022)','</sup>'),\n        x = 0,\n        font=list(size=16)))"
  },
  {
    "objectID": "data_analytics/unemployment_index.html#comparison-of-the-unemployment-rate-among-presidential-regimes",
    "href": "data_analytics/unemployment_index.html#comparison-of-the-unemployment-rate-among-presidential-regimes",
    "title": "Analysis 2: Unemployment index",
    "section": "- Comparison of the unemployment rate among presidential regimes",
    "text": "- Comparison of the unemployment rate among presidential regimes\n\n\nCode\nregime=data.frame(president=factor(c(\"Lee Myung-bak\",\"Park Geun-hye\",\"Hwang Kyo-ahn\",\"Moon Jae-in\",\"Yoon Suk-yeol\"),\n                              levels=c(\"Lee Myung-bak\",\"Park Geun-hye\",\"Hwang Kyo-ahn\",\"Moon Jae-in\",\"Yoon Suk-yeol\")),\n             start_date=ymd(c(20100101,20130201,20170301,20170510,20220510)), \n             end_date=ymd(c(20130131,20170228,20170509,20220509,20230701)))\n\nregime %>% \n    kbl(col.names = gsub(\"[_]\", \" \", names(.)) %>% str_to_title()) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\n\n\n \n  \n    President \n    Start Date \n    End Date \n  \n \n\n  \n    Lee Myung-bak \n    2010-01-01 \n    2013-01-31 \n  \n  \n    Park Geun-hye \n    2013-02-01 \n    2017-02-28 \n  \n  \n    Hwang Kyo-ahn \n    2017-03-01 \n    2017-05-09 \n  \n  \n    Moon Jae-in \n    2017-05-10 \n    2022-05-09 \n  \n  \n    Yoon Suk-yeol \n    2022-05-10 \n    2023-07-01 \n  \n\n\n\n\n\n\n\nCode\ndatebreaks <- seq(as.Date(\"2010-01-01\"), as.Date(\"2022-12-01\"), by=\"6 month\")\nsmooth %>% \n    tidyr::gather(\"Default\",\n                  \"3RSSH Twice\",\n                  \"4253H Twice\",\n                  key = \"variable\",\n                  value=\"value\") %>% \n    dplyr::filter(variable==\"Default\") %>% \n    ggplot(aes(group=1,text=paste('Time: ', format(zoo::as.yearmon(year),\"%Y/%m\"),\n                     '<br>Rate (%): ', formattable::percent(value/100))))+\n    geom_rect(data=regime,aes(xmin=start_date,\n                              xmax=end_date, \n                              ymin=2,\n                              ymax=6, \n                              fill=president,text=\"\"), alpha=0.2)+\n    geom_line(aes(x=year,y=value),color=\"black\",size=1)+\n    geom_point(aes(x=year,y=value),color=\"black\",size=1.5)+\n    theme_classic() +\n    labs(fill=\"Presidential Regime\",\n         y=\"Unimployment Index(%)\")+\n    scale_x_date(breaks=datebreaks,labels=date_format(\"%Y/%m\"))+\n    theme(text=element_text(family=\"Noto Serif\",size=12),\n          axis.text.x = element_text(angle=30, hjust=1),\n          axis.title.x=element_blank())+\n    geom_smooth(aes(x=year,y=value),\n                method='loess',\n                color=\"orange\",\n                linetype=\"dashed\",\n                fill = \"orange\",\n                alpha=0.1) -> p2\n\n\nWarning: Ignoring unknown aesthetics: text\n\n\nCode\nggplotly(p2,tooltip=c(\"text\") )%>% \n    layout(title = list(text = paste0(\n        'Unemployment Rate of economically active population with smoothing',\n        '<br>',\n        '<sup>',\n        'Source: Korean Population and Housing Census (retrieved from KOSIS) (Jan, 2010 ~ June, 2022)','</sup>'),\n        x = 0,\n        font=list(size=16)))\n\n\n`geom_smooth()` using formula 'y ~ x'"
  },
  {
    "objectID": "data_analytics/unemployment_index.html#comparison-of-the-unemployment-rate-between-male-and-female",
    "href": "data_analytics/unemployment_index.html#comparison-of-the-unemployment-rate-between-male-and-female",
    "title": "Analysis 2: Unemployment index",
    "section": "- Comparison of the unemployment rate between male and female",
    "text": "- Comparison of the unemployment rate between male and female\n\n\nCode\nunemp=data.frame(year=ym(total$PRD_DE),\n                 total_unemp=total$DT,\n                 male_unemp=male$DT,\n                 female_unemp=female$DT)\n\nunemp %>% \n    mutate_if(is.character,as.numeric) %>%\n    mutate(month=format(as.Date(year,format=\"%Y%m\"), \"%b\")) -> unemp\nunemp$month=ordered(month.abb[as.numeric(unemp$month)],levels=month.abb)\n\n\nunemp %>% \n    select(-year) %>% \n    gather(\"variable\",\"value\",1:3) %>% \n    group_by(month,variable,.add = TRUE) %>% \n    mutate(Mean_value= mean(value),Min_value=min(value),Max_value=max(value))%>% \n    mutate(variable=factor(variable,\n                           levels=c(\"total_unemp\",\"male_unemp\",\"female_unemp\"))) %>%\n    ggplot(aes(x=month,y=Mean_value,fill=variable))+ \n    facet_wrap(~variable,\n               labeller = labeller(variable = c(\"total_unemp\" = \"Total Unemployment\",   \n                                                \"male_unemp\" = \"Male Unemployment\",\n                                            \"female_unemp\" = \"Female Unemployment\")))+\n    theme_classic()+\n    geom_bar(stat = \"identity\", position = \"dodge\")+\n    scale_fill_manual(labels=c(\"Total Unemployment\", \n                               \"Male Unemployment\",\n                               \"Female Unemployment\"),\n                      name = \"Genders\",values =c(\"gray\",\"#619CFF\",\"#F8766D\"))+\n    labs(y=\"Unemployment Rate\\n\",\n        x=\"\\n\")+\n    geom_errorbar(aes(ymin = Min_value, \n                      ymax = Max_value), \n                      width = 0.05, position = position_dodge(0.9))+\n    theme(text=element_text(family=\"Noto Serif\",size=12),\n          axis.text.x = element_text(angle=45, hjust=1),\n          axis.title.x=element_blank())+\n    coord_cartesian(ylim=c(1.5,7))+\n    geom_text(aes(label= paste(sprintf(\"%2.2f\", Mean_value),\"%\",sep=\"\")),\n              vjust=-0.4, size=3,position = position_dodge(width = 1)) -> p3\n    \n\nmrg <- list(l = 100, r = 50 ,\n          b = 30, t = 150)\n\nggplotly(p3, tooltip=\"text\")%>% \n    style(textposition = \"top\") %>% \n    layout(title = list(text = paste0(\n        'Unemployment Rate of economically active population',\n        '<br>',\n        '<sup>',\n        'Source: Korean Population and Housing Census (retrieved from KOSIS) (Jan, 2010 ~ June, 2022)<br>',\n        'Error Bar: Min-Max Rate Per Month',\n        '</sup>'),\n        x = 0.05,\n        font=list(size=16)),\n        margin = mrg) \n\n\n\n\n\n\n\n\nCode\nunemp=data.frame(year=ym(total$PRD_DE),\n                 total_unemp=total$DT,\n                 male_unemp=male$DT,\n                 female_unemp=female$DT)\n\nunemp %>% \n    mutate_if(is.character,as.numeric) %>%\n    mutate(month=format(as.Date(year,format=\"%Y%m\"), \"%b\")) -> unemp\nunemp$month=ordered(month.abb[as.numeric(unemp$month)],levels=month.abb)\n\n\nunemp %>% \n    select(-year) %>% \n    gather(\"variable\",\"value\",1:3) %>% \n    group_by(month,variable,.add = TRUE) %>% \n    mutate(Mean_value= mean(value),Min_value=min(value),Max_value=max(value))%>% \n    mutate(variable=factor(variable,\n                           levels=c(\"total_unemp\",\"male_unemp\",\"female_unemp\"))) %>%\n    ggplot(aes(x=month,y=Mean_value,fill=variable))+ \n    theme_classic()+\n    geom_bar(stat = \"identity\", position = \"dodge\")+\n    scale_fill_manual(labels=c(\"Total Unemployment\", \n                               \"Male Unemployment\",\n                               \"Female Unemployment\"),\n                      name = \"Genders\",values =c(\"gray\",\"#619CFF\",\"#F8766D\"))+\n    labs(y=\"Unemployment Rate\\n\")+\n    geom_errorbar(aes(ymin = Min_value, \n                      ymax = Max_value), \n                      width = 0.05, position = position_dodge(0.9))+\n    theme(text=element_text(family=\"Noto Serif\",size=12),\n          axis.text.x = element_text(angle=45, hjust=1),\n          axis.title.x=element_blank())+\n    coord_cartesian(ylim=c(1.5,7)) -> p4\n    \n\nmrg <- list(l = 100, r = 50 ,\n          b = 30, t = 150)\n\nggplotly(p4, tooltip=c(\"value\",\"year\"))%>% \n    style(textposition = \"top\") %>% \n    layout(title = list(text = paste0(\n        'Unemployment Rate of economically active population',\n        '<br>',\n        '<sup>',\n        'Source: Korean Population and Housing Census (retrieved from KOSIS) (Jan, 2010 ~ June, 2022)<br>',\n        'Error Bar: Min-Max Rate Per Month',\n        '</sup>'),\n        x = 0.05,\n        font=list(size=16)),\n        margin = mrg)"
  },
  {
    "objectID": "data_analytics/unemployment_index.html#seasonal-decomposition-of-the-unemployment-rate",
    "href": "data_analytics/unemployment_index.html#seasonal-decomposition-of-the-unemployment-rate",
    "title": "Analysis 2: Unemployment index",
    "section": "- Seasonal decomposition of the unemployment rate",
    "text": "- Seasonal decomposition of the unemployment rate\n\n\nCode\nunemp_total.decompose=decompose(unemp_total)\nunemp_male.decompose=decompose(unemp_male)\nunemp_female.decompose=decompose(unemp_female)\n\n\n\n\nCode\n# Total\nplot(unemp_total.decompose,cex.main=2, cex.lab=2, cex.axis=2)\n\n\n\n\n\n\n\n\n\nCode\n# Male\nplot(unemp_male.decompose,cex.main=2, cex.lab=2, cex.axis=2)\n\n\n\n\n\n\n\n\n\nCode\n# Female\nplot(unemp_female.decompose,cex.main=2, cex.lab=2, cex.axis=2)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(unemp_total.decompose$seasonal,main=\"The Plot of Seasoal Decomposition\",cex.main=2, cex.lab=2, cex.axis=2)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Box-Cox Transformation(To visualize seasonality and to improve normality)\nlambda <- forecast::BoxCox.lambda(unemp_total)\nunemp_total_bc <- forecast::BoxCox(unemp_total, lambda)\n\n# Boxcox transforamtion is only applicable when data only contain positive value.\nplot(unemp_total_bc, main = \"Box-Cox : Unemployment Rate\",,cex.main=2, cex.lab=2, cex.axis=2)\n\n\n\n\n\n\n\n\n\n\n- Visualize seasonality and comparing trends per year\n\n\nCode\nunemp %>%\n    mutate(time=year,\n        year=factor(format(as.Date(year), \"%Y\"))) -> unemp2\n\n\n\n\nCode\nunemp2 %>% \n    select(time,month,year,total_unemp,male_unemp,female_unemp) %>%\n    gather(\"variable\",\"value\", 4:6) %>% \n    mutate(variable=factor(variable,levels= c(\"total_unemp\",\n                                              \"male_unemp\",\n                                          \"female_unemp\"))) %>% \n    ggplot(aes(x=as.factor(month),\n               y=value,\n               group=year,\n               color=as.factor(year),\n               text=paste('Time: ', format(zoo::as.yearmon(time),\"%Y/%m\"),\n                     '<br>Rate (%): ', formattable::percent(value/100),\n                     '<br>Gender: ',variable))) +\n    geom_line() + \n    geom_point()+\n    facet_wrap(~variable,\n               labeller = labeller(variable = \n                                       c(\"total_unemp\" = \"Total Unemployment\",   \n                                         \"male_unemp\" = \"Male Unemployment\",\n                                         \"female_unemp\" = \"Female Unemployment\")))+\n    theme_classic()+\n    scale_fill_manual(labels=c(\"Total Unemployment\", \n                               \"Male Unemployment\",\n                               \"Female Unemployment\"),\n                      name = \"Genders\",values =c(\"gray\",\"#619CFF\",\"#F8766D\"))+\n    labs(y=\"Unemployment Rate\\n\",color = \"Year\")+\n    theme(text=element_text(family=\"Noto Serif\",size=12),\n          axis.text.x = element_text(angle=45, hjust=1),\n          axis.title.x=element_blank()) +\n    coord_cartesian(ylim=c(1.5,7)) -> p5\n    \n\nmrg <- list(l = 100, r = 50 ,\n          b = 30, t = 100)\n\ngp<- ggplotly(p5, tooltip=\"text\")%>% \n    style(textposition = \"top\") %>% \n    layout(title = list(text = paste0(\n        'Unemployment Rate of economically active population',\n        '<br>',\n        '<sup>',\n        'Source: Korean Population and Housing Census (retrieved from KOSIS) (Jan, 2010 ~ June, 2022)',\n        '</sup>'),\n        x = 0.05,\n        font=list(size=16)),\n        margin = mrg) \n\nfor (i in seq_along(gp$x$data)) {\n  # Is the layer the first entry of the group?\n  is_first <- grepl(\"^\\\\(.*?,1\\\\)\", gp$x$data[[i]]$name)\n  # Extract the group identifier and assign it to the name and legendgroup arguments\n  gp$x$data[[i]]$name <- gsub(\"^\\\\((.*?),\\\\d+\\\\)\", \"\\\\1\", gp$x$data[[i]]$name)\n  gp$x$data[[i]]$legendgroup <- gp$x$data[[i]]$name\n  # Show the legend only for the first layer of the group \n  if (!is_first) gp$x$data[[i]]$showlegend <- FALSE\n}\n\ngp\n\n\n\n\n\n\n\n\nCode\nunemp2 %>% \n    select(time,month,year,total_unemp,male_unemp,female_unemp) %>%\n    gather(\"variable\",\"value\", 4:6) %>% \n    mutate(variable=factor(variable,levels= c(\"total_unemp\",\n                                              \"male_unemp\",\n                                          \"female_unemp\"))) %>% \n    ggplot(aes(x=as.factor(month),\n               y=sleek(value),\n               group=year,\n               color=as.factor(year),\n               text=paste('Time: ', format(zoo::as.yearmon(time),\"%Y/%m\"),\n                     '<br>Rate (%): ', formattable::percent(value/100),\n                     '<br>Gender: ',variable))) +\n    geom_line() + \n    geom_point()+\n    facet_wrap(~variable,\n               labeller = labeller(variable = \n                                       c(\"total_unemp\" = \"Total Unemployment\",   \n                                         \"male_unemp\" = \"Male Unemployment\",\n                                         \"female_unemp\" = \"Female Unemployment\")))+\n    theme_classic()+\n    scale_fill_manual(labels=c(\"Total Unemployment\", \n                               \"Male Unemployment\",\n                               \"Female Unemployment\"),\n                      name = \"Genders\",values =c(\"gray\",\"#619CFF\",\"#F8766D\"))+\n    labs(y=\"Unemployment Rate\\n\",color = \"Year\")+\n    theme(text=element_text(family=\"Noto Serif\",size=12),\n          axis.text.x = element_text(angle=45, hjust=1),\n          axis.title.x=element_blank()) +\n    coord_cartesian(ylim=c(1.5,7)) -> p6\n    \n\nmrg <- list(l = 100, r = 50 ,\n          b = 30, t = 100)\n\ngp1<- ggplotly(p6, tooltip=\"text\")%>% \n    style(textposition = \"top\") %>% \n    layout(title = list(text = paste0(\n        'Unemployment Rate of economically active population with 4253H Twice smoothing',\n        '<br>',\n        '<sup>',\n        'Source: Korean Population and Housing Census (retrieved from KOSIS) (Jan, 2010 ~ June, 2022)',\n        '</sup>'),\n        x = 0.05,\n        font=list(size=16)),\n        margin = mrg) \n\nfor (i in seq_along(gp1$x$data)) {\n  # Is the layer the first entry of the group?\n  is_first <- grepl(\"^\\\\(.*?,1\\\\)\", gp1$x$data[[i]]$name)\n  # Extract the group identifier and assign it to the name and legendgroup arguments\n  gp1$x$data[[i]]$name <- gsub(\"^\\\\((.*?),\\\\d+\\\\)\", \"\\\\1\", gp1$x$data[[i]]$name)\n  gp1$x$data[[i]]$legendgroup <- gp1$x$data[[i]]$name\n  # Show the legend only for the first layer of the group \n  if (!is_first) gp1$x$data[[i]]$showlegend <- FALSE\n}\n\n\ngp1"
  },
  {
    "objectID": "data_analytics/unemployment_index.html#predicting-next-years-unemployment-rate-using-arima-algorithm.",
    "href": "data_analytics/unemployment_index.html#predicting-next-years-unemployment-rate-using-arima-algorithm.",
    "title": "Analysis 2: Unemployment index",
    "section": "- Predicting next year’s unemployment rate using ARIMA algorithm.",
    "text": "- Predicting next year’s unemployment rate using ARIMA algorithm.\n\n\nCode\n# ARIMA\naTSA::adf.test(unemp_total, nlag = NULL, output = TRUE) \n\n\nAugmented Dickey-Fuller Test \nalternative: stationary \n \nType 1: no drift no trend \n     lag    ADF p.value\n[1,]   0 -0.772   0.402\n[2,]   1 -0.805   0.390\n[3,]   2 -0.667   0.440\n[4,]   3 -0.649   0.446\n[5,]   4 -0.676   0.437\nType 2: with drift no trend \n     lag   ADF p.value\n[1,]   0 -4.78    0.01\n[2,]   1 -5.77    0.01\n[3,]   2 -5.65    0.01\n[4,]   3 -4.89    0.01\n[5,]   4 -5.19    0.01\nType 3: with drift and trend \n     lag   ADF p.value\n[1,]   0 -4.86    0.01\n[2,]   1 -5.95    0.01\n[3,]   2 -5.85    0.01\n[4,]   3 -5.16    0.01\n[5,]   4 -5.64    0.01\n---- \nNote: in fact, p.value = 0.01 means p.value <= 0.01 \n\n\nCode\n# p-value<=0.01 Reject null-hypothesis. (Stationary)\n\n\n\n\nCode\nfit=auto.arima(unemp_total,trace=T)\n\n\n\n ARIMA(2,1,2)(1,1,1)[12]                    : 36.50482\n ARIMA(0,1,0)(0,1,0)[12]                    : 68.4576\n ARIMA(1,1,0)(1,1,0)[12]                    : 37.8781\n ARIMA(0,1,1)(0,1,1)[12]                    : 39.43664\n ARIMA(2,1,2)(0,1,1)[12]                    : 42.49405\n ARIMA(2,1,2)(1,1,0)[12]                    : 36.07573\n ARIMA(2,1,2)(0,1,0)[12]                    : 60.73393\n ARIMA(2,1,2)(2,1,0)[12]                    : 36.37945\n ARIMA(2,1,2)(2,1,1)[12]                    : 38.59869\n ARIMA(1,1,2)(1,1,0)[12]                    : 35.92575\n ARIMA(1,1,2)(0,1,0)[12]                    : 58.66389\n ARIMA(1,1,2)(2,1,0)[12]                    : 36.1904\n ARIMA(1,1,2)(1,1,1)[12]                    : 36.2949\n ARIMA(1,1,2)(0,1,1)[12]                    : 41.57701\n ARIMA(1,1,2)(2,1,1)[12]                    : 38.35171\n ARIMA(0,1,2)(1,1,0)[12]                    : 34.33111\n ARIMA(0,1,2)(0,1,0)[12]                    : 56.7069\n ARIMA(0,1,2)(2,1,0)[12]                    : 34.64578\n ARIMA(0,1,2)(1,1,1)[12]                    : 34.77616\n ARIMA(0,1,2)(0,1,1)[12]                    : 39.77648\n ARIMA(0,1,2)(2,1,1)[12]                    : 36.78503\n ARIMA(0,1,1)(1,1,0)[12]                    : 33.73023\n ARIMA(0,1,1)(0,1,0)[12]                    : 55.59995\n ARIMA(0,1,1)(2,1,0)[12]                    : 33.42099\n ARIMA(0,1,1)(2,1,1)[12]                    : 35.52775\n ARIMA(0,1,1)(1,1,1)[12]                    : 33.70222\n ARIMA(0,1,0)(2,1,0)[12]                    : 49.02686\n ARIMA(1,1,1)(2,1,0)[12]                    : 34.1495\n ARIMA(1,1,0)(2,1,0)[12]                    : 36.97406\n\n Best model: ARIMA(0,1,1)(2,1,0)[12]                    \n\n\n\n\nCode\nforecast::forecast(fit, level=c(75, 95), h=12) %>% \n    autoplot() + \n    theme_classic()+\n    theme(text=element_text(family=\"Noto Serif\",size=12)) -> p7\n\nggplotly(p7) %>% \n    layout(title = list(text = paste0(\n        'Prediction of unemployment rate of economically active population (for next 12 months)',\n        '<br>',\n        '<sup>',\n        'Korean Population and Housing Census (retrieved from KOSIS) (Jan, 2010 ~ June, 2022)','</sup>'),\n        x = 0,\n        font=list(size=16)))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sangwon Ju (주상원)",
    "section": "",
    "text": "Hi. I'm a Master's student in  Graduate School of Public Administration at Seoul National University, Seoul, South Korea. \n\nI'm currently studying public policy and management. Generally, my works seeks to understand interaction between information systems and public policy process, quantify impact of information systems on acquiring public value, and figure out how researchers can contribute to improving organizational decision-making by adequately utilizing information systems and evidence-based practices.   \n\n\n\n\nSeoul National University, GSPA | Seoul, KR\nM.P.A in Public Policy | Sep 2021 - Aug 2023\nYonsei University, CSS | Seoul, KR\nB.A in Public Policy and Management\nB.A in Business Administration\nMinor in Applied Statistics | Mar 2015 - Aug 2021\n\n\n\n\n\nKorea Research Institute for Local Administration\nResearch Assistant | May 2022 - Present\nEvidence-Based Research Lab, GSPA, SNU\nResearch Assistant | Sep 2021 - Present"
  },
  {
    "objectID": "publication.html",
    "href": "publication.html",
    "title": "Publications / Working Papers",
    "section": "",
    "text": "To be updated"
  },
  {
    "objectID": "publication.html#working-papers",
    "href": "publication.html#working-papers",
    "title": "Publications / Working Papers",
    "section": "Working Papers",
    "text": "Working Papers\n\nSocietal Impacts of Information Systems\n\nJu, S. (2023), How does public information systems affects improving internet accessibility of students (Literature Review)\n\nEvidence-Based Policy and Management\n\nJu, S. & Lee, J., Kim, B.J. (2022), Evidence-Based Policy in Asian Countries: Applying Model of Evidence-Based Practice Implementation for Maturation Stage Analysis [in Korean]. (Analysis / Writing Finished, Target Journal: Korean Public Administration Review)\n\nOrganizational Decision-making\n\nJu, S. (2023), Blame Avoidance and Research Utilization: Evidence From Korean Public Enterprises (Literature Review)"
  },
  {
    "objectID": "publication.html#academic-presentations",
    "href": "publication.html#academic-presentations",
    "title": "Publications / Working Papers",
    "section": "Academic Presentations",
    "text": "Academic Presentations\n\nJu, S. & Lee, J. (2022), Evidence-Based Policy in Asian Countries: Applying Model of Evidence-Based Practice Implementation for Maturation Stage Analysis [in Korean, Poster Session], 2022 Korean Public Administration Summer Conference and Annual KAPA International Conference, Yeosu, Korea, June 2022."
  },
  {
    "objectID": "research_interests.html",
    "href": "research_interests.html",
    "title": "Research Interests",
    "section": "",
    "text": "(0) policy analysis and program evaluation\n(1) management information systems\n\nquantifying societal impact of information systems\n\n(2) evidence-based public policy and management (EBPPM)\n\nbeing evidence-based is being data-driven?\nwhat is the difference between evidence-based approach and contemporary policy analysis? (such as discourse policy analysis)\nPositivist vs. Constructivist\n\n(3) organization theory and behavior\n\nStrategic decision-making\nhuman-machine cooperation in organization decision-making.\n\n\nMethodologically, I’m interested in applied econometrics for quasi-experimental approach, machine-learning as well as other computational methods for both business and public data analytics, and applied psychology survey analysis. Also I have prior experience in policy analysis techniques (such as Cost-Benefit Analysis, Analytic Hierarchy Process etc.)"
  },
  {
    "objectID": "data_analytics/FWA.html#텍스트-마이닝을-활용한-빅데이터-텍스트-분석",
    "href": "data_analytics/FWA.html#텍스트-마이닝을-활용한-빅데이터-텍스트-분석",
    "title": "Sangwon Ju's Personal Page",
    "section": "- 텍스트 마이닝을 활용한 빅데이터 텍스트 분석",
    "text": "- 텍스트 마이닝을 활용한 빅데이터 텍스트 분석\n\n기술통계 분석\n1. 빈도표 계산 및 말뭉치 등을 활용한 시각화 단어가 몇번 출현했는 지수(Count)를 기반으로 하여 텍스트를 표현 - BoW: 단어의 순서를 고려하지 않고 단어 출현 빈도에만 집중 - DTM (Document-Term Matrix): 문서단어행렬, 다수의 문서에서 등장하는 단어들의 빈도를 행렬로 표현하는 방식 - TF-IDF (Term Frequency - Inverse Document Frequency): 단어 빈도 - 역 문서 빈도  총 문서 수 대비 적게 등장한 단어가 중요한 단어  특정 문서 안에서 많이 등장한다고 해도 중요도가 올라가지는 않음  > TF: 특정 문서 D에서 특정 단어 T의 등장 횟수  DF: 특정 단어 T가 등장한 문서의 수  IDF: DF에 반비례 하는 수. ln(총문서수/(DF))  TF-IDF: TF * IDF 희귀하면서도 특정 텍스트에서 자주 사용된 단어 (TF)는 그 텍스트에서 중요함 2. 단어간 혹은 기사간 상관관계 - 동시 출현(Co-Occurrence) 단어 분석 문장 혹은 기사에 함께 사용된 단어는 어떤 단어일지 분석하는 것. 단어의 “맥락”을 파악하기 위하여 어떤 단어들이 함께 쓰였는지를 알아야 함. 의미를 가진 단어(명사, 동사, 형용사)등을 추출하여 어떤 단어들이 함께 빈번하게 쓰였는지 분석해보는게 필요함. 3. 연관 규칙 분석 (Association Rules) - 장바구니 분석 Apriori Algorithm(Agrawal et al., 1993): 어떤 단어가 다른 단어들과의 연관규칙을 가지는지를 추출 하는 방식\n\n\n토픽 모델링\n토픽 모델링은 문서와 단어로 구성된 행렬(DTM)을 기반으로 문서에 잠재되어 (Latent)있다고 가정된 토픽의 등장확률을 추정하는 일련의 통계적 텍스트 처리기법을 일컫는다. (Blei, 2014; Blei and Lafferty, 2007;Blei, Ng and Jordan, 2003) DTM을 활용하여 주제-확률 분포, 단어-확률 분포를 구한뒤 잠재 주제를 찾는 LDA나 Singular Value Decomposition을 통해 차원 축소를 하는 방법이 있다.\n\n\nLDA(Latent Dirichlet Allocation): 이 문서에서는 어떤 주제들이 오가고 있을까?  PLSA를 조건부 확률로 확장시킨 기법으로 잠재 주제의 확률적 분포에 대한 PLSA의 한계점을 보완한 모델이다. LDA모델은 무작위로 섞여있는 대량의 문서에서 단어들의 패턴을 추론하여 각 토픽의 특성을 도출하는데 용이하며, 텍스트 데이터의 의미구조를 파악하기에 적합한 방법 중 하나이다.  한 문서는 여러가지 토픽으로 이루어지고, 토픽은 여러 단어를 혼합하여 구성된다.   1개의 토픽은 여러 단어(서로 다른 확률을 가진)로 구성. 1개의 단어는 여러 토픽에서 서로 다른 확률을 가짐.  delta는 문장이 각 토픽에 등장할 확률, beta는 단어가 각 토픽에 등장할 확률\n\nfyi) 디리클레 분포(Dirichlet distribution):  베타분포를 다변량으로 확장한 것으로 다변량 베타분포라고 볼 수 있음. (K가 2일때 베타분포) LDA 토픽 모델링으로 예를 들면, 한 문서에 대한 토픽의 분포는 k개의 토픽의 확률 (\\(p_k\\))로 표현할 수 있음.  문서에서 각 단어에 대한 토픽을 샘플을 할때 이 토픽의 분포는 Multinomial 분포를 가정하게 됨. dirichlet 분포의 샘플링 된 k차원 벡터는 합이 1을 만족하기 때문에, multinomial 분포의 모수(\\(p_k\\))에 사용될 수 있음 -> 분포의 분포를 표현.\n\\[f(x_1, x_2, \\cdots, x_K) = \\frac{1}{\\mathrm{B}(\\boldsymbol\\alpha)} \\prod_{i=1}^K x_i^{\\alpha_i - 1} \\]\n\\[ \\mathrm{B}(\\boldsymbol\\alpha) = \\frac{\\prod_{i=1}^K \\Gamma(\\alpha_i)} {\\Gamma\\bigl(\\sum_{i=1}^K \\alpha_i\\bigr)}\\]\n제한조건: \\[ \\sum_{i=1}^{K} x_i = 1 \\]\nhttps://donghwa-kim.github.io/distributions.html (참고)"
  },
  {
    "objectID": "data_analytics/FWA.html#자료수집",
    "href": "data_analytics/FWA.html#자료수집",
    "title": "Sangwon Ju's Personal Page",
    "section": "자료수집 ",
    "text": "자료수집 \n우리나라 COVID-19 최초 발생월인 2020년 2월부터 2021년 12월까지의 ‘유연근무’혹은 ’탄력근무’ 혹은 ’원격근무’를 포함하고 있는 정치부, 사회부 언론기사 제목 11,334건을 한국언론진흥재단(BIGKINDS)에서 수집. (경제부 기사들은 특정기업이 유연근무를 사용하기 시작하였음을 홍보하는 기사들이 많아 제외하였음)\n\na. 데이터 불러오기\nworksheet = gc.open('NewsResult_20200201-20211202 (1)').sheet1\nrows = worksheet.get_all_values()\nbigkinds=pd.DataFrame.from_records(rows)\nbigkinds.columns=bigkinds.iloc[0]\nbigkinds=bigkinds.drop(bigkinds.index[0])\n\nimport pandas_profiling\nbigkinds.profile_report()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb. 기술 통계 분석\n\n시기 별 기사의 수\n\n\nfrom datetime import datetime \nnumber=bigkinds >> group_by(X.일자) >> summarize(count=n(X.일자))\nnumber.head(10)\n\n\n\n\n\n  \n    \n      \n      일자\n      count\n    \n  \n  \n    \n      0\n      20200201\n      1\n    \n    \n      1\n      20200202\n      1\n    \n    \n      2\n      20200203\n      5\n    \n    \n      3\n      20200204\n      8\n    \n    \n      4\n      20200205\n      7\n    \n    \n      5\n      20200206\n      48\n    \n    \n      6\n      20200207\n      15\n    \n    \n      7\n      20200208\n      2\n    \n    \n      8\n      20200209\n      3\n    \n    \n      9\n      20200210\n      3\n    \n  \n\n\n\n\n# list 내포\nkdate = [ datetime.strptime(d, '%Y%m%d') for d in number[\"일자\"] ]\n\nhead(kdate)\nnumber['date'] = kdate\nkdate1 = [datetime.strftime(d, '%Y%m') for d in number[\"date\"] ]\n\nnumber['date1'] = kdate1\nnumber.head(10)\nnumber2=number[number.일자.astype(\"int64\")<20211131] >> select([\"date1\",\"count\"])  >> rename(num=\"count\") >> group_by('date1') >> summarise(num=X.num.sum())\n\nfig=plt.figure(figsize = (10,7))\n\nplt.plot(number[\"date\"], number[\"count\"],color='blue', label=str(\"기사\"))\nplt.title(\"일별 유연근무제 관련 기사 수\",fontsize=20)\nplt.style.use(\"default\")\nplt.rc('font', family='NanumBarunGothic') \n\nplt.legend(fontsize=20)\nplt.xticks(rotation=75,fontsize=10)\nplt.yticks(fontsize=10)\n\nax = fig.add_subplot(1, 1, 1)\nax.set_xlabel(\"일별\", fontsize=\"15\")\nax.set_ylabel(\"기사 건수\", fontsize=\"15\")\nplt.show()\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n  if sys.path[0] == '':\n\n\n\n\n\n\nfig2=plt.figure(figsize = (10,7))\nax = fig2.add_subplot(1, 1, 1)\nax.set_xlabel(\"기사 건수\", fontsize=\"15\")\nax.set_ylabel(\"월별\", fontsize=\"15\")\n\nplt.plot(number2[\"date1\"], number2[\"num\"],color='red', label=str(\"기사\"))\nplt.title(\"월별 유연근무제 관련 기사 수\",fontsize=20)\nplt.style.use(\"default\")\nplt.rc('font', family='NanumBarunGothic') \n\nplt.legend(fontsize=20)\nplt.xticks(rotation=75,fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()\n\n\n\n\n\n텍스트 전처리\n\n\n# 토큰화\narticle=bigkinds >> select(\"제목\") >> rename(title=\"제목\")\nprint(article[\"title\"].head(10))\narticle[\"title\"]=article[\"title\"].astype(str)\narticle.shape #11334개의 기사\n\n1                                     동화약품, 가족친화 기업 재인증\n2               집단감염 취약한 콜센터 찾은 안경덕 고용부 장관 \"방역수칙 준수\" 당부\n3                  환풍기 타고 확산? 전파력 5배 오미크론, 재택치료 빈틈 파고드나\n4                                 [팀장시각]서로 위로하는 코로나 분투기\n5                        새 판 짜는 완성차 노조 MZ세대 품을까 [비즈360]\n6                           “재택치료? 가족들 번갈아가며 확진되란 건가요?”\n7                    5000명대 확진에 자영업자들 “다시 거리두기 격상되나” 한숨\n8                   전면등교 후 인천 학생 자가격리자 5천명 폭등 돌봄공백 '비상'\n9     \"가구를 통해 건강한 세상 만들겠다\" 유해물질 소음 진동 걱정없는 책상 [환경표지 ...\n10               김인호 서울시의회 의장, 코로나 확산세 관련 서울시에 적극 대응 요청\nName: title, dtype: object\n\n\n(11334, 1)\n\n\ndef text_preprocess(text):\n    \"\"\"\n    텍스트 전처리\n    1. span tag 삭재\n    2. br tag 삭제\n    3. 영어, 한글, 숫자, 온점 제외 삭제\n    4. 온점을 구분으로 문장 구분\n    \"\"\"\n    text = re.sub(\"(<span class='quot[0-9]'>|</span>|<br/>|<br />|([^0-9가-힣A-Za-z. ]))\",\"\",text)\n    return [sen.strip() for sen in text.split('.') if sen.strip()]\ndf = pd.DataFrame(index=np.arange(1,article.shape[0]+1), columns=['title'])\n# 정규표현식으로 불필요한 부분 제거\nfor i in np.arange(1,article.shape[0]+1):\n  df[\"title\"][i]=text_preprocess(article[\"title\"][i])\n\ndf\n\n\n\n\n\n  \n    \n      \n      title\n    \n  \n  \n    \n      1\n      [동화약품 가족친화 기업 재인증]\n    \n    \n      2\n      [집단감염 취약한 콜센터 찾은 안경덕 고용부 장관 방역수칙 준수 당부]\n    \n    \n      3\n      [환풍기 타고 확산 전파력 5배 오미크론 재택치료 빈틈 파고드나]\n    \n    \n      4\n      [팀장시각서로 위로하는 코로나 분투기]\n    \n    \n      5\n      [새 판 짜는 완성차 노조 MZ세대 품을까 비즈360]\n    \n    \n      ...\n      ...\n    \n    \n      11330\n      [정부 신종코로나 사망자 치사율 축소 논란 글로벌 대유행 가능성도]\n    \n    \n      11331\n      [신종코로나 확산 사태로 가장 먼저 재택근무 시행하는 업계는]\n    \n    \n      11332\n      [지옥철서 신종코로나 옮길라 문지방 출퇴근 지시한 제약회사]\n    \n    \n      11333\n      [여주시 신종 코로나 선제적 대응위해 보건소 선별진료소 운영]\n    \n    \n      11334\n      [태안군 6번 확진자 접촉 관내 2인 음성 판정]\n    \n  \n\n11334 rows × 1 columns\n\n\n\nsentence_arr = []\nfor i in np.arange(1,article.shape[0]):\n    text=df.title[i][0] \n    sentence_arr.insert(0,text)\n\npprint.pprint(sentence_arr[1:10])\n\n['지옥철서 신종코로나 옮길라 문지방 출퇴근 지시한 제약회사',\n '신종코로나 확산 사태로 가장 먼저 재택근무 시행하는 업계는',\n '정부 신종코로나 사망자 치사율 축소 논란 글로벌 대유행 가능성도',\n '경찰인재개발원 필수 인력만 남고 근무 장소 변경 허용',\n '격리 시설 직원들 하소연 유치원서 자녀 보내지 말라네요',\n '오늘은 이런 경향2월4일 재탕 후퇴 미흡  20대 총선보다 부실한 주거공약',\n '신종 코로나 16번째 확진자 발생 태국 여행한 42세 한국인 여성',\n '신종 코로나 확진 1명 추가 태국 여행 뒤 증상 발현',\n '우한 폐렴 비상오락가락하는 정부 기준 자가격리도 잇단 혼선']\n\n\ncheck = ['탄력', '재택', '유연']\nmatching1 = [s for s in sentence_arr if \"유연\" in s] \nmatching2 = [s for s in sentence_arr if \"재택\" in s] \nmatching3 = [s for s in sentence_arr if \"탄력\" in s] \nmatching =matching1 + matching2 + matching3 \nmatching=list(set(matching))\n\nprint(len(matching))\ntype(matching)\n# 1226개의 기사 제목\n\n1226\n\n\nlist\n\n\n한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소(morpheme) 단위로 형태소 토큰화(morpheme tokenization)를 수행하게 됨을 뜻한다. 여기선 이 중에서 Okt와 꼬꼬마를 통해서 토큰화를 수행한다.  참고: https://wikidocs.net/21698\nfrom konlpy.tag import *\nkkma = Kkma()  \nokt = Okt()  \n\nOKT\n\nokt_list=[]\nfor title in matching:\n  tokenized3=okt.pos(title)\n  okt_list.insert(len(okt_list)+1,tokenized3)\n\nokt_list[:3]\n\n[[('코로나', 'Noun'),\n  ('19', 'Number'),\n  ('우려', 'Noun'),\n  ('에', 'Josa'),\n  ('유엔', 'Noun'),\n  ('본부', 'Noun'),\n  ('직원', 'Noun'),\n  ('3000', 'Number'),\n  ('명', 'Noun'),\n  ('3', 'Number'),\n  ('주간', 'Noun'),\n  ('재택근무', 'Noun'),\n  ('돌입', 'Noun')],\n [('재택근무', 'Noun'),\n  ('중', 'Noun'),\n  ('아이', 'Noun'),\n  ('도', 'Josa'),\n  ('보육', 'Noun'),\n  ('하', 'Suffix'),\n  ('라', 'Josa'),\n  ('고요', 'Noun'),\n  ('긴급', 'Noun'),\n  ('보육', 'Noun'),\n  ('청원', 'Noun'),\n  ('갑론', 'Noun'),\n  ('을', 'Josa'),\n  ('박', 'Noun')],\n [('KBS', 'Alpha'),\n  ('본관', 'Noun'),\n  ('3', 'Number'),\n  ('층', 'Noun'),\n  ('직원', 'Noun'),\n  ('1', 'Number'),\n  ('명', 'Noun'),\n  ('확진', 'Noun'),\n  ('필수', 'Noun'),\n  ('인력', 'Noun'),\n  ('제외', 'Noun'),\n  ('재택근무', 'Noun')]]\n\n\nokt_morphs_list=[]\nfor title in matching:\n  tokenized4=okt.morphs(title)\n  okt_morphs_list.insert(len(okt_morphs_list)+1,tokenized4)\n\nokt_morphs_list[:3]\n\n[['코로나',\n  '19',\n  '우려',\n  '에',\n  '유엔',\n  '본부',\n  '직원',\n  '3000',\n  '명',\n  '3',\n  '주간',\n  '재택근무',\n  '돌입'],\n ['재택근무',\n  '중',\n  '아이',\n  '도',\n  '보육',\n  '하',\n  '라',\n  '고요',\n  '긴급',\n  '보육',\n  '청원',\n  '갑론',\n  '을',\n  '박'],\n ['KBS', '본관', '3', '층', '직원', '1', '명', '확진', '필수', '인력', '제외', '재택근무']]\n\n\n\n꼬꼬마\n\nkkma_list=[]\nfor title in matching:\n  tokenized=kkma.pos(title)\n  kkma_list.insert(len(kkma_list)+1,tokenized)\n\nkkma_list[:5]\n\n[[('코로나', 'NNG'),\n  ('19', 'NR'),\n  ('우려', 'NNG'),\n  ('에', 'JKM'),\n  ('유엔', 'NNG'),\n  ('본부', 'NNG'),\n  ('직원', 'NNG'),\n  ('3000', 'NR'),\n  ('명', 'NNM'),\n  ('3', 'NR'),\n  ('주간', 'NNG'),\n  ('재택근무', 'NNG'),\n  ('돌입', 'NNG')],\n [('재택근무', 'NNG'),\n  ('중', 'NNB'),\n  ('아이', 'NNG'),\n  ('도', 'JX'),\n  ('보육', 'NNG'),\n  ('하', 'XSV'),\n  ('라', 'ECD'),\n  ('고요', 'NNG'),\n  ('긴급', 'NNG'),\n  ('보육', 'NNG'),\n  ('청원', 'NNG'),\n  ('갑론을박', 'NNG')],\n [('KBS', 'OL'),\n  ('본관', 'NNG'),\n  ('3', 'NR'),\n  ('층', 'NNG'),\n  ('직원', 'NNG'),\n  ('1', 'NR'),\n  ('명', 'NNM'),\n  ('확', 'MAG'),\n  ('질', 'VV'),\n  ('ㄴ', 'ETD'),\n  ('필수', 'NNG'),\n  ('인력', 'NNG'),\n  ('제외', 'NNG'),\n  ('재택근무', 'NNG')],\n [('서울', 'NNG'),\n  ('LS', 'OL'),\n  ('용', 'NNG'),\n  ('산', 'NNG'),\n  ('타워', 'NNG'),\n  ('직장인', 'NNG'),\n  ('확', 'MAG'),\n  ('진', 'NNG'),\n  ('판정', 'NNG'),\n  ('임직원', 'NNG'),\n  ('재택근무', 'NNG')],\n [('코로나', 'NNG'),\n  ('시대', 'NNG'),\n  ('재택근무', 'NNG'),\n  ('개인', 'NNG'),\n  ('시간', 'NNG'),\n  ('늘', 'VV'),\n  ('었', 'EPT'),\n  ('지만', 'ECE'),\n  ('일', 'NNG'),\n  ('생활', 'NNG'),\n  ('분리', 'NNG'),\n  ('어렵', 'VV'),\n  ('어', 'ECS')]]\n\n\nkkma_morphs_list=[]\nfor title in matching:\n  tokenized1=kkma.morphs(title)\n  kkma_morphs_list.insert(len(kkma_morphs_list)+1,tokenized1)\n\nkkma_morphs_list[:5]\n\n[['코로나',\n  '19',\n  '우려',\n  '에',\n  '유엔',\n  '본부',\n  '직원',\n  '3000',\n  '명',\n  '3',\n  '주간',\n  '재택근무',\n  '돌입'],\n ['재택근무', '중', '아이', '도', '보육', '하', '라', '고요', '긴급', '보육', '청원', '갑론을박'],\n ['KBS',\n  '본관',\n  '3',\n  '층',\n  '직원',\n  '1',\n  '명',\n  '확',\n  '질',\n  'ㄴ',\n  '필수',\n  '인력',\n  '제외',\n  '재택근무'],\n ['서울', 'LS', '용', '산', '타워', '직장인', '확', '진', '판정', '임직원', '재택근무'],\n ['코로나', '시대', '재택근무', '개인', '시간', '늘', '었', '지만', '일', '생활', '분리', '어렵', '어']]\n\n\n딱히 차이가 없으므로 OKT로만 분석 진행.|\n\n불용어 제거  불용어 리스트: https://www.ranks.nl/stopwords/korean\n\nworksheet2 = gc.open('stopwords').sheet1\nrows2 = worksheet2.get_all_values()\nstopwords=pd.DataFrame.from_records(rows2)\nstopwords=pd.Series.tolist(stopwords[0])\nokt_morphs_list_stop=[]\nfor words in okt_morphs_list:\n  tokenized=[]\n  for word in words:\n    if not word in stopwords:\n      tokenized.insert(len(tokenized)+1,word)\n  okt_morphs_list_stop.insert(len(okt_morphs_list_stop)+1,tokenized)\n\nokt_morphs_list_stop[:5]\n\n[['코로나', '19', '우려', '유엔', '본부', '직원', '3000', '명', '3', '주간', '재택근무', '돌입'],\n ['재택근무', '중', '도', '보육', '라', '고요', '긴급', '보육', '청원', '갑론', '박'],\n ['KBS', '본관', '3', '층', '직원', '1', '명', '확진', '필수', '인력', '제외', '재택근무'],\n ['서울', 'LS', '용산', '타워', '직장인', '확진', '판정', '임', '직원', '재택근무'],\n ['코로나', '시대', '재택근무', '개인', '늘었지만', '생활', '분리', '어려워']]\n\n\nkkma_morphs_list_stop=[]\nfor words in kkma_morphs_list:\n  tokenized=[]\n  for word in words:\n    if not word in stopwords:\n      tokenized.insert(len(tokenized)+1,word)\n  kkma_morphs_list_stop.insert(len(kkma_morphs_list_stop)+1,tokenized)\n\nkkma_morphs_list_stop[:5]\n\n[['코로나', '19', '우려', '유엔', '본부', '직원', '3000', '명', '3', '주간', '재택근무', '돌입'],\n ['재택근무', '중', '도', '보육', '라', '고요', '긴급', '보육', '청원', '갑론을박'],\n ['KBS',\n  '본관',\n  '3',\n  '층',\n  '직원',\n  '1',\n  '명',\n  '확',\n  '질',\n  'ㄴ',\n  '필수',\n  '인력',\n  '제외',\n  '재택근무'],\n ['서울', 'LS', '용', '산', '타워', '직장인', '확', '진', '판정', '임직원', '재택근무'],\n ['코로나', '시대', '재택근무', '개인', '늘', '었', '생활', '분리', '어렵']]\n\n\n\nWord Cloud\n\nfrom wordcloud import WordCloud, STOPWORDS\nimport nltk as nltk\ntotal_okt= []\nfor element in okt_morphs_list_stop:\n  total_okt+=element\ntotal_okt_over2=pd.Series(total_okt)[pd.Series(total_okt).str.len()>=2]\ncount_okt=pd.DataFrame(total_okt).value_counts().rename_axis('unique_values').reset_index(name='counts')\ncount_okt.columns=[\"word\",\"counts\"]\n\ncount_okt2=count_okt >> mask(X.word.str.len() >=2)\ncount_okt2=count_okt2.reset_index().iloc[:,1:]\ncount_okt2.head(60)\n\n\n\n\n\n  \n    \n      \n      word\n      counts\n    \n  \n  \n    \n      0\n      재택근무\n      968\n    \n    \n      1\n      코로나\n      365\n    \n    \n      2\n      19\n      191\n    \n    \n      3\n      재택\n      163\n    \n    \n      4\n      직원\n      148\n    \n    \n      5\n      확산\n      86\n    \n    \n      6\n      근무\n      85\n    \n    \n      7\n      기업\n      83\n    \n    \n      8\n      확진\n      75\n    \n    \n      9\n      출근\n      57\n    \n    \n      10\n      확대\n      53\n    \n    \n      11\n      시행\n      46\n    \n    \n      12\n      진자\n      41\n    \n    \n      13\n      유연근무제\n      41\n    \n    \n      14\n      유연\n      41\n    \n    \n      15\n      직장\n      40\n    \n    \n      16\n      콜센터\n      40\n    \n    \n      17\n      공무원\n      38\n    \n    \n      18\n      연장\n      38\n    \n    \n      19\n      실시\n      34\n    \n    \n      20\n      거리\n      33\n    \n    \n      21\n      감염\n      33\n    \n    \n      22\n      전환\n      33\n    \n    \n      23\n      정부\n      32\n    \n    \n      24\n      포스코\n      32\n    \n    \n      25\n      두기\n      31\n    \n    \n      26\n      공공기관\n      31\n    \n    \n      27\n      권고\n      30\n    \n    \n      28\n      도입\n      30\n    \n    \n      29\n      폐쇄\n      30\n    \n    \n      30\n      직장인\n      29\n    \n    \n      31\n      단계\n      28\n    \n    \n      32\n      회식\n      27\n    \n    \n      33\n      회사\n      27\n    \n    \n      34\n      삼성\n      27\n    \n    \n      35\n      출퇴근\n      27\n    \n    \n      36\n      돌입\n      26\n    \n    \n      37\n      해야\n      26\n    \n    \n      38\n      LG\n      26\n    \n    \n      39\n      사업\n      25\n    \n    \n      40\n      국회\n      25\n    \n    \n      41\n      하는\n      25\n    \n    \n      42\n      서울\n      24\n    \n    \n      43\n      대응\n      23\n    \n    \n      44\n      금지\n      23\n    \n    \n      45\n      비상\n      23\n    \n    \n      46\n      분산\n      22\n    \n    \n      47\n      그룹\n      21\n    \n    \n      48\n      방역\n      20\n    \n    \n      49\n      지원\n      20\n    \n    \n      50\n      에도\n      20\n    \n    \n      51\n      활용\n      20\n    \n    \n      52\n      전원\n      19\n    \n    \n      53\n      강화\n      19\n    \n    \n      54\n      업무\n      19\n    \n    \n      55\n      임산부\n      19\n    \n    \n      56\n      본사\n      19\n    \n    \n      57\n      KT\n      19\n    \n    \n      58\n      신청\n      18\n    \n    \n      59\n      비대\n      18\n    \n  \n\n\n\n\ntotal_okt_over2 # 9467개\ntotal_okt_over3=[]\nfor element in total_okt_over2:\n  if element not in [\"재택근무\",\"유연근무제\",\"19\",\"재택\",\"해야\",\"진자\",\"비대\"]:\n    total_okt_over3.insert(0,element)\n\noktplot=nltk.Text(total_okt_over3,name=\"Test\")\nfig=plt.figure(figsize = (10,5))\nax = fig.add_subplot(1, 1, 1)\nplt.title(\"키워드 빈도별 그래프\",fontsize=20)\noktplot.plot(50)\nplt.show(ax)\n\n\n\n\n\ndata=oktplot.vocab().most_common(50)\nplt.figure(figsize = (10,5))\npath=\"/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\"\nwc=WordCloud(font_path=path,relative_scaling=0.2,background_color=\"white\",width=1200, height=800).generate_from_frequencies(dict(data))\n\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()\n\n\n\n\n\n분석의 문제점  제목기반 분석이라 의미있는 내용을 뽑아낼 수 없었음. 맥락이 제거된 빈도기반 분석으로 어떤 맥락에서 사용되었는지 알수가 없었음. 의미있는 인사이트를 찾을수는 없었으나 공무원, 공공기관, 포스코, LG 등 공공영역이나 대기업 위주로 유연근무제가 시행된다는 사실을 확인할 수 있었음. 콜센터와 같은 밀집된 곳에서 시행하는 업무의 경우, 유연근무제를 통해 감염을 확산을 저지하려는 시도가 있었지 않았나 추측해 보았음.\nTF-IDF\n\nfrom collections import defaultdict\n\nvectorizer = TfidfVectorizer()\ntdm = vectorizer.fit_transform(sentence_arr)\n\nword_count = pd.DataFrame({\n    '단어': vectorizer.get_feature_names(),\n    '빈도': tdm.sum(axis=0).flat\n})\n\n/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n\n\n\nword_count.sort_values(\"빈도\",ascending=False).reset_index(drop=True).head(30)\n\n\n\n\n\n  \n    \n      \n      단어\n      빈도\n    \n  \n  \n    \n      0\n      코로나19\n      248.149943\n    \n    \n      1\n      코로나\n      225.877234\n    \n    \n      2\n      확진\n      189.862035\n    \n    \n      3\n      재택근무\n      166.912066\n    \n    \n      4\n      확진자\n      141.297835\n    \n    \n      5\n      거리두기\n      134.722720\n    \n    \n      6\n      직원\n      116.244045\n    \n    \n      7\n      폐쇄\n      82.505198\n    \n    \n      8\n      수도권\n      79.311515\n    \n    \n      9\n      사회적\n      77.250924\n    \n    \n      10\n      방역\n      64.115543\n    \n    \n      11\n      콜센터\n      63.758580\n    \n    \n      12\n      감염\n      60.624583\n    \n    \n      13\n      발생\n      59.834789\n    \n    \n      14\n      3단계\n      54.067897\n    \n    \n      15\n      정부\n      53.735398\n    \n    \n      16\n      확산\n      51.893703\n    \n    \n      17\n      서울\n      51.615911\n    \n    \n      18\n      비상\n      48.585535\n    \n    \n      19\n      1명\n      47.710836\n    \n    \n      20\n      국회\n      45.337426\n    \n    \n      21\n      백신\n      44.223253\n    \n    \n      22\n      신규\n      43.779173\n    \n    \n      23\n      추가\n      43.749493\n    \n    \n      24\n      집단감염\n      43.617216\n    \n    \n      25\n      검사\n      40.211961\n    \n    \n      26\n      마스크\n      38.943360\n    \n    \n      27\n      음성\n      37.046574\n    \n    \n      28\n      격상\n      35.974340\n    \n    \n      29\n      재택\n      35.499295\n    \n  \n\n\n\n\n\n\nc. 동시 출현(Co-Occurrence) \n참고: https://bab2min.tistory.com/598\n# 2글자 이상의 단어로 한정 / 의미없는 숫자 제거\ncooccur=[]\nfor elements in okt_morphs_list_stop:\n  new_elements=[]\n  for i in elements:\n    if i not in [\"재택근무\",\"유연\"]:\n      text = re.sub(r'[a-zA-Z0-9]',' ',i).strip()\n      if len(text)>=2:\n        new_elements.append(text)\n  cooccur.append(new_elements)\ncount = {}   #동시출현 빈도가 저장될 dict\nfor line in cooccur:\n    words = line \n    for i, a in enumerate(words):\n        for b in words[i+1:]:\n            if a == b: continue   #같은 단어의 경우는 세지 않음\n            if a > b: \n              a, b = b, a   #A, B와 B, A가 다르게 세어지는것을 막기 위해 항상 a < b로 순서 고정\n            count[a, b] = count.get((a, b), 0) + 1   #실제로 센다\ndef dict_to_df(df):\n        data_df = pd.DataFrame({'keys': df.keys(), 'features': df.values()})\n        data_df['word1'] = data_df['keys'].apply(lambda x: x[0])\n        data_df['word2'] = data_df['keys'].apply(lambda x: x[1])\n        return data_df[['word1','word2','features']]\n\ncooccur_df.sort_values(\"features\",ascending=False).head(10)\n\n\n\n\n\n  \n    \n      \n      word1\n      word2\n      features\n    \n  \n  \n    \n      884\n      거리\n      두기\n      89\n    \n    \n      98\n      코로나\n      확산\n      62\n    \n    \n      24\n      직원\n      확진\n      52\n    \n    \n      65\n      근무\n      재택\n      46\n    \n    \n      94\n      근무\n      유연\n      39\n    \n    \n      770\n      직원\n      코로나\n      36\n    \n    \n      174\n      코로나\n      확진\n      34\n    \n    \n      585\n      근무\n      분산\n      32\n    \n    \n      1238\n      건물\n      폐쇄\n      30\n    \n    \n      745\n      감염\n      직원\n      27\n    \n  \n\n\n\n\n\ncooccur_df=dict_to_df(count)\ncooccur_df.features.describe()\n\ncount    9559.000000\nmean        2.456219\nstd         2.635716\nmin         1.000000\n25%         1.000000\n50%         2.000000\n75%         3.000000\nmax        89.000000\nName: features, dtype: float64\n\n\n\n\nd. 네트워크 그래프\nimport networkx as nx\nimport operator\nimport matplotlib.colors as mcolors\nimport matplotlib.cm as cm\ncooccur_df_major=cooccur_df >> mask(X.features>=13)\n\n# generate sample graph\nplt.figure(figsize = (9,9),facecolor='k')\nplt.rcParams['font.sans-serif'] = ['NanumBarunGothic'] \ng = nx.from_pandas_edgelist(cooccur_df_major, 'word1', 'word2')\n\n\n# centrality\ndeg_centrality = nx.degree_centrality(g)\ncentrality = np.fromiter(deg_centrality.values(), float)\n# plot\npos = nx.kamada_kawai_layout(g,scale=3)\nnx.draw(g, pos, node_color=centrality,with_labels=True)\nplt.title(\"유연근무제 기사제목 분석\",size=15)\nplt.cool()\n\n\nsizes = centrality / np.max(centrality) * 200\nnormalize = mcolors.Normalize(vmin=centrality.min(), vmax=centrality.max())\ncolormap = cm.cool\n\nscalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\nscalarmappaple.set_array(centrality)\n\nplt.colorbar(scalarmappaple,shrink=0.3)\n\nplt.show()\n\n\n\n\n\n\n\ndef dict_to_df_1(df):\n        data_df = pd.DataFrame({'keys': df.keys(), 'features': df.values()})\n        data_df['word1'] = data_df['keys']\n        return data_df[['word1','features']]\n\ndict_to_df_1(deg_centrality).sort_values(\"features\",ascending=False)[1:20]\n\n\n\n\n\n  \n    \n      \n      word1\n      features\n    \n  \n  \n    \n      5\n      코로나\n      0.101266\n    \n    \n      10\n      기업\n      0.088608\n    \n    \n      34\n      본사\n      0.075949\n    \n    \n      44\n      경력\n      0.075949\n    \n    \n      6\n      근무\n      0.075949\n    \n    \n      1\n      확진\n      0.050633\n    \n    \n      48\n      금지\n      0.050633\n    \n    \n      57\n      단계\n      0.037975\n    \n    \n      7\n      재택\n      0.037975\n    \n    \n      16\n      시행\n      0.037975\n    \n    \n      36\n      거리\n      0.037975\n    \n    \n      18\n      아기\n      0.037975\n    \n    \n      73\n      국회\n      0.037975\n    \n    \n      33\n      감염\n      0.037975\n    \n    \n      55\n      구로\n      0.025316\n    \n    \n      26\n      전환\n      0.025316\n    \n    \n      66\n      구글\n      0.025316\n    \n    \n      42\n      시차\n      0.025316\n    \n    \n      41\n      폐쇄\n      0.025316"
  },
  {
    "objectID": "data_analytics/FWA.html#분석-실패-요인-및-느낀점",
    "href": "data_analytics/FWA.html#분석-실패-요인-및-느낀점",
    "title": "Sangwon Ju's Personal Page",
    "section": "분석 실패 요인 및 느낀점",
    "text": "분석 실패 요인 및 느낀점\n\n(진행하더라도 유의미한 분석결과가 나오지 않을 것으로 예상되어) 토픽 모델링은 진행하지 않았음\n빈도기반 텍스트 마이닝 분석은 그러한 단어가 어떤 맥락에서 형성되었는지 알 수 없고 어떠한 의미를 가지는지를 이해하는데 있어서 어려움이 있다.\n신문 기사 제목들이 서로 응집성을 가지지 않고 산발적으로 나타나는 경우가 다수였기 때문에 적절한 분석이 진행되지 못한 것으로 보임.\n이후 보다 의미있는 분석을 위해서는 신문 기사 내용들을 활용을 하거나, 다른 텍스트 원천을 활용하는 것이 보다 효과적인 분석에 있어서 필요할 것으로 보임."
  },
  {
    "objectID": "data_analytics/FWA.html#경제활동인구조사-20152021",
    "href": "data_analytics/FWA.html#경제활동인구조사-20152021",
    "title": "Sangwon Ju's Personal Page",
    "section": "1. 경제활동인구조사 (2015~2021) ",
    "text": "1. 경제활동인구조사 (2015~2021) \n\n\n경제활동인구조사: 통계종류지정통계/조사통계 -계속여부: 계속통계 -작성목적: 국민의 경제활동(취업, 실업, 노동력 등) 특성을 조사함으로써 거시경제 -분석과 인력자원의 개발정책 수립에 필요한 기초 자료를 제공 -작성주기:월  -작성체계: 조사원(면접조사)→지방통계청(사무소)→통계청  -공표범위: 시도 -공표주기: 월 -특이점: 2017년 9월 조사부터 복수응답가능\n\n\nfrom mizani.breaks import date_breaks, minor_breaks\nfrom mizani.formatters import date_format\nimport matplotlib.font_manager as fm\npath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' \nfont = fm.FontProperties(fname=path, size=13)\n\na. 유연근무제 활용여부\nyes=pd.read_json(\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7099S/2/1/20211204112805_1&prdSe=M&startPrdDe=201508&endPrdDe=202108\")\nno=pd.read_json(\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7099S/2/1/20211204112931_1&prdSe=M&startPrdDe=201508&endPrdDe=202108\")\npj_usege=yes >> bind_rows(no, join='outer') >> select(X.PRD_DE,X.C1_NM,X.DT)\npj_usege=pj_usege.reset_index(drop=True)\n\nplt.figure()\npn.options.figure_size = (8,6)\n(ggplot(pj_usege, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(0,22001),breaks= np.arange(0,22001,2000))\n    + geom_line() \n    + geom_point(pj_usege,aes(x='factor(PRD_DE)',y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"참여 여부\")\n    + scale_color_manual(values=(\"blue\",\"red\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=0, nudge_y=1000,size=13,color=\"black\")\n    + ggtitle('임금 근로자 중 유연근무제 참여 인원 수\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697391465)>\n\n\n\n\nb. 성별 유연근무제 활용현황\nlink_list=[]\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7103S/2/1/20211204135633&prdSe=M&startPrdDe=\"\nfor i in range(201508,202109,100):\n  link_list.append(link+str(i))\npj_gender=pd.read_json(link_list[0])\nfor i in link_list[1:]:\n  pj_gender = pj_gender >> bind_rows(pd.read_json(i), join='outer')\npj_gender=pj_gender.reset_index(drop=True)\npj_gender2=pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(~X.C1_NM==\"계\") >>  mask(~X.C2_NM==\"계\")\npj_gender2=pj_gender2.reset_index(drop=True)\npj_total=pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT)  >> mask(~X.C1_NM==\"계\") >> mask(X.C2_NM==\"계\")\n\npj_total\n\n\n\n\n\n  \n    \n      \n      PRD_DE\n      C1_NM\n      C2_NM\n      DT\n    \n  \n  \n    \n      3\n      201508\n      남자\n      계\n      11006.6\n    \n    \n      6\n      201508\n      여자\n      계\n      8467.9\n    \n    \n      12\n      201608\n      남자\n      계\n      11085.6\n    \n    \n      15\n      201608\n      여자\n      계\n      8657.6\n    \n    \n      21\n      201708\n      남자\n      계\n      11188.2\n    \n    \n      24\n      201708\n      여자\n      계\n      8817.9\n    \n    \n      30\n      201808\n      남자\n      계\n      11171.3\n    \n    \n      33\n      201808\n      여자\n      계\n      8873.7\n    \n    \n      39\n      201908\n      남자\n      계\n      11395.7\n    \n    \n      42\n      201908\n      여자\n      계\n      9163.3\n    \n    \n      48\n      202008\n      남자\n      계\n      11361.3\n    \n    \n      51\n      202008\n      여자\n      계\n      9084.6\n    \n    \n      57\n      202108\n      남자\n      계\n      11516.6\n    \n    \n      60\n      202108\n      여자\n      계\n      9475.9\n    \n  \n\n\n\n\n\npj_total2=pj_total >> select(~X.C2_NM) >> spread(X.PRD_DE, X.DT) >> select(~X.C1_NM)\npj_total2.index=[\"남자\",\"여자\"]\npj_total2.transpose() >> mutate(ratio=np.round(X.남자/(X.남자+X.여자),2),배수 =np.round(X.남자/(X.여자),2) )\n# 총 경제활동 인원 대비 남성 비율 / 점차 줄어드는 중 \n\n\n\n\n\n  \n    \n      \n      남자\n      여자\n      ratio\n      배수\n    \n  \n  \n    \n      201508\n      11006.6\n      8467.9\n      0.57\n      1.30\n    \n    \n      201608\n      11085.6\n      8657.6\n      0.56\n      1.28\n    \n    \n      201708\n      11188.2\n      8817.9\n      0.56\n      1.27\n    \n    \n      201808\n      11171.3\n      8873.7\n      0.56\n      1.26\n    \n    \n      201908\n      11395.7\n      9163.3\n      0.55\n      1.24\n    \n    \n      202008\n      11361.3\n      9084.6\n      0.56\n      1.25\n    \n    \n      202108\n      11516.6\n      9475.9\n      0.55\n      1.22\n    \n  \n\n\n\n\n\nplt.figure()\npn.options.figure_size = (8,6)\n(ggplot(pj_total, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(6000,15001),breaks= np.arange(0,22001,2000))\n    + geom_line() \n    + geom_point(pj_total,aes(x='factor(PRD_DE)',y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"성별\")\n    + scale_color_manual(values=(\"blue\",\"red\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=0, nudge_y=500,size=13,color=\"black\")\n    + ggtitle('조사대상 성별 임금 근로자 수\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697419985)>\n\n\n\nplt.figure()\npn.options.figure_size = (14,6)\n(ggplot(pj_gender2, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C2_NM\",color=\"C2_NM\")) \n    + facet_wrap('C1_NM')\n    + scale_y_continuous(limits=(0,14001),breaks= np.arange(0,22001,2000))\n    + geom_line() \n    + geom_point(pj_gender2, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C2_NM\",color=\"C2_NM\"))\n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"참여 여부\")\n    + scale_color_manual(values=(\"blue\",\"red\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=0, nudge_y=1000,size=13,color=\"black\")\n    + ggtitle('임금 근로자 중 성별 유연근무제 참여 인원 수\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697654101)>\n\n\n# 성별 경제활동 참여 인구 대비 유연근무제 참여자 비율 \nratio_total=(pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"계\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,3)*100,ratio_notuse=np.round(X.notused/X.계,3)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_male=(pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"남자\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,3)*100,ratio_notuse=np.round(X.notused/X.계,3)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_female=(pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"여자\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,3)*100,ratio_notuse=np.round(X.notused/X.계,3)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio=pd.concat([ratio_total,ratio_male,ratio_female], keys=[\"전체\",\"남성\",\"여성\"]).reset_index() >> select(~X.level_1) >> rename(성별=\"level_0\") \n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(ratio, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"성별\",color=\"성별\")) \n    + scale_y_continuous(limits=(0,20),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(ratio, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"성별\",color=\"성별\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"성별\")\n    + scale_color_manual(values=(\"#619CFF\",\"#F8766D\",\"gray\"))\n    + geom_text(aes(label=\"ratio_use\"),nudge_x=0, nudge_y=+0.5,size=10,color=\"black\",format_string='{}%')\n    + ggtitle('성별 총 임금근로자 대비 유연근무제 참여 인원 수\\n(자료 출처: 통계청 경제활동인구조사)'))    \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696383501)>\n\n\npj_age_2021=pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.PRD_DE==202108) >> mask(~X.C1_NM==\"계\") >>mask(~X.C2_NM==\"계\")\n# 2021년 기준 유연근무제 참여집단과 비참여집단 비교\npj_2021=pj_gender >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.PRD_DE==202108) \n\nplt.figure()\npn.options.figure_size = (10,6)\ndodge_text = position_dodge(width=0.9)\n(ggplot(pj_2021,aes(x='C1_NM',y=\"DT\",fill=\"C1_NM\",group=\"C1_NM\")) \n    + scale_y_continuous(limits=(0,22000),breaks= np.arange(0,22001,2000))\n    + geom_bar(stat='identity',position = position_dodge(width = 0.9)) \n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"유형 별\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(fill=\"성별\")\n    + facet_wrap('C2_NM')\n    + scale_fill_manual(values=(\"gray\",\"#619CFF\",\"#F8766D\"))\n    + geom_text(aes(label='DT'), position=dodge_text,size=10, va='bottom', format_string='{}')\n    + ggtitle('임금 근로자 중 성별 유연근무제 참여 인원 수 (2021)\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697263013)>\n\n\n\n\nc. 연령 별 유연근무제 사용 유형\nlink_list=[]\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7105S/2/1/20211204160618&prdSe=M&startPrdDe=\"\nfor i in range(201508,202109,100):\n  link_list.append(link+str(i))\npj_age=pd.read_json(link_list[0])\nfor i in link_list[1:]:\n  pj_age = pj_age >> bind_rows(pd.read_json(i), join='outer')\nratio_age_total=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"계\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_15=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"15 - 29세\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_30=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"30 - 39세\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_40=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"40 - 49세\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_50=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"50 - 59세\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age_60=(pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"60세이상\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_age=pd.concat([ratio_age_total,ratio_age_15,ratio_age_30,ratio_age_40,ratio_age_50,ratio_age_60], keys=[\"전체\",\"15 - 29세\",\"30 - 39세\",\"40 - 49세\",\"50 - 59세\",\"60세이상\"]).reset_index() >> select(~X.level_1) >> rename(연령별=\"level_0\") \nratio_age[\"ratio_use\"]=np.round(ratio_age[\"ratio_use\"].astype(np.float64),2)\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(ratio_age, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"연령별\",color=\"연령별\")) \n    + scale_y_continuous(limits=(0,25),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(ratio_age, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"연령별\",color=\"연령별\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"연령 별\")\n    + geom_text(aes(label=\"ratio_use\"),nudge_x=0, nudge_y=+0.8,size=8,color=\"black\",format_string='{}%')\n    + ggtitle('연령별 총 임금근로자 대비 유연근무제 참여 인원 비율\\n(자료 출처: 통계청 경제활동인구조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8731672718093)>\n\n\npj_age_2021=pj_age >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.PRD_DE==202108) >> mask(~X.C1_NM==\"계\") >>mask(~X.C2_NM==\"계\")\n\nplt.figure()\npn.options.figure_size = (12,6)\ndodge_text = position_dodge(width=0.9)\n(ggplot(pj_age_2021,aes(x='C1_NM',y=\"DT\",fill=\"C1_NM\",group=\"C1_NM\")) \n    + scale_y_continuous(limits=(0,6000),breaks= np.arange(0,22001,2000))\n    + geom_bar(stat='identity',position = position_dodge(width = 0.9)) \n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"유형 별\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(fill=\"연령별\")\n    + facet_wrap('C2_NM')\n    + geom_text(aes(label='DT'), position=dodge_text,size=10, va='bottom', format_string='{}') \n    + scale_fill_manual(values=(\"#4a4e4d\",\"#0e9aa7\" ,\"orange\",\"#f6cd61\",\"#f9caa7\"))\n    + ggtitle('임금 근로자 중 연령별 유연근무제 참여 인원 수 (2021)\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696667145)>\n\n\n\n\nd. 혼인상태별 유연근무제 활용현황\nlink_marriage_list=[]\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7104S/2/1/20211204164055&prdSe=M&startPrdDe=\"\nfor i in range(201508,202109,100):\n  link_marriage_list.append(link+str(i))\npj_marriage=pd.read_json(link_marriage_list[0])\nfor i in link_marriage_list[1:]:\n  pj_marriage = pj_marriage >> bind_rows(pd.read_json(i), join='outer')\nratio_marriage_total=(pj_marriage >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"계\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_marriage_no=(pj_marriage >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"미혼\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_marriage_yes=(pj_marriage >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.C1_NM==\"기혼\") >> select(~X.C1_NM) >> spread(X.C2_NM,X.DT) >> rename(used=\"활용하고 있음\",notused=\"활용하지 않음\")\n  >> mutate(ratio_use=np.round(X.used/X.계,4)*100,ratio_notuse=np.round(X.notused/X.계,4)*100) >> select(X.PRD_DE,X.ratio_use,X.ratio_notuse)) \nratio_marriage=pd.concat([ratio_marriage_total,ratio_marriage_yes,ratio_marriage_no], keys=[\"전체\",\"기혼\",\"미혼\"]).reset_index() >> select(~X.level_1) >> rename(결혼=\"level_0\") \nratio_marriage[\"ratio_use\"]=np.round(ratio_marriage[\"ratio_use\"].astype(np.float64),2)\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(ratio_marriage, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"결혼\",color=\"결혼\")) \n    + scale_y_continuous(limits=(0,18),breaks= np.arange(0,101,3))\n    + geom_line() \n    + geom_point(ratio_marriage, aes(x='factor(PRD_DE)', y=\"ratio_use\",group=\"결혼\",color=\"결혼\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"혼인 여부\")\n    + scale_color_manual(values=(\"#619CFF\",\"#F8766D\",\"gray\"))\n    + annotate(\"text\", x=6.5, y=17.91, label=\"17.91%\", size=12,color=\"black\")\n    + annotate(\"text\", x=6.5, y=16.93, label=\"16.93%\", size=12,color=\"black\")\n    + annotate(\"text\", x=6.5, y=16, label=\"16.35%\", size=12,color=\"black\")\n    + ggtitle('혼인 유형 별 임금근로자 대비 유연근무제 참여 인원 수\\n(자료 출처: 통계청 경제활동인구조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696204773)>\n\n\npj_marriage_2021=pj_marriage >> select(X.PRD_DE,X.C1_NM,X.C2_NM,X.DT) >> mask(X.PRD_DE==202108) >> mask(~X.C1_NM==\"계\")\n\nplt.figure()\npn.options.figure_size = (10,6)\ndodge_text = position_dodge(width=0.9)\n(ggplot(pj_marriage_2021,aes(x='C1_NM',y=\"DT\",fill=\"C1_NM\",group=\"C1_NM\")) \n    + scale_y_continuous(limits=(0,15000),breaks= np.arange(0,22001,2000))\n    + geom_bar(stat='identity',position = position_dodge(width = 0.9)) \n    + theme_classic() \n    + ylab(\"인원 (천 명)\")\n    + xlab(\"유형 별\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(fill=\"연령별\")\n    + facet_wrap('C2_NM')\n    + geom_text(aes(label='DT'), position=dodge_text,size=10, va='bottom', format_string='{}')\n    + scale_fill_manual(values=(\"#619CFF\",\"#F8766D\"))\n    + ggtitle('임금 근로자 중 성별 유연근무제 참여 인원 수 (2021)\\n(자료 출처: 통계청 경제활동인구조사)'))\n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696952981)>\n\n\n\n\ne. 유연근무제 활용형태(복수응답)\nlink_type_list=[]\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1DE7100S/2/1/20211204170759&prdSe=M&startPrdDe=\"\nfor i in range(201508,202109,100):\n  link_type_list.append(link+str(i))\npj_type=pd.read_json(link_type_list[0])\nfor i in link_type_list[1:]:\n  pj_type = pj_type >> bind_rows(pd.read_json(i), join='outer')\nratio_type=pj_type >> mask(X.ITM_NM_ENG==\"ratio\") >> select(X.PRD_DE,X.C1_NM,X.DT)\nratio_type['C1_NM']=pd.Categorical(ratio_type['C1_NM'], ordered=True,categories=['근로시간단축근무제','시차출퇴근제','선택적 근무시간제','재택 및 원격근무제','탄력적 근무제','기타유형(재량근무 등)'])\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(ratio_type,aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + geom_line() \n    + scale_y_continuous(limits=(-1,50),breaks= np.arange(0,101,10))\n    + geom_point(ratio_type, aes(x='factor(PRD_DE)', y=\"DT\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"유연근무 유형\")\n    + scale_color_manual(values=(\"#4a4e4d\",\"#0e9aa7\" ,\"#f9caa7\",\"red\",\"#f6cd61\",\"green\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=0, nudge_y=+1,size=8,color=\"black\",format_string='{}%')\n    + geom_vline(xintercept=5+(4/12),linetype=\"dashed\")\n    + ggtitle('유연근무제 참여 유형별 비율\\n(자료 출처: 통계청 경제활동인구조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696647101)>\n\n\n\n\n유연근무제의 사용 현황 정리 (통계청 경제활동인구조사)\n\nCOVID-19과 상관 없이 인식 개선으로 유연근무제 사용 인원 수는 지속적으로 증가하여 왔음.\n예상했던 것 과는 달리 남성들이 유연근무제를 사용하는 비율이 여성이 사용하는 비율보다 높았음. (2021년 8월 기준 남성이 18.2%, 여성이 15.2%)\n유연근무제를 가장 많이 사용하는 계층은 30대 였으며 그 다음으로 40대 20대 50대 순이다. 60세 이상 집단의 경우 거의 사용하지 않았는데 50대 이상 집단과 비교하였을 때 큰 차이가 나타나고 있는 것을 확인할 수 있다.\nCOVID-19 이전까지 기혼집단이 유연근무제를 많이 사용하였으나, 이후로는 미혼집단이 오히려 더 많이 사용하고 있는 것으로 보인다.(2020년 8월 기준 미혼집단이 17.91%, 기혼집단이 16.35%)\nCOVID-19까지는 재택 및 원격 근무제(공간적 유연) 선택 비율이 가장 낮고 시차출퇴근 선택자들의 비율이 가장 높았으나, 2021년 기준 재택 및 원격 근무제 선택 비중이 가장 높은 것으로 확인된다. \n유연근무제가 원래 일 가정 갈등 정책의 하위 정책으로 분류되어진 상황에서 여성들에 비해 남성들이 더 많이 사용하고 있다는 점, 미혼 집단의 사용율이 오히려 높다는 점에서 초기의 정책 목표를 달성하였다고 보기 어려운 부분이 있다."
  },
  {
    "objectID": "data_analytics/FWA.html#공직생활실태조사-20172020",
    "href": "data_analytics/FWA.html#공직생활실태조사-20172020",
    "title": "Sangwon Ju's Personal Page",
    "section": "2. 공직생활실태조사 (2017~2020)",
    "text": "2. 공직생활실태조사 (2017~2020)\n\n지금부터의 분석은 2017~2020년 한국행정연구원이 (주)리서치앤리서치에 의뢰하여 실시한 5개년도의 ‘공직생활 실태조사’ 자료를 활용하여 분석한 것이다.  - 정부의 인적자원관리 현황과 공무원의 인식을 파악하기 위한 목적으로 조사시점기준 46개 중앙행정기관 및 17개 광역자치단체 소속 일반직 공무원을 대상으로 진행  층화 집락 추출 방식을 활용하여 부차모집단별 추출된 각 표본 과/팀에서 10명내외를 계통추출  - 표본의 크기는 각년도 말일 기준으로 모집단을 모비율 추정의 목표 오차(95% 신뢰수준 오차의 한계)인 2%∼3%를 만족하도록 구성  - 확률표본 수집 후 E-mail 웹 조사를 사용하였음.\n\n# 반복작업의 어려움으로 파이썬용 함수를 만들었음.\nlink=\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/417/DT_417002N_011/2/1/20211204203850&prdSe=Y&startPrdDe=\"\n\ndef kosis(link,a,b):\n  link_list=[]\n  for i in range(int(a),int(b)+1,1):\n    new_link=link+str(i)\n    link_list.append(new_link)\n  \n  df= pd.read_json(link_list[0])\n  if len(link_list)>=2:\n    for i in link_list[1:]:\n      df = df >> bind_rows(pd.read_json(i), join='outer')\n  result=df.reset_index(drop=True)    \n  return result  \npj_gov=kosis(link,2017,2020)\n\na. 성별 정부조직 유연근무제 사용 비율\npj_gov=pj_gov>>mask(X.C2_NM==\"있다\")\npj_gov_gender=pj_gov >> mask((X.C1_NM==\"남성\")|(X.C1_NM==\"여성\")|(X.C1_NM==\"전체\"))\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_gender, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(50,80),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_gender, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"성별\")\n    + scale_color_manual(values=(\"#619CFF\",\"#F8766D\",\"gray\"))\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('성별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697292525)>\n\n\n\n\nb. 연령 별 정부조직 유연근무제 사용 비율\npj_gov_age=pj_gov >> mask((X.C1_NM==\"20대\")|(X.C1_NM==\"30대\")|(X.C1_NM==\"40대\")|(X.C1_NM==\"50대 이상\")|(X.C1_NM==\"전체\"))\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_age, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(42,85),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_age, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"연령대별\")\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('연령대별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762698177993)>\n\n\n\n\nc. 직급 별 정부조직 유연근무제 사용 비율\npj_gov_rank=pj_gov >> mask((X.C1_NM==\"1~4급\")|(X.C1_NM==\"5급\")|(X.C1_NM==\"6~7급\")|(X.C1_NM==\"8~9급\"))\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_rank, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(42,85),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_rank, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"직급별\")\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('직급별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762697124449)>\n\n\n\n\nd. 소속조직 수준 별 정부조직 유연근무제 사용 비율\npj_gov_level=pj_gov >> mask((X.C1_NM==\"광역자치단체\")|(X.C1_NM==\"중앙행정기관\"))\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_level, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(42,85),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_level, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"소속조직 수준별\")\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('소속조직 수준별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696037269)>\n\n\n\n\ne. 재직기간별 유연근무제 사용 비율\npj_gov_length=pj_gov >> mask((X.C1_NM==\"5년 이하\")|(X.C1_NM==\"6~10년\")|(X.C1_NM==\"11~15년\")|(X.C1_NM==\"16~20년\")|(X.C1_NM==\"21~25년\")|(X.C1_NM==\"26년 이상\")  )\npj_gov_length[\"C1_NM\"]=pd.Categorical(pj_gov_length[\"C1_NM\"], ordered=True,categories=[\"5년 이하\",\"6~10년\",\"11~15년\",\"16~20년\",\"21~25년\",\"26년 이상\"])\n\nplt.figure()\npn.options.figure_size = (10,6)\n(ggplot(pj_gov_length, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\")) \n    + scale_y_continuous(limits=(42,80),breaks= np.arange(0,101,5))\n    + geom_line() \n    + geom_point(pj_gov_length, aes(x='factor(PRD_DE)', y=\"DT\",group=\"C1_NM\",color=\"C1_NM\"))\n    + theme_classic() \n    + ylab(\"비율 (%)\")\n    + xlab(\"시점\") \n    + theme(text=element_text(fontproperties=font))\n    + labs(colour=\"재직기간별\")\n    + geom_text(aes(label=\"DT\"),nudge_x=.25, nudge_y=+.5,size=12,color=\"black\",format_string='{}%')\n    + ggtitle('재직기간별 정부조직 공무원 유연근무제 참여 비율\\n(자료 출처: 한국행정연구원 공직생활실태조사)'))   \n\n/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  if pdtypes.is_categorical(arr):\n\n\n<Figure size 432x288 with 0 Axes>\n\n\n\n\n\n<ggplot: (8762696138673)>\n\n\n\n\n정부조직 유연근무제의 특징 정리 (한국행정연구원 공직생활실태조사)\n\nCOVID-19이전까지 유연근무제의 사용이 꾸준히 감소하던 추세였다가, 발생 이후 급증함.\n전체기간에서 민간 및 공공기관 인구를 모두 포함해서 조사한 경제활동인구조사와 비교 시 정부조직 공무원들은 유연근무제를 더욱 약 2배 정도 많이 사용하고 있는 것으로 확인되었음.\n\n정부조직에서는 경제활동인구조사와는 달리 남성들이 유연근무제를 사용하는 비율이 여성이 사용하는 비율보다 낮았음. (2020년 기준 남성이 72.4%, 여성이 75.5%) 20대의 경우 정부조직에서 COVID-19 이전까지 유연근무제를 가장 적게 사용하던 연령대였으나, COVID-19이후 가장 많이 사용하는 연령대로 변화하였음. (2019년 47.5% 2020년 79.6%) 낮은 연령대의 공무원들이 유연근무제를 사용하지 못했던 원인에 대해서 깊이 있게 고찰해볼 필요가 존재함.(눈치가 보여서, 사용 못하였음… or 2015년 자체부서평가의 시행으로 잠시 올라갔다가 다시 떨어지는 추세)\n이러한 경향성은 직급별, 재직기간별 분석 자료를 통해 분석하였을 때 더욱 뚜렷하게 드러나는데, COVID-19이전까지는 하더라도 유연근무제가 재직기간이 길수록 직급이 높을 수록 훨씬 더 많이 사용하는 경향성이 있는 것으로 보였는데, 2020년 데이터에서는 직급 별 유연근무제 사용 비율이 큰 차이가 없었고, 재직기간이 5년 미만인 공무원들이 79%로 다른 세대에 비해서 월등하게 높은 유연근무제 사용율을 보이고 있는 것을 확인할 수 있었음.\n공공영역 유연근무제의 확산을 위해서는 유연근무제를 사용할 수 있는 조직적, 관리자적 지원이 필수적(Choi, 2017)이라는 이전 연구결과를 통해 미루어 보았을 때 유연근무제의 확산을 위해서 이후 소위 조직 내 입지가 적은 구성원들이 자유롭게 사용할 수 있는 분위기를 형성하기 위한 정책적 노력이 필요할 것으로 보인다."
  },
  {
    "objectID": "data_analytics/employees.html",
    "href": "data_analytics/employees.html",
    "title": "Analysis 1: Number of local government employees",
    "section": "",
    "text": "Data retrieved from KOSIS (Korean Statistical Information Service).\nAgenda1: examining trend of the total local government employee number to find out the impact of “The Transition of Fire Officals to National Position”.\nAgenda2: visualize the number of employees to separate the impact of transition from original fluctuation in number.\n\n\n\n\n\nCode\npacman::p_load(\"jsonlite\",\n               \"tidyverse\",\n               \"forecast\",\n               \"ggfortify\",\n               \"forecast\",\n               \"httr\",\n               \"sleekts\",\n               \"lubridate\",\n               \"stats\",\n               \"smooth\",\n               \"ghibli\",\n               \"plyr\",\n               \"scales\",\n               \"formattable\",\n               \"knitr\",\n               \"showtext\",\n               \"kableExtra\",\n               \"IRdisplay\",\n               \"glue\",\n               \"echarts4r\",\n               \"plotly\")\n\n\n\n\n\n\n\nCode\nfont_add_google(name=\"Lato\")\nshowtext_auto()"
  },
  {
    "objectID": "data_analytics/employees.html#importing-data",
    "href": "data_analytics/employees.html#importing-data",
    "title": "Analysis 1: Number of local government employees",
    "section": "- Importing data",
    "text": "- Importing data\n\n\nCode\n# auto inporting function\nkosis1 = function (a,b){\n    library(\"jsonlite\")\n    library(\"dplyr\")\n    i1=a\n    i2=b    \n    years=seq(i1+1,i2,1)\n    data= fromJSON(glue::glue(\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1YL2101E/2/1/20211111002533&prdSe=Y&startPrdDe={i1}&endPrdDe={i1}\"))\n    for(i in years) {\n        assign(paste(\"employee_\",i,sep=\"\"), \n               fromJSON(glue::glue(\"https://kosis.kr/openapi/statisticsData.do?method=getList&apiKey=YjNjZjJmNDI2NWE1N2U3NGRiZWE3ZmI3MmU4YjliNGU=&format=json&jsonVD=Y&userStatsId=jsw0641/101/DT_1YL2101E/2/1/20211111002533&prdSe=Y&startPrdDe={i}&endPrdDe={i}\")))\n        data %>% \n            full_join(get(paste(\"employee_\",i,sep=\"\"))) -> data\n        print(paste(\"employee_\",i,\" added\",sep=\"\"))\n    }\n    return(data)\n}\n\n# Importing Data\nemployee_data=kosis1(2008,2020)\n\n\n\n\nCode\nemployee_data %>% \n    glimpse()\n\n\nRows: 230\nColumns: 14\n$ TBL_NM      <chr> \"지방자치단체공무원 현원(시도)\", \"지방자치단체공무원 현원(…\n$ PRD_DE      <chr> \"2008\", \"2008\", \"2008\", \"2008\", \"2008\", \"2008\", \"2008\", \"2…\n$ TBL_ID      <chr> \"DT_1YL2101E\", \"DT_1YL2101E\", \"DT_1YL2101E\", \"DT_1YL2101E\"…\n$ ITM_NM      <chr> \"지방자치단체공무원 현원\", \"지방자치단체공무원 현원\", \"지…\n$ ITM_ID      <chr> \"16110T2009_036\", \"16110T2009_036\", \"16110T2009_036\", \"161…\n$ ORG_ID      <chr> \"101\", \"101\", \"101\", \"101\", \"101\", \"101\", \"101\", \"101\", \"1…\n$ UNIT_NM     <chr> \"명\", \"명\", \"명\", \"명\", \"명\", \"명\", \"명\", \"명\", \"명\", \"명\"…\n$ UNIT_NM_ENG <chr> \"In person\", \"In person\", \"In person\", \"In person\", \"In pe…\n$ C1_OBJ_NM   <chr> \"행정구역별\", \"행정구역별\", \"행정구역별\", \"행정구역별\", \"…\n$ DT          <chr> \"275231\", \"46270\", \"15752\", \"10799\", \"12964\", \"6473\", \"676…\n$ PRD_SE      <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\"…\n$ C1          <chr> \"15110SDB000\", \"15110SDB001\", \"15110SDB002\", \"15110SDB003\"…\n$ C1_NM       <chr> \"전국\", \"서울특별시\", \"부산광역시\", \"대구광역시\", \"인천광…\n$ C1_NM_ENG   <chr> \"Whole country\", \"Seoul\", \"Busan\", \"Daegu\", \"Incheon\", \"Gw…\n\n\n\n\nCode\n# Selected Provinces \nemployee_data$C1_NM_ENG %>% \n    unique() -> level\nlevel\n\n\n [1] \"Whole country\"     \"Seoul\"             \"Busan\"            \n [4] \"Daegu\"             \"Incheon\"           \"Gwangju\"          \n [7] \"Daejeon\"           \"Ulsan\"             \"Gyeonggi-do\"      \n[10] \"Gangwon-do\"        \"Chungcheongbuk-do\" \"Chungcheongnam-do\"\n[13] \"Jeollabuk-do\"      \"Jeollanam-do\"      \"Gyeongsangbuk-do\" \n[16] \"Gyeongsangnam-do\"  \"Jeju\"              \"Sejong\"           \n\n\nSouth Korea is made up of 17 first-tier administrative divisions: 6 metropolitan cities (gwangyeoksi 광역시/廣域市), 1 special city (teukbyeolsi 특별시/特別市), 1 special self-governing city (teukbyeol-jachisi 특별자치시/特別自治市), and 9 provinces (do 도/道), including one special self-governing province (teukbyeol jachido 특별자치도/特別自治道). (cited from Wikipedia)"
  },
  {
    "objectID": "data_analytics/employees.html#clensing-data",
    "href": "data_analytics/employees.html#clensing-data",
    "title": "Analysis 1: Number of local government employees",
    "section": "- Clensing data",
    "text": "- Clensing data\n\n\nCode\nemployee_data$DT=as.numeric(employee_data$DT)\nemployee_data=employee_data%>%\n    dplyr::rename(ad_division=C1_NM_ENG) \n\n\nemployee_data %>% \n    filter(PRD_DE==2018) %>% \n    select(ad_division,DT) %>% \n    dplyr::rename(employee_2018=\"DT\") -> employee_2018\n\nemployee_data %>% \n    filter(PRD_DE==2019) %>% \n    select(ad_division,DT) %>% \n    dplyr::rename(employee_2019=\"DT\") -> employee_2019\n\nemployee_data %>% \n    filter(PRD_DE==2020) %>% \n    select(ad_division,DT) %>% \n    dplyr::rename(employee_2020=\"DT\") -> employee_2020"
  },
  {
    "objectID": "data_analytics/employees.html#the-decrease-rate-of-the-number-of-employees-in-2020-compared-to-2018",
    "href": "data_analytics/employees.html#the-decrease-rate-of-the-number-of-employees-in-2020-compared-to-2018",
    "title": "Analysis 1: Number of local government employees",
    "section": "- The decrease rate of the number of employees in 2020 compared to 2018",
    "text": "- The decrease rate of the number of employees in 2020 compared to 2018\n\n\nCode\nemployee_2018 %>% \n    full_join(employee_2019) %>% \n    full_join(employee_2020) %>% \n    dplyr::rename(Local_Divisions=\"ad_division\") -> emp_num\n\n\nJoining, by = \"ad_division\"\nJoining, by = \"ad_division\"\n\n\nCode\nemp_num$Local_Divisions=factor(emp_num$Local_Divisions,levels=rev(level))\n\nknitr::kable(emp_num,format.args = list(big.mark = \",\"),\n            caption = \"The Number of local government employees (2018, 2019, 2020)\",\n            col.names = gsub(\"[_]\", \" \", names(emp_num))) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\n\n\nThe Number of local government employees (2018, 2019, 2020)\n \n  \n    Local Divisions \n    employee 2018 \n    employee 2019 \n    employee 2020 \n  \n \n\n  \n    Whole country \n    322,862 \n    337,084 \n    292,182 \n  \n  \n    Seoul \n    50,599 \n    52,081 \n    45,826 \n  \n  \n    Busan \n    19,088 \n    19,294 \n    16,509 \n  \n  \n    Daegu \n    12,912 \n    13,321 \n    10,975 \n  \n  \n    Incheon \n    14,515 \n    15,662 \n    13,478 \n  \n  \n    Gwangju \n    7,956 \n    8,409 \n    7,377 \n  \n  \n    Daejeon \n    7,704 \n    7,981 \n    6,704 \n  \n  \n    Ulsan \n    6,409 \n    6,684 \n    5,644 \n  \n  \n    Sejong \n    1,906 \n    2,132 \n    1,767 \n  \n  \n    Gyeonggi-do \n    54,864 \n    58,293 \n    51,147 \n  \n  \n    Gangwon-do \n    18,599 \n    19,215 \n    16,047 \n  \n  \n    Chungcheongbuk-do \n    13,947 \n    14,661 \n    13,040 \n  \n  \n    Chungcheongnam-do \n    18,180 \n    19,313 \n    16,522 \n  \n  \n    Jeollabuk-do \n    17,042 \n    17,811 \n    15,639 \n  \n  \n    Jeollanam-do \n    21,698 \n    22,685 \n    20,247 \n  \n  \n    Gyeongsangbuk-do \n    26,745 \n    27,829 \n    24,047 \n  \n  \n    Gyeongsangnam-do \n    24,836 \n    25,690 \n    22,056 \n  \n  \n    Jeju \n    5,862 \n    6,023 \n    5,157 \n  \n\n\n\n\n\n\n\nCode\nemp_num %>% \n    mutate(Increase_Rate=formattable::percent((employee_2020-employee_2018)/employee_2018)) %>%\n    select(Local_Divisions,Increase_Rate) %>% \n    kbl(col.names = gsub(\"[_]\", \" \", names(.)),\n        caption = \"The decrease rate of the number of employees in 2020 compared to 2018\") %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\n\n\nThe decrease rate of the number of employees in 2020 compared to 2018\n \n  \n    Local Divisions \n    Increase Rate \n  \n \n\n  \n    Whole country \n    -9.50% \n  \n  \n    Seoul \n    -9.43% \n  \n  \n    Busan \n    -13.51% \n  \n  \n    Daegu \n    -15.00% \n  \n  \n    Incheon \n    -7.14% \n  \n  \n    Gwangju \n    -7.28% \n  \n  \n    Daejeon \n    -12.98% \n  \n  \n    Ulsan \n    -11.94% \n  \n  \n    Sejong \n    -7.29% \n  \n  \n    Gyeonggi-do \n    -6.77% \n  \n  \n    Gangwon-do \n    -13.72% \n  \n  \n    Chungcheongbuk-do \n    -6.50% \n  \n  \n    Chungcheongnam-do \n    -9.12% \n  \n  \n    Jeollabuk-do \n    -8.23% \n  \n  \n    Jeollanam-do \n    -6.69% \n  \n  \n    Gyeongsangbuk-do \n    -10.09% \n  \n  \n    Gyeongsangnam-do \n    -11.19% \n  \n  \n    Jeju \n    -12.03% \n  \n\n\n\n\n\n\nOverall, the number of employees in every local divisions decreased by around 6 to 15 percentage points."
  },
  {
    "objectID": "data_analytics/employees.html#increase-rate-of-the-number-of-employees-in-2019-compared-to-2018",
    "href": "data_analytics/employees.html#increase-rate-of-the-number-of-employees-in-2019-compared-to-2018",
    "title": "Analysis 1: Number of local government employees",
    "section": "- Increase rate of the number of employees in 2019 compared to 2018",
    "text": "- Increase rate of the number of employees in 2019 compared to 2018\n\n\nCode\nemp_num %>% \n    mutate(increase=round(((employee_2019-employee_2018)/employee_2018)*100,2)) %>%\n    select(Local_Divisions,increase) %>% \n    ggplot(aes(x=Local_Divisions,y=increase)) + \n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    theme_classic() +\n    geom_text(aes(label= paste(sprintf(\"%2.2f\", increase),\"%\",sep=\"\")), size=3, position = position_dodge(width = 1))+\n  labs(x=\"17 first-tier administrative divisions\",\n       y=\"Increase Rate(%)\")+\n  scale_y_continuous(breaks=seq(0, 15, 1)) + \n  theme(text=element_text(family=\"Lato\",size=10),\n        plot.title = element_text(size = 5))+\n  coord_flip() -> p \n\nplotly::ggplotly(p, tooltip=\"text\") %>% \n    style(textposition = \"right\") %>% \n    layout(title = list(text = paste0(\n        'Increase rate of employees in 2019 (compared to 2018)',\n        '<br>',\n        '<sup>',\n        'Source: Ministry of Public Administration and Security (KOSIS)','</sup>'),\n        x = 0.1,\n        font=list(size=15)))"
  },
  {
    "objectID": "data_analytics/employees.html#increase-rate-of-the-number-of-employees-in-2020-compared-to-2018",
    "href": "data_analytics/employees.html#increase-rate-of-the-number-of-employees-in-2020-compared-to-2018",
    "title": "Analysis 1: Number of local government employees",
    "section": "- Increase rate of the number of employees in 2020 compared to 2018",
    "text": "- Increase rate of the number of employees in 2020 compared to 2018\n\n\nCode\nemp_num %>% \n    mutate(increase=round(((employee_2020-employee_2018)/employee_2018)*100,2)) %>%\n    select(Local_Divisions,increase) %>% \n    arrange(increase) %>% \n    ggplot(aes(x=Local_Divisions,y=increase)) + \n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    theme_classic() +\n    geom_text(aes(label= paste(sprintf(\"%2.2f\", increase),\"%\",sep=\"\")), size=3, position = position_dodge(width = 1))+\n  labs(x=\"17 first-tier administrative divisions\",\n       y=\"Increase Rate(%)\")+\n  scale_y_continuous(breaks=seq(0, 15, 1)) + \n  theme(text=element_text(family=\"Lato\",size=10),\n        plot.title = element_text(size = 5)) +\n  coord_flip() -> p \n\nplotly::ggplotly(p, tooltip=\"text\") %>% \n    style(textposition = \"left\") %>% \n    layout(title = list(text = paste0(\n        'Decrease rate of employees in 2020 (compared to 2018)',\n        '<br>',\n        '<sup>',\n        'Source: Ministry of Public Administration and Security (KOSIS)','</sup>'),\n        x = 0.1,\n        font=list(size=15)))\n\n\n\n\n\n\n\n\nCode\nemp_num %>% \n    mutate(increase=round(((employee_2020-employee_2018)/employee_2018)*100,2)) %>%\n    select(Local_Divisions,increase) %>% \n    arrange(increase) %>% \n    ggplot(aes(x=factor(Local_Divisions,levels=rev(.$Local_Divisions)),y=increase)) + \n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    theme_classic() +\n    geom_text(aes(label= paste(sprintf(\"%2.2f\", increase),\"%\",sep=\"\")), size=3, position = position_dodge(width = 1))+\n  labs(x=\"17 first-tier administrative divisions\",\n       y=\"Increase Rate(%)\")+\n  scale_y_continuous(breaks=seq(0, 15, 1)) + \n  theme(text=element_text(family=\"Lato\",size=10),\n        plot.title = element_text(size = 5)) +\n  coord_flip() -> p \n\nplotly::ggplotly(p, tooltip=\"text\") %>% \n    style(textposition = \"left\") %>% \n    layout(title = list(text = paste0(\n        'Decrease rate of employees in 2020 (compared to 2018)',\n        '<br>',\n        '<sup>',\n        'Source: Ministry of Public Administration and Security (KOSIS)','</sup>'),\n        x = 0.1,\n        font=list(size=15)))\n\n\nWarning: Use of `.$Local_Divisions` is discouraged. Use `Local_Divisions` instead.\nUse of `.$Local_Divisions` is discouraged. Use `Local_Divisions` instead."
  },
  {
    "objectID": "data_analytics/employees.html#trends-of-the-number-of-local-government-employees-from-2009-to-2020",
    "href": "data_analytics/employees.html#trends-of-the-number-of-local-government-employees-from-2009-to-2020",
    "title": "Analysis 1: Number of local government employees",
    "section": "- Trends of the number of local government employees from 2009 to 2020",
    "text": "- Trends of the number of local government employees from 2009 to 2020\n\n\nCode\nemployee_data %>% \n    filter(ad_division==\"Whole country\") %>%  \n    arrange(PRD_DE) %>% \n    transmute(year=(PRD_DE),number=DT) %>%\n    mutate_if(is.character,as.numeric) %>%\n    dplyr::mutate(Diff_growth = number - lag(number), \n    # Difference in route between years\n     Rate_percent = round((Diff_growth)/lag(number) * 100,2)) %>% \n    # growth rate in percent\n    filter(year>2008) %>% \n    mutate(year=factor(year)) -> employee3\n\n employee3 %>% \n    kbl(col.names = gsub(\"[_]\", \" \", names(.)),\n        caption = \"The decrease rate of the number of employees in 2020 compared to 2018\",\n        format.args = list(big.mark = \",\")) %>% \n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\n\n\nThe decrease rate of the number of employees in 2020 compared to 2018\n \n  \n    year \n    number \n    Diff growth \n    Rate percent \n  \n \n\n  \n    2009 \n    278,303 \n    3,072 \n    1.12 \n  \n  \n    2010 \n    279,636 \n    1,333 \n    0.48 \n  \n  \n    2011 \n    281,035 \n    1,399 \n    0.50 \n  \n  \n    2012 \n    284,355 \n    3,320 \n    1.18 \n  \n  \n    2013 \n    287,299 \n    2,944 \n    1.04 \n  \n  \n    2014 \n    289,914 \n    2,615 \n    0.91 \n  \n  \n    2015 \n    296,273 \n    6,359 \n    2.19 \n  \n  \n    2016 \n    303,401 \n    7,128 \n    2.41 \n  \n  \n    2017 \n    310,654 \n    7,253 \n    2.39 \n  \n  \n    2018 \n    322,862 \n    12,208 \n    3.93 \n  \n  \n    2019 \n    337,084 \n    14,222 \n    4.40 \n  \n  \n    2020 \n    292,182 \n    -44,902 \n    -13.32 \n  \n\n\n\n\n\n\n\nCode\nfont_add_google(name=\"Noto Serif\")\nemployee3  %>% \n  ggplot(aes(x=as.factor(year))) + \n  geom_bar(aes(fill=\"pink\",y=Diff_growth),stat = \"identity\") + \n  theme_classic()+\n  geom_text(aes(y=Diff_growth+sign(Diff_growth)*-15,label= scales::comma(Diff_growth)), size=5,position = position_dodge(width = 1))+\n  theme(text=element_text(family=\"Noto Serif\",size=12),legend.position = \"none\")+\n  scale_x_discrete(labels = c(2009:2020))+\n  scale_y_continuous(breaks =seq(-45000,15000,by=5000)) +\n  labs(x=\"17 first-tier administrative divisions\",\n       y=\"Increase Rate(%)\")-> p1\n\nplotly::ggplotly(p1, tooltip=\"text\") %>% \n    style(textposition = \"center\") %>% \n    layout(title = list(text = paste0(\n        'Trends of the number of local government employees from 2009 to 2020',\n        '<br>',\n        '<sup>',\n        'Source: Ministry of Public Administration and Security (KOSIS)','</sup>'),\n        x = 0.01,\n        font=list(size=16)))\n\n\n\n\n\n\n\n\nCode\nemployee3  %>% \n  ggplot(aes(x=as.factor(year))) + \n  geom_bar(aes(x = as.factor(year), y = Diff_growth), stat = \"identity\",fill=\"gray\",alpha=0.3)+\n  geom_line(aes(x = as.integer(1:12), y = Rate_percent*3500),color=\"orange\",size=1)+\n  geom_point(aes(x = as.factor(year), y = Rate_percent*3500),color=\"red\",size=2, alpha=0.7) +\n  geom_text(aes(x = as.factor(year),y=Rate_percent*3500,label= paste(sprintf(\"%2.2f\", Rate_percent),\"%\",sep=\"\")),color=\"black\",hjust=-0.1,vjust=-2.3, size=8,position = position_dodge(width = 2))+\n  theme_classic()+\n  scale_y_continuous(sec.axis = sec_axis(~./3500, name = paste(\"Increase Rate  (%)\",\"\\n\"),breaks = seq(-15,10,5)),breaks =comma(seq(-50000,25000,by=5000),format = \"d\") )+\n  scale_x_discrete(labels = as.factor(c(2009:2020)))+\n  coord_cartesian(ylim=c(-50000,25000))+\n  labs(x=\"17 first-tier administrative divisions\",\n       y=\"Change in # of employees\",\n       title=\"Trends of the number of local government employees from 2009 to 2020\",\n       subtitle=\"Source: Ministry of Public Administration and Security (KOSIS)\") +\n  theme(text=element_text(family=\"Noto Serif\",size=25))\n\n\nWarning: position_dodge requires non-overlapping x intervals"
  },
  {
    "objectID": "data_analytics/EDA7.html",
    "href": "data_analytics/EDA7.html",
    "title": "EDA Assignment 7: Chapter 9",
    "section": "",
    "text": "R의 trees 자료를 이용하여 다음을 수행하여라.\n\n\nVolume을 Y축에, Height를 X축에 그리고 또한 Volume을 Y축에, Girth를 X축에 그린 후 두 그래프에서 자료들판단)이 직선으로 모형을 세우기 적합한 지, 선형성이 어떤 것이 더 강한지 비교하여라. (눈으로 판단)\n\npacman::p_load(\"skimr\",\"tidyverse\")\ntrees %>% glimpse()\n\nRows: 31\nColumns: 3\n$ Girth  <dbl> 8.3, 8.6, 8.8, 10.5, 10.7, 10.8, 11.0, 11.0, 11.1, 11.2, 11.3, …\n$ Height <dbl> 70, 65, 63, 72, 81, 83, 66, 75, 80, 75, 79, 76, 76, 69, 75, 74,…\n$ Volume <dbl> 10.3, 10.3, 10.2, 16.4, 18.8, 19.7, 15.6, 18.2, 22.6, 19.9, 24.…\n\nskimr::skim(trees)\n\n\nData summary\n\n\nName\ntrees\n\n\nNumber of rows\n31\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nGirth\n0\n1\n13.25\n3.14\n8.3\n11.05\n12.9\n15.25\n20.6\n▃▇▃▅▁\n\n\nHeight\n0\n1\n76.00\n6.37\n63.0\n72.00\n76.0\n80.00\n87.0\n▃▃▆▇▃\n\n\nVolume\n0\n1\n30.17\n16.44\n10.2\n19.40\n24.2\n37.30\n77.0\n▇▅▁▂▁\n\n\n\n\nsum(is.na(trees)) # 결측치 없음\n\n[1] 0\n\nplot(y=trees$Volume,x=trees$Height,main=\"Linearity of volume and height\",xlab=\"height\",ylab=\"volume\")\n\n\n\nplot(y=trees$Volume,x=trees$Girth,main=\"Linearity of volume and girth\",xlab=\"girth\",ylab=\"volume\")\n\n\n\n\n첫번째 자료의 경우 경향성이 따로 나타나지 않는 것으로 보인다. 두 Plot을 비교할 경우 두번째 자료(volume,girth)가 직선으로 모형으로 세우기 적합하다고 본다. X축과 Y축의 선형성 또한 두번째 자료가 더 강하게 나타나는 것으로 보인다.\n\n\n\n각각 r-line을 적합 시킨 후 그래프 위에 그려라. 각기 잔차를 구하여 y-hat vs. residual plot을 그리고 적합 타당성을 판단하고 비교하여라.\n\n# 첫번째 플롯에 대해서\nplot(y=trees$Volume,x=trees$Height,main=\"Linearity of volume and height\",xlab=\"height\",ylab=\"volume\")\n(z1 <- line(x=trees$Height,y=trees$Volume))\n\n\nCall:\nline(x = trees$Height, y = trees$Volume)\n\nCoefficients:\n[1]  -115.118     1.918\n\nabline(coef(z1))\nz1.ls <- lm(trees$Volume ~ trees$Height)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 63, y = 72, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\n# Tukey-Tree Plot :\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline:Volume~Height\")\nabline(0,0)       \n\n\n\nboxplot(residuals(z1)) # outlier 없음\n\n\n\n# 두번째 플롯에 대해서\nplot(y=trees$Volume,x=trees$Girth,main=\"Linearity of volume and girth\",xlab=\"girth\",ylab=\"volume\")\n(z2 <- line(x=trees$Girth,y=trees$Volume))\n\n\nCall:\nline(x = trees$Girth, y = trees$Volume)\n\nCoefficients:\n[1]  -36.585    5.046\n\nabline(coef(z2))\nz2.ls <- lm(trees$Volume ~ trees$Girth)\nabline(z2.ls$coef, lty=2,col=\"red\")\nlegend(x = 8.5, y = 71, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\n# Tukey-Tree Plot :\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by rline: Volume~Height\")\nabline(0,0)    \n\n# 이차함수를 따를지도 모른다.\nk=seq(-100,100,0.1)\na<-function(x) {((1/50)*(x-35)^2)-8}\nlines(a(k)~k)\n\n\n\nboxplot(residuals(z2)) # outlier 없음\n\n\n\n\n첫번째 Plot의 경우 이 분산성이 발생하는 것으로 보인다. Y_hat이 작을 때에는 잔차의 폭이 좁았는데 점점 커질수록 잔차의 폭이 넓어지고 있는 모습을 보이고 있다는 점에서 그러하다. Ideal한 Residual Plot은 띠 모양으로 Plot의 점들이 x축에 평행한 직선을 이루어야 하는데 Plot에서의 잔차는 점차 늘어나고 있다는 점에서 Transformation을 통해 잔차를 조정해야 한다.\n두번째 Plot의 경우에도 점들이 x축에 평행하게 모여있지는 않고 일종의 Qudratic Form (2차함수) 곡선을 이루고 있는 것으로 보인다.Ideal한 Residual Plot은 띠 모양으로 Plot의 점들이 x축에 평행 직선을 이루어야 하는데 실제 Plot의 모양은 곡선을 이루고 있는 것으로 보아 변수 들을 변환한다면 현재의 잔차들이 가지고 있는 경향성을 완화할 수 있을 것이라고 생각한다.\n\n\n\nVolume ~ Height plot에서 직선화하기 위한 재표현을 시행착오 방법으로 찾아라. Volume만 변환시켜 보아라. Height만 변환시켜 보아라. 시행착오 과정을 모두 수록하여라.\n\n# 단순화\nattach(trees)\nmedHeight <- as.vector(3)\nmedVolume <- as.vector(3)\nmedHeight[1] <- median(Height[1:10]); medVolume[1] <- median(Volume[1:10])\nmedHeight[2] <- median(Height[11:21]); medVolume[2] <- median(Volume[11:21])\nmedHeight[3] <- median(Height[22:31]); medVolume[3] <- median(Volume[22:31])\nplot(medVolume~medHeight, type=\"b\",main=\"MedVolume~MedHeight\")   # \"b\"= both points and line\n\n\n\ndetach(trees)\n\n# 시행착오\n# 먼저 Y변수에 대해서 큰부분을 작게 작은 부분을 크게 만드는 변환\nplot(y=sqrt(trees$Volume),x=trees$Height,main=\"Linearity of sqrt(volume) and height\",xlab=\"height\",ylab=\"sqrt volume\")\n\n\n\nplot(y=log(trees$Volume),x=trees$Height,main=\"Linearity of log(volume) and height\",xlab=\"height\",ylab=\"log volume\")\n\n\n\n# X변수에 대해서 변환을 진행\nplot(y=trees$Volume,x=(trees$Height)^2,main=\"Linearity of volume and height squares\",xlab=\"height squares\",ylab=\"volume\")\n\n\n\n# 책에서 제시한 변환법\nvh=trees$Volume/trees$Height\nplot(y=vh,x=trees$Height,main=\"Linearity of volume/height and height\",xlab=\"height\",ylab=\"volume/height\")\n\n\n\n# Volume만 변화시키기\n# 1) y에 Sqrt 씌우기\n\nplot(y=sqrt(trees$Volume),x=trees$Height,main=\"Linearity of sqrt(volume) and height\",xlab=\"height\",ylab=\"sqrt volume\")\n(z3 <- line(x=trees$Height,y=sqrt(trees$Volume)))\n\n\nCall:\nline(x = trees$Height, y = sqrt(trees$Volume))\n\nCoefficients:\n[1]  -7.7958   0.1693\n\nabline(coef(z3))\nz3.ls <- lm(sqrt(trees$Volume) ~ trees$Height)\nabline(z3.ls$coef, lty=2,col=\"red\")\nlegend(x = 63, y = 8.5, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\n# 2) y에 Log 씌우기\n\nplot(y=log(trees$Volume),x=trees$Height,main=\"Linearity of log(volume) and height\",xlab=\"height\",ylab=\"log volume\")\n(z4 <- line(x=trees$Height,y=log(trees$Volume)))\n\n\nCall:\nline(x = trees$Height, y = log(trees$Volume))\n\nCoefficients:\n[1]  -1.39776   0.06068\n\nabline(coef(z4))\nz4.ls <- lm(log(trees$Volume) ~ trees$Height)\nabline(z4.ls$coef, lty=2,col=\"red\")\nlegend(x = 63, y = 4.2, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\n# 3) x에 제곱 씌우기\nplot(y=trees$Volume,x=(trees$Height)^2,main=\"Linearity of volume and height squares\",xlab=\"height squares\",ylab=\"volume\")\n(z5 <- line(x=(trees$Height)^2,y=trees$Volume))\n\n\nCall:\nline(x = (trees$Height)^2, y = trees$Volume)\n\nCoefficients:\n[1]  -43.3710    0.0127\n\nabline(coef(z5))\nk=(trees$Height)^2\nz5.ls <- lm(trees$Volume ~k )\nabline(z5.ls$coef, lty=2,col=\"red\")\nlegend(x = 4000, y = 72, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\n# 4) Huh\nvh=trees$Volume/trees$Height\nplot(y=vh,x=trees$Height,main=\"Linearity of volume/height and height\",xlab=\"height\",ylab=\"volume/height\")\n(z6 <- line(x=trees$Height,y=vh))\n\n\nCall:\nline(x = trees$Height, y = vh)\n\nCoefficients:\n[1]  -1.12720   0.01978\n\nabline(coef(z6))\nz6.ls <- lm(vh~trees$Height)\nabline(z6.ls$coef, lty=2,col=\"red\")\nlegend(x = 64, y = 0.85, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\n\n총 네가지 방법으로 변환을 진행해 보았는데 4가지 표현 중 x변수를 변환하는 방법의 경우 r-line 위쪽 부분의 점들이 어느정도 r-line에 평행하게 선형성을 보이고 있으나 밑부분의 점들은 선형적이지 않아 선택하지 않았다. y변수에 대한 변환 중 log와 sqrt를 비교할 경우 log 변환을 한 Plot의 가장 큰 점인 (90,4.5) 부근에 한 점이 가장자리 점들을 기준으로 한 선위에서 약간 벗어난 것으로 보이기 때문에 y변수에 대한 sqrt 변환이 log변환에 비해서 적합하다고 판단하였다.\n\nplot(y=log(trees$Volume),x=log(trees$Height),main=\"Linearity of log(volume) and log(height)\",xlab=\"log height\",ylab=\"log volume\")\n(z7 <- line(x=log(trees$Height),y=log(trees$Volume)))\n\n\nCall:\nline(x = log(trees$Height), y = log(trees$Volume))\n\nCoefficients:\n[1]  -16.582    4.573\n\nabline(coef(z7))\nz7.ls <- lm(log(trees$Volume) ~ log(trees$Height))\nabline(z7.ls$coef, lty=2,col=\"red\")\nlegend(x = 4.15, y = 4.15, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(y=sqrt(trees$Volume),x=sqrt(trees$Height),main=\"Linearity of sqrt(volume) and sqrt(height)\",xlab=\"sqrt height\",ylab=\"sqrt volume\")\n(z8 <- line(x=sqrt(trees$Height),y=sqrt(trees$Volume)))\n\n\nCall:\nline(x = sqrt(trees$Height), y = sqrt(trees$Volume))\n\nCoefficients:\n[1]  -20.50    2.94\n\nabline(coef(z8))\nz8.ls <- lm(sqrt(trees$Volume) ~ sqrt(trees$Height))\nabline(z8.ls$coef, lty=2,col=\"red\")\nlegend(x = 8, y = 8.5, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\n\n추가로 x축 y축 전부에 log와 sqrt 변환을 적용하였는데 위의 변환들 보다 잔차들이 안정되어진 것으로 추정된다.\n\n\n\n(다)에 찾은 변환으로 각기 r-line으로 적합하고 residual plot, residual의 boxplot, stem-and-leaf display 등으로 적합성를 비교하여라.\n\nplot(residuals(z3) ~ fitted(z3), main = \"Residual plot by rline:sqrt(volume) ~ height\")\nabline(0,0)    \n\n\n\nplot(residuals(z4) ~ fitted(z4), main = \"Residual plot by rline:log(volume) ~ height\")\nabline(0,0) \n\n\n\nplot(residuals(z5) ~ fitted(z5), main = \"Residual plot by rline:volume ~ height^2\")\nabline(0,0)    \n\n\n\nplot(residuals(z6) ~ fitted(z6), main = \"Residual plot by rline:volume/height ~ height\")\nabline(0,0) \n\n\n\nplot(residuals(z7) ~ fitted(z7), main = \"Residual plot by rline:log volume ~ log height\")\nabline(0,0) \n\n\n\nplot(residuals(z8) ~ fitted(z8), main = \"Residual plot by rline:sqrt volume ~ sqrt height\")\nabline(0,0) \n\n\n\n\n그러나 Residual plot을 그려볼 경우 여러 변환들 중 적합해 보이는 것은 y변수에 대한 log 변환인 것으로 보인다. 나머지 변환의 경우 직선 밑 부분의 점들이 점점 줄어들고 있는 경향성이 나타나고 있는데 그럴경우 적합하지 않은 변환이기 때문이다\ny변수에만 log변환을 한 경우를 다른 Residual plot을 비교할 경우 미묘한 차이지만 맨위에 있는 4개의 점들이 줄어드는 경향성이 있고 마지막점의 이상성이 다소 있다는 점에서 단점이 있지만 전반적인 Residual Plot을 비교하면 log가 가장 적정해 보인다.\n\nboxplot(residuals(z3),main=\"Residual boxplot of sqrt(volume) ~ height\")\n\n\n\nboxplot(residuals(z4),main=\"Residual boxplot of log(volume) ~ height\")\n\n\n\nboxplot(residuals(z5),main=\"Residual boxplot of volume ~ height^2\")\n\n\n\nboxplot(residuals(z6),main=\"Residual boxplot of volume/height ~ height\")\n\n\n\nboxplot(residuals(z7),main=\"Residual boxplot of xy log\")\n\n\n\nboxplot(residuals(z8),main=\"Residual boxplot of xy sqrt\")\n\n\n\n\n첫번째, 두번째 boxplot의 경우 median이 lower hinge쪽에 더 가까운 것으로 보인다. 또 Whisker의 길이도 lower whisker쪽이 더 길게 나타나고 있다. Whisker의 길이와 Box내의 대칭성의 경우 3번째 Boxplot이 가장 대칭적인 것으로 보인다. 그럼에도 불구하고 log변환에서 대칭성이 크게 감소하지는 않았다는 점에서 사용 가능한 변환으로 보인다.\nx변수와 y변수에 동시에 log변환을 취한 boxplot이 y변수에만 log변환을 취한 boxplot에 비해서 whisker의 길이가 대칭적이 된 것으로 보인다.\n\nstem(residuals(z3))\n\n\n  The decimal point is at the |\n\n  -1 | 865\n  -1 | 0\n  -0 | 887655\n  -0 | 443100\n   0 | 3\n   0 | 5678\n   1 | 33444\n   1 | 58899\n\nstem(residuals(z4))\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -6 | 6\n  -4 | 821\n  -2 | 454110\n  -0 | 77650\n   0 | 014\n   2 | 174\n   4 | 4688900\n   6 | 173\n\nstem(residuals(z5))\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  -2 | 431\n  -1 | 55\n  -1 | 20\n  -0 | 9999866\n  -0 | 40\n   0 | 1344\n   0 | 5\n   1 | 01344\n   1 | 566\n   2 | 04\n\nstem(residuals(z6))\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -2 | 864\n  -1 | 7631100\n  -0 | 99764\n   0 | 034678\n   1 | 56889\n   2 | 14579\n\nstem(residuals(z7))\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -6 | 4\n  -4 | 818\n  -2 | 46111\n  -0 | 887764\n   0 | 007\n   2 | 084\n   4 | 5789900\n   6 | 178\n\nstem(residuals(z8))\n\n\n  The decimal point is at the |\n\n  -1 | 965\n  -1 | 0\n  -0 | 98776655\n  -0 | 421\n   0 | 044\n   0 | 678\n   1 | 22334\n   1 | 5788\n   2 | 0\n\nstem(residuals(z3),0.5)\n\n\n  The decimal point is at the |\n\n  -1 | 8650\n  -0 | 887655443100\n   0 | 35678\n   1 | 3344458899\n\nstem(residuals(z4),0.5)\n\n\n  The decimal point is at the |\n\n  -0 | 7655\n  -0 | 33222222221\n   0 | 0012334\n   0 | 555555677\n\nstem(residuals(z5),0.5)\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  -2 | 431\n  -1 | 5520\n  -0 | 999986640\n   0 | 13445\n   1 | 01344566\n   2 | 04\n\nstem(residuals(z6),0.5)\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -2 | 864\n  -0 | 763110099764\n   0 | 03467856889\n   2 | 14579\n\nstem(residuals(z7),0.5)\n\n\n  The decimal point is at the |\n\n  -0 | 6655\n  -0 | 33222222220\n   0 | 002233\n   0 | 5555555678\n\nstem(residuals(z8),0.5)\n\n\n  The decimal point is at the |\n\n  -1 | 9650\n  -0 | 98776655421\n   0 | 044678\n   1 | 223345788\n   2 | 0\n\n\n전반적으로 가장 큰 Cluster를 기준으로 대칭적인 종모양을 띄고 있지는 않은 것으로 보인다. y변수에 대한 sqrt변환의 경우와 log변환의 경우 그리고 x변수에 대한 제곱 변환의 경우 한개의 Cluster가 아니라 여러개의 Cluster가 있는 것으로 보인다. 교재에서 제시한 변환 방식이 Skewed to the right 되어 있지만 그나마 한개의 종모양의 형태를 띄고 있는 것으로 보인다.\nxy변수에 대한 log변환을 취한 경우 Stem 4를 제외하면 전반적으로 종모양이 잘 이루어지고 있는 것으로 보인다. stem 4가 이상치가 아니라면 2개의 cluster에 의한 쌍봉분포일 것이고, stem 4가 이상치라면 정규분포를 잘 이루고 있는 것으로 볼 수 있다."
  },
  {
    "objectID": "data_analytics/EDA7.html#가-1",
    "href": "data_analytics/EDA7.html#가-1",
    "title": "EDA Assignment 7: Chapter 9",
    "section": "(가)",
    "text": "(가)\nOzone을 Y변수로 하고, Solar.R, Wind, Temp 각각의 세 X 변수에 대하여 산점도를 그리고 변환이 필요하면 변환하여 r-line으로 적합한 후 residual 분석 등으로 최적 X 변수의 순위를 선정하여라.\n\n결측치 확인하기\n\ndata(\"airquality\")\n\ncolSums(is.na(airquality))\n\n  Ozone Solar.R    Wind    Temp   Month     Day \n     37       7       0       0       0       0 \n\ndim(airquality)\n\n[1] 153   6\n\nround(colSums(is.na(airquality))/dim(airquality)[1]*100,2)\n\n  Ozone Solar.R    Wind    Temp   Month     Day \n  24.18    4.58    0.00    0.00    0.00    0.00 \n\n\nOzone 자료의 결측치 비율이 24.18%로 거의 1/4에 해당하는 자료에 대한 Ozone 데이터가 나타나지 않은 것으로 보인다. 따라서 분석을 진행 할때 있어 이부분을 유의해야 할 것으로 보인다. Solar.R자료는 약 4.58%에 해당하는 자료가 현재 결측되어진 것으로 보인다.\n\n\nOzone~Solar.R\n\nattach(airquality)\nplot(Ozone~Solar.R,main=\"linearity of Ozone ~ Solar\")\n\n\n\nlength(Ozone) # 51개씩 쪼개기\n\n[1] 153\n\nairquality2=airquality[order(airquality$Solar.R),]\n\nmedOzone <- as.vector(3)\nmedSolar <- as.vector(3)\nmedOzone[1] <- median(airquality2$Ozone[1:51],na.rm=T); medSolar[1] <- median(airquality2$Solar.R[1:51],na.rm=T)\nmedOzone[2] <- median(airquality2$Ozone[52:102],na.rm=T); medSolar[2] <- median(airquality2$Solar.R[52:102],na.rm=T)\nmedOzone[3] <- median(airquality2$Ozone[103:153],na.rm=T); medSolar[3] <- median(airquality2$Solar.R[103:153],na.rm=T)\nplot(medOzone ~ medSolar, type=\"b\") \n\n\n\n# 선형관계보다는 기울기가 음수인 이차함수의 관계인 것으로 보인다. y변수 변환을 통해 선형성을 확보 \n\nplot(y=log(Ozone),x=Solar.R,main=\"Linearity of log(Ozone) and Solar.R\",xlab=\"Solar.R\",ylab=\"log(Ozone)\")\n(z1 <- line(y=log(Ozone),x=Solar.R))\n\n\nCall:\nline(y = log(Ozone), x = Solar.R)\n\nCoefficients:\n[1]  2.74304  0.00341\n\nabline(coef(z1))\nz1.ls <- lm(log(Ozone) ~ Solar.R)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 250, y = 1, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(y=sqrt(Ozone),x=Solar.R,main=\"Linearity of sqrt(Ozone) and Solar.R\",xlab=\"Solar.R\",ylab=\"sqrt(Ozone)\")\n(z2 <- line(y=sqrt(Ozone),x=Solar.R))\n\n\nCall:\nline(y = sqrt(Ozone), x = Solar.R)\n\nCoefficients:\n[1]  3.808932  0.008582\n\nabline(coef(z2))\nz2.ls <- lm(sqrt(Ozone) ~ Solar.R)\nabline(z2.ls$coef, lty=2,col=\"red\")\nlegend(x = 10, y = 12, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\ns2=Solar.R^2\nplot(y=Ozone,x=s2,main=\"Linearity of Ozone and Solar.R^2\",xlab=\"Solar.R^2\",ylab=\"Ozone\")\n(z3 <- line(y=Ozone,x=s2))\n\n\nCall:\nline(y = Ozone, x = s2)\n\nCoefficients:\n[1]  1.935e+01  2.498e-04\n\nabline(coef(z3))\nz3.ls <- lm(Ozone ~ s2)\nabline(z3.ls$coef, lty=2,col=\"red\")\nlegend(x = 10, y =150, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline:log y ~ x\")\nabline(0,0) \n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by rline:sqrt y ~ x\")\nabline(0,0) \n\n\n\nplot(residuals(z3) ~ fitted(z3), main = \"Residual plot by rline: y~ x^2\")\nabline(0,0) \n\n\n\n# log 변환 \nboxplot(residuals(z1)) # outlier 1개\n\n\n\nboxplot(residuals(z2)) # outlier 없음\n\n\n\nboxplot(residuals(z3)) # outlier 2개\n\n\n\n# stem and leaf\nstem(residuals(z1))\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -26 | 7\n  -24 | \n  -22 | \n  -20 | \n  -18 | \n  -16 | \n  -14 | 44\n  -12 | 4342\n  -10 | 4\n   -8 | 96624\n   -6 | 763776533321\n   -4 | 88610854\n   -2 | 865407632\n   -0 | 8744221088742\n    0 | 001139\n    2 | 0344802445799\n    4 | 0114735\n    6 | 44568\n    8 | 1280002234469\n   10 | 602689\n   12 | 44556\n   14 | 7\n\nstem(residuals(z2))\n\n\n  The decimal point is at the |\n\n  -3 | 20\n  -2 | 999432000\n  -1 | 7666655544443221111000\n  -0 | 9999766543333222221110\n   0 | 0013357899999\n   1 | 001111222677\n   2 | 0122667799\n   3 | 223344577789\n   4 | 1679\n   5 | 0015\n   6 | \n   7 | 1\n\nstem(residuals(z3))\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  -3 | 43\n  -2 | 976400\n  -1 | 986555554433332221111000\n  -0 | 99998776655543333222211\n   0 | 00011446\n   1 | 011122233344568\n   2 | 1459\n   3 | 01279999\n   4 | 2569\n   5 | 1117789\n   6 | 03\n   7 | 06\n   8 | 0366\n   9 | 8\n  10 | \n  11 | \n  12 | \n  13 | 5\n\ncor.test(Ozone,Solar.R,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  Ozone and Solar.R\nt = 3.8798, df = 109, p-value = 0.0001793\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.173194 0.502132\nsample estimates:\n      cor \n0.3483417 \n\ncor.test(log(Ozone),Solar.R,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  log(Ozone) and Solar.R\nt = 5.3509, df = 109, p-value = 4.885e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2947757 0.5921585\nsample estimates:\n      cor \n0.4561082 \n\ncor.test(sqrt(Ozone),Solar.R,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  sqrt(Ozone) and Solar.R\nt = 4.5948, df = 109, p-value = 1.17e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2339963 0.5480629\nsample estimates:\n      cor \n0.4028201 \n\ncor.test(Ozone,s2,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  Ozone and s2\nt = 2.8565, df = 109, p-value = 0.00513\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.08152183 0.42918594\nsample estimates:\n      cor \n0.2639047 \n\n# y변수에 그래프의 잔차제곱 합\nsum(residuals(z1)^2)\n\n[1] 66.29339\n\nsum(residuals(z2)^2)\n\n[1] 596.0805\n\nsum(residuals(z3)^2)\n\n[1] 129877.1\n\ndetach(airquality)\n\n총 3가지 변환 중 y축에 대한 변환들이 잔차들이 안정되어진 것으로 보인다. 1번 변환 (y변수만 log 변환)의 경우 자료가 잘 퍼져있다는 장점이 있으나 잔차들의 곡선의 경향성이 완전히 사라지지는 않은 것으로 보인다. 잔차의 크기가 작은 편이다. 2번 변환 (y변수만 sqrt 변환)의 경우 자료에서의 곡선성이 거의 사라졌다는 장점이 있으나 잔차의 y축으로 퍼진 범위가 넓어졌다.\n변환한 그래프들을 기준으로 전반적으로 Ozone량과 Solar.R의 값은 양의 상관관계를 가지고 있는 것으로 보인다.\n\n\nOzone~Wind\n\nattach(airquality)\nattach(airquality)\n\nThe following objects are masked from airquality (pos = 3):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\nplot(Ozone~Wind,main=\"linearity of Ozone ~ Wind\")\n(z <- line(x=Wind,y=Ozone))\n\n\nCall:\nline(x = Wind, y = Ozone)\n\nCoefficients:\n[1]  113.175   -7.417\n\nabline(coef(z))\nz.ls <- lm(Ozone~Wind)\nabline(z.ls$coef, lty=2,col=\"red\")\nlegend(x = 16, y = 150, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nairquality2=airquality[order(airquality$Wind),]\n\nmedOzone <- as.vector(3)\nmedWind <- as.vector(3)\nmedOzone[1] <- median(airquality2$Ozone[1:51],na.rm=T); medWind[1] <- median(airquality2$Wind[1:51],na.rm=T)\nmedOzone[2] <- median(airquality2$Ozone[52:102],na.rm=T); medWind[2] <- median(airquality2$Wind[52:102],na.rm=T)\nmedOzone[3] <- median(airquality2$Ozone[103:153],na.rm=T); medWind[3] <- median(airquality2$Wind[103:153],na.rm=T)\nplot(medOzone ~ medWind, type=\"b\") \n\n\n\n# 감소하는 convex 함수의 관계인 것으로 보인다. y변수 변환을 통해 선형성을 확보\nplot(y=log(Ozone),x=Wind,main=\"Linearity of log(Ozone) and Wind\")\n(z1 <- line(y=log(Ozone),x=Wind))\n\n\nCall:\nline(y = log(Ozone), x = Wind)\n\nCoefficients:\n[1]   5.3333  -0.1924\n\nabline(coef(z1))\nz1.ls <- lm(log(Ozone) ~ Wind)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 2, y = 1, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(y=sqrt(Ozone),x=Wind,main=\"Linearity of sqrt(Ozone) and Wind\")\n(z2 <- line(y=sqrt(Ozone),x=Wind))\n\n\nCall:\nline(y = sqrt(Ozone), x = Wind)\n\nCoefficients:\n[1]  11.8507  -0.5891\n\nabline(coef(z2))\nz2.ls <- lm(sqrt(Ozone) ~ Wind)\nabline(z2.ls$coef, lty=2,col=\"red\")\nlegend(x = 16, y = 12, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nw2=Wind^2\nplot(y=Ozone,x=w2,main=\"Linearity of Ozone and Wind^2\")\n(z3 <- line(y=Ozone,x=w2))\n\n\nCall:\nline(y = Ozone, x = w2)\n\nCoefficients:\n[1]  79.8590  -0.3743\n\nabline(coef(z3))\nz3.ls <- lm(Ozone ~ w2)\nabline(z3.ls$coef, lty=2,col=\"red\")\nlegend(x = 300, y =150, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nplot(residuals(z3) ~ fitted(z3), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nboxplot(residuals(z1)) # three outliers\n\n\n\nboxplot(residuals(z2)) # one outlier\n\n\n\nboxplot(residuals(z3)) # two outliers\n\n\n\nstem(residuals(z1))\n\n\n  The decimal point is at the |\n\n  -3 | 5\n  -3 | \n  -2 | \n  -2 | 11\n  -1 | \n  -1 | 4221100\n  -0 | 988887776666665555\n  -0 | 444433333333222222221111110000\n   0 | 000111122222223333333344444\n   0 | 555555555566677777899999\n   1 | 01133\n   1 | 6\n   2 | 3\n\nstem(residuals(z2))\n\n\n  The decimal point is at the |\n\n  -5 | 11\n  -4 | 1\n  -3 | 85111\n  -2 | 9887433322100\n  -1 | 7766655432111100000\n  -0 | 998888887665443310\n   0 | 0011222344455666999\n   1 | 00012234445666777999\n   2 | 01222246899\n   3 | 134667\n   4 | 7\n   5 | \n   6 | 4\n\nstem(residuals(z3))\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  -5 | 5\n  -4 | 64310\n  -3 | 877643322\n  -2 | 9987765432110\n  -1 | 8887766666544220\n  -0 | 98876654444320\n   0 | 00134455667788999\n   1 | 01146799\n   2 | 00346689\n   3 | 0111123447\n   4 | 0277889\n   5 | 234\n   6 | 12\n   7 | 9\n   8 | \n   9 | 2\n  10 | \n  11 | 8\n\n# y변수 그래프의 잔차제곱 합\nsum(residuals(z1)^2)\n\n[1] 66.85564\n\nsum(residuals(z2)^2)\n\n[1] 489.5301\n\nsum(residuals(z3)^2)\n\n[1] 113187.1\n\ncor.test(Ozone,Wind,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  Ozone and Wind\nt = -8.0401, df = 114, p-value = 9.272e-13\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7063918 -0.4708713\nsample estimates:\n       cor \n-0.6015465 \n\ncor.test(log(Ozone),Wind,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  log(Ozone) and Wind\nt = -6.822, df = 114, p-value = 4.551e-10\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.6563096 -0.3948621\nsample estimates:\n       cor \n-0.5384181 \n\ncor.test(sqrt(Ozone),Wind,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  sqrt(Ozone) and Wind\nt = -7.8938, df = 114, p-value = 1.983e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7008452 -0.4622775\nsample estimates:\n       cor \n-0.5944899 \n\ncor.test(Ozone,w2,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  Ozone and w2\nt = -6.2579, df = 114, p-value = 7.055e-09\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.6298998 -0.3561715\nsample estimates:\n      cor \n-0.505653 \n\ndetach(airquality)\n\n3가지 변환 중 Ozone에 sqrt를 취한 변환이 가장 적절해 보인다. Boxplot 기준으로 Residual에서 한개의 Outlier가 존재하고 median에서 hinge들 까지의 길이와 whisker의 길이들이 서로 각각 대칭적인 것으로 보인다. 줄기 잎 그림을 그렸더니 두 변환에서 모두 0을 중심으로 하는 종모양을 어느정도 이루고 있는 것으로 보인다. 변환 이전에 비해서 잔차들이 안정된 것으로 보이지만 완전하지 않다. 변환한 데이터들 기준으로 Ozone과 Wind는 전반적으로 음의 상관관계를 보이고 있는 것을 확인할 수 있다.\n\n### Ozone~Temp\nattach(airquality)\n\nThe following objects are masked from airquality (pos = 3):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\nplot(Ozone~Temp,main=\"linearity of Ozone ~ Temp\")\n(z <- line(x=Temp,y=Ozone))\n\n\nCall:\nline(x = Temp, y = Ozone)\n\nCoefficients:\n[1]  -194.216     3.027\n\nabline(coef(z))\nz.ls <- lm(Ozone~Temp)\nabline(z.ls$coef, lty=2,col=\"red\")\nlegend(x = 58, y = 150, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\n# 직선에서 많이 떨어져있는 3~5개정도의 점을 제외하면 전반적으로 변수들이 양의 상관관계를 보이고 있는 것으로 보인다.\n\nairquality3=airquality[order(airquality$Temp),]\n\nmedOzone <- as.vector(3)\nmedTemp <- as.vector(3)\nmedOzone[1] <- median(airquality3$Ozone[1:51],na.rm=T); medTemp[1] <- median(airquality3$Temp[1:51],na.rm=T)\nmedOzone[2] <- median(airquality3$Ozone[52:102],na.rm=T); medTemp[2] <- median(airquality3$Temp[52:102],na.rm=T)\nmedOzone[3] <- median(airquality3$Ozone[103:153],na.rm=T); medTemp[3] <- median(airquality3$Temp[103:153],na.rm=T)\nplot(medOzone ~ medTemp, type=\"b\") \n\n\n\n# 증가하는 convex 함수의 관계인 것으로 보인다. y변수 변환을 통해 선형성을 확보 \n\nplot(y=log(Ozone),x=Temp,main=\"Linearity of log ozone and temp\",xlab=\"temp\",ylab=\"log Ozone\")\n(z1<- line(y=log(Ozone),x=(Temp)))\n\n\nCall:\nline(y = log(Ozone), x = (Temp))\n\nCoefficients:\n[1]  -2.8968   0.0813\n\nabline(coef(z1))\nz1.ls <- lm(log(Ozone) ~ Temp)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 58, y = 5, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(y=sqrt(Ozone),x=Temp,main=\"Linearity of sqrt ozone and temp\",xlab=\"temp\",ylab=\"sqrt Ozone\")\n(z2<- line(y=sqrt(Ozone),x=Temp))\n\n\nCall:\nline(y = sqrt(Ozone), x = Temp)\n\nCoefficients:\n[1]  -12.7938    0.2424\n\nabline(coef(z2))\nz2.ls <- lm(sqrt(Ozone) ~ Temp)\nabline(z2.ls$coef, lty=2,col=\"red\")\nlegend(x = 58, y = 12, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nt2=Temp^2\nplot(Ozone~t2,main=\"linearity of Ozone ~ Temp^2\")\n(z3 <- line(x=t2,y=Ozone))\n\n\nCall:\nline(x = t2, y = Ozone)\n\nCoefficients:\n[1]  -79.53178    0.01972\n\nabline(coef(z3))\nz3.ls <- lm(Ozone~t2)\nabline(z3.ls$coef, lty=2,col=\"red\")\nlegend(x = 3000, y = 150, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nplot(residuals(z3) ~ fitted(z3), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nboxplot(residuals(z1)) # 5 outliers\n\n\n\nboxplot(residuals(z2)) # 2 outliers\n\n\n\nboxplot(residuals(z3)) # 3 outliers\n\n\n\nstem(residuals(z1))\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -18 | 0\n  -16 | 6\n  -14 | 9\n  -12 | \n  -10 | 700\n   -8 | \n   -6 | 7764228864331\n   -4 | 65187640\n   -2 | 9975322111074321\n   -0 | 866655420732111\n    0 | 112356679002345889\n    2 | 05666889113344689\n    4 | 175579\n    6 | 11357557\n    8 | 67\n   10 | 4676\n   12 | 2\n   14 | 04\n\nstem(residuals(z2))\n\n\n  The decimal point is at the |\n\n  -4 | 0\n  -3 | 811\n  -2 | 65311000\n  -1 | 9987777666444443333322221000\n  -0 | 888888876665522210\n   0 | 0011112233344455555677788888999\n   1 | 012333334455588\n   2 | 013668\n   3 | 007\n   4 | 04\n   5 | \n   6 | 1\n\nstem(residuals(z3))\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  -4 | 10\n  -3 | 773100\n  -2 | 88754332111\n  -1 | 888877666666655444443211100\n  -0 | 999977654220\n   0 | 011223344567888899999\n   1 | 0002222233344445556889\n   2 | 12238\n   3 | 00128\n   4 | 55\n   5 | \n   6 | \n   7 | 15\n   8 | \n   9 | \n  10 | \n  11 | 8\n\n# y변수 그래프의 잔차제곱 합\nsum(residuals(z1)^2)\n\n[1] 40.98835\n\nsum(residuals(z2)^2)\n\n[1] 332.1941\n\nsum(residuals(z3)^2)\n\n[1] 64694.05\n\ncor.test(Ozone,Temp)\n\n\n    Pearson's product-moment correlation\n\ndata:  Ozone and Temp\nt = 10.418, df = 114, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5913340 0.7812111\nsample estimates:\n      cor \n0.6983603 \n\ncor.test(sqrt(Ozone),(Temp))\n\n\n    Pearson's product-moment correlation\n\ndata:  sqrt(Ozone) and (Temp)\nt = 11.869, df = 114, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6491335 0.8152728\nsample estimates:\n      cor \n0.7434629 \n\ncor.test(log(Ozone),(Temp))\n\n\n    Pearson's product-moment correlation\n\ndata:  log(Ozone) and (Temp)\nt = 11.741, df = 114, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6444258 0.8125409\nsample estimates:\n      cor \n0.7398211 \n\ncor.test((Ozone),t2)\n\n\n    Pearson's product-moment correlation\n\ndata:  (Ozone) and t2\nt = 10.859, df = 114, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6100642 0.7923742\nsample estimates:\n      cor \n0.7130697 \n\ndetach(airquality)\n\n3가지 변환 중 sqrt 변환이 가장 적절해 보인다. boxplot 기준으로 median에서 hinge들까지의 거리가 적절해보이고 (다소 위쪽으로 몰려있는 것 처럼 보이지만), whisker의 길이도 대칭적인 것으로 보인다. 다만 outlier의 수는 2개이다. Stem and Leaf Plot에서 변환 이후 데이터에서 종 모양이 대칭적으로 나타나는 것 처럼 보인다.\n변환한 데이터들 기준으로 Ozone과 Temp는 전반적으로 양의 상관관계를 보이고 있는 것을 확인할 수 있다.\n변환된 데이터들의 Residual plot들을 기준으로 볼 때 예측력이 가장 높은 지표는 Wind변수이고, 다음으로는 Temp변수이고, 다음으로는 Solar.R변수 인 것으로 추측된다. Residual들이 가장 넓게 퍼져있는 지표는 Soalr.R변수이고 나머지 두변수들은 Residual이 원형으로 다소 뭉쳐있는데 상대적으로 Temp 변수들이 많이 퍼져있기 때문에 Wind 변수의 순위를 높게 잡았다.\nX~Y둘다 변환\n\nchoose(3,1)\n\n[1] 3\n\nattach(airquality)\n\nThe following objects are masked from airquality (pos = 3):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\n# Ozone ~ Solar.R\ncor.test(Ozone,Solar.R)\n\n\n    Pearson's product-moment correlation\n\ndata:  Ozone and Solar.R\nt = 3.8798, df = 109, p-value = 0.0001793\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.173194 0.502132\nsample estimates:\n      cor \n0.3483417 \n\nplot(y=log(Ozone),x=Solar.R,main=\"R-line\")\nabline(line(y=log(Ozone),x=Solar.R)$coeff)\n\n\n\nplot(y=log(Ozone),x=log(Solar.R),main=\"R-line: log\")\n(z1 <- line(y=log(Ozone),x=log(Solar.R)))\n\n\nCall:\nline(y = log(Ozone), x = log(Solar.R))\n\nCoefficients:\n[1]  0.8148  0.5269\n\nabline(coef(z1))\nz1.ls <- lm(log(Ozone) ~ log(Solar.R))\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 2, y = 4.5, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(y=sqrt(Ozone),x=sqrt(Solar.R),main=\"R-line: sqrt\")\n(z2 <- line(y=sqrt(Ozone),x=sqrt(Solar.R)))\n\n\nCall:\nline(y = sqrt(Ozone), x = sqrt(Solar.R))\n\nCoefficients:\n[1]  2.5206  0.2168\n\nabline(coef(z2))\nz2.ls <- lm(sqrt(Ozone) ~ sqrt(Solar.R))\nabline(z2.ls$coef, lty=2,col=\"red\")\nlegend(x = 3, y = 12, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline: log\") #오른쪽으로 잔차들이 몰리게 되었다는 점에서 부적절한 변환으로 보임.\nabline(0,0)  \n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by rline: sqrt\") #한개의 outlier만 제외 하면 전반적으로 변환 이전에 비해서 잔차들이 잘 퍼져있는 것으로 보임. \nabline(0,0)\n\n\n\nboxplot(residuals(z1)) # outlier 없음\n\n\n\nboxplot(residuals(z2)) # outlier 1개\n\n\n\nstem(residuals(z1)) \n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -18 | 1\n  -16 | \n  -14 | 650\n  -12 | 24\n  -10 | 332\n   -8 | 765421544\n   -6 | 84300874\n   -4 | 642219641\n   -2 | 7311999984320\n   -0 | 9887632\n    0 | 013893334777\n    2 | 005577825\n    4 | 369277\n    6 | 245023367\n    8 | 01112713337\n   10 | 25788049\n   12 | \n   14 | 3\n\nstem(residuals(z2)) \n\n\n  The decimal point is at the |\n\n  -3 | 1\n  -2 | 997431100\n  -1 | 876655554444432210\n  -0 | 999888666665443322221111000\n   0 | 033467899999\n   1 | 0011111155677\n   2 | 0222677788\n   3 | 113344667888\n   4 | 0568\n   5 | 0115\n   6 | \n   7 | 1\n\n# Y만 변환일 때에 비해 잔차들이 보이던 곡선의 경향성이 다소 완화되어진 것을 확인할 수 있다.\n\n\n# Ozone ~ Wind\ncor.test(Ozone,Wind)\n\n\n    Pearson's product-moment correlation\n\ndata:  Ozone and Wind\nt = -8.0401, df = 114, p-value = 9.272e-13\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7063918 -0.4708713\nsample estimates:\n       cor \n-0.6015465 \n\nplot(y=log(Ozone),x=Wind,main=\"R-line\")\nabline(line(y=log(Ozone),x=Wind)$coeff)\n\n\n\nplot(line(y=log(Ozone),x=Wind)$residuals~line(y=log(Ozone),x=Wind)$fit)\nabline(0,0) # 다소 곡선의 형태\n\n\n\nplot(y=log(Ozone),x=log(Wind),main=\"R-line: log\")\n(z1 <- line(y=log(Ozone),x=log(Wind)))\n\n\nCall:\nline(y = log(Ozone), x = log(Wind))\n\nCoefficients:\n[1]   7.492  -1.845\n\nabline(coef(z1))\nz1.ls <- lm(log(Ozone) ~ log(Wind))\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 0.5, y = 4.5, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(y=sqrt(Ozone),x=sqrt(Wind),main=\"R-line: sqrt\")\n(z2 <- line(y=sqrt(Ozone),x=sqrt(Wind)))\n\n\nCall:\nline(y = sqrt(Ozone), x = sqrt(Wind))\n\nCoefficients:\n[1]  17.078  -3.664\n\nabline(coef(z2))\nz2.ls <- lm(sqrt(Ozone) ~ sqrt(Wind))\nabline(z2.ls$coef, lty=2,col=\"red\")\nlegend(x = 1.5, y = 4, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline: log\") # Outlier 제외할 경우에도 약간의 곡선의 흔적이 남아있는 것으로 보임.\nabline(0,0)  \n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by rline: sqrt\") # 여전히 완벽하게 잔차를 퍼트리지는 못한 것으로 보이고 곡선의 흔적이 보임\nabline(0,0)\n\n\n\nboxplot(residuals(z1)) # outlier 3개\n\n\n\nboxplot(residuals(z2)) # outlier 1개\n\n\n\nstem(residuals(z1)) \n\n\n  The decimal point is at the |\n\n  -3 | 3\n  -2 | \n  -2 | 0\n  -1 | 9\n  -1 | 322200\n  -0 | 99988766655555555\n  -0 | 44444333333322211111111111111000\n   0 | 0001111111222333333344444\n   0 | 5555566666666667788899\n   1 | 000002333\n   1 | 67\n\nstem(residuals(z2)) \n\n\n  The decimal point is at the |\n\n  -4 | 87\n  -3 | 751\n  -2 | 7766543300\n  -1 | 9977755222222100\n  -0 | 987777666555554443332221100\n   0 | 01345566678899\n   1 | 001233333344566678999\n   2 | 0001233444668\n   3 | 0137788\n   4 | 1\n   5 | 07\n\n# Y만 변환일 때에 비해 잔차들이 보이던 곡선의 경향성이 다소 완화되어진 것을 확인할 수 있다. 잔차들이 조금 더 y축을 기준으로 대칭적이 된 것을 확인할 수 있다.\n\n\n\n# Ozone ~ Temp\ncor.test(Ozone,Temp)\n\n\n    Pearson's product-moment correlation\n\ndata:  Ozone and Temp\nt = 10.418, df = 114, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5913340 0.7812111\nsample estimates:\n      cor \n0.6983603 \n\nplot(y=log(Ozone),x=Temp,main=\"R-line\")\nabline(line(y=log(Ozone),x=Temp)$coeff)\n\n\n\nplot(line(y=log(Ozone),x=Temp)$residuals~line(y=log(Ozone),x=Temp)$fitted)\nabline(0,0) # outleir을 제외하더라도 다소 대칭적이지는 않아보임 (곡선 관계가 남아있는 것 같아보이지만 확실하지는 않음)\n\n\n\nplot(y=log(Ozone),x=log(Temp),main=\"R-line: log\")\n(z1 <- line(y=log(Ozone),x=log(Temp)))\n\n\nCall:\nline(y = log(Ozone), x = log(Temp))\n\nCoefficients:\n[1]  -23.526    6.208\n\nabline(coef(z1))\nz1.ls <- lm(log(Ozone) ~ log(Temp))\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 4.05, y = 5., c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(y=sqrt(Ozone),x=sqrt(Temp),main=\"R-line: sqrt\")\n(z2 <- line(y=sqrt(Ozone),x=sqrt(Temp)))\n\n\nCall:\nline(y = sqrt(Ozone), x = sqrt(Temp))\n\nCoefficients:\n[1]  -31.28    4.24\n\nabline(coef(z2))\nz2.ls <- lm(sqrt(Ozone) ~ sqrt(Temp))\nabline(z2.ls$coef, lty=2,col=\"red\")\nlegend(x = 7.5, y = 12, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline: log\") # 곡선의 형태가 완화되고 잔차들이 y축을 기준으로 대칭되어 나타나는 것으로 보인다. \nabline(0,0)\n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by rline: sqrt\") # 여전히 완벽하게 잔차를 퍼트리지는 못한 것으로 보이고 곡선의 흔적이 보임\nabline(0,0)\n\n\n\nboxplot(residuals(z1)) # outlier 4개\n\n\n\nboxplot(residuals(z2)) # outlier 1개\n\n\n\nstem(residuals(z1))  # 0을 기준으로 종모양이 나타남\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -16 | 93\n  -14 | 6\n  -12 | 5\n  -10 | 66\n   -8 | 432100\n   -6 | 41108431\n   -4 | 54200776200\n   -2 | 987554229843322\n   -0 | 987651099931\n    0 | 133357788899013467\n    2 | 00235555679011224\n    4 | 468915669\n    6 | 03349\n    8 | 52\n   10 | 4345\n   12 | 17\n   14 | 7\n\nstem(residuals(z2)) \n\n\n  The decimal point is at the |\n\n  -4 | 0\n  -3 | 911\n  -2 | 6532110\n  -1 | 99888777776544444333222211100\n  -0 | 999888666665322110\n   0 | 0111222333455555566667788889\n   1 | 000122333444456789\n   2 | 11367\n   3 | 0128\n   4 | 03\n   5 | \n   6 | 1\n\n# 변환이후에는 변환 이전에 비해서 큰 차이가 없는 것 처럼 보이기는 한다. outlier들을 제외 하더라도 큰 차이는 없는 것으로 보인다.\n\n\nlmfit=lm(Ozone~Solar.R+Temp+Wind,data=airquality)\nsummary(lmfit)\n\n\nCall:\nlm(formula = Ozone ~ Solar.R + Temp + Wind, data = airquality)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-40.485 -14.219  -3.551  10.097  95.619 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -64.34208   23.05472  -2.791  0.00623 ** \nSolar.R       0.05982    0.02319   2.580  0.01124 *  \nTemp          1.65209    0.25353   6.516 2.42e-09 ***\nWind         -3.33359    0.65441  -5.094 1.52e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.18 on 107 degrees of freedom\n  (42 observations deleted due to missingness)\nMultiple R-squared:  0.6059,    Adjusted R-squared:  0.5948 \nF-statistic: 54.83 on 3 and 107 DF,  p-value: < 2.2e-16\n\nlmfit2=lm(sqrt(Ozone)~(Solar.R)+(Temp)+(Wind),data=airquality)\nsummary(lmfit2)\n\n\nCall:\nlm(formula = sqrt(Ozone) ~ (Solar.R) + (Temp) + (Wind), data = airquality)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0994 -1.0902 -0.2060  0.8784  4.7782 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -3.284232   1.545516  -2.125 0.035888 *  \nSolar.R      0.005556   0.001554   3.574 0.000528 ***\nTemp         0.134491   0.016996   7.913 2.46e-12 ***\nWind        -0.220179   0.043869  -5.019 2.08e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.42 on 107 degrees of freedom\n  (42 observations deleted due to missingness)\nMultiple R-squared:  0.6707,    Adjusted R-squared:  0.6614 \nF-statistic: 72.64 on 3 and 107 DF,  p-value: < 2.2e-16\n\nlmfit3=lm(log(Ozone)~(Solar.R)+(Temp)+(Wind),data=airquality)\nsummary(lmfit3)\n\n\nCall:\nlm(formula = log(Ozone) ~ (Solar.R) + (Temp) + (Wind), data = airquality)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.06193 -0.29970 -0.00231  0.30756  1.23578 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.2621323  0.5535669  -0.474 0.636798    \nSolar.R      0.0025152  0.0005567   4.518 1.62e-05 ***\nTemp         0.0491711  0.0060875   8.077 1.07e-12 ***\nWind        -0.0615625  0.0157130  -3.918 0.000158 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5086 on 107 degrees of freedom\n  (42 observations deleted due to missingness)\nMultiple R-squared:  0.6644,    Adjusted R-squared:  0.655 \nF-statistic: 70.62 on 3 and 107 DF,  p-value: < 2.2e-16\n\nlmfit4=lm(sqrt(Ozone)~sqrt(Solar.R)+sqrt(Temp)+sqrt(Wind),data=airquality)\nsummary(lmfit4)\n\n\nCall:\nlm(formula = sqrt(Ozone) ~ sqrt(Solar.R) + sqrt(Temp) + sqrt(Wind), \n    data = airquality)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1313 -1.0142 -0.2502  0.9461  4.2580 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   -9.59783    3.01971  -3.178 0.001937 ** \nsqrt(Solar.R)  0.12993    0.03477   3.737 0.000301 ***\nsqrt(Temp)     2.12867    0.29694   7.169 1.02e-10 ***\nsqrt(Wind)    -1.55165    0.26821  -5.785 7.28e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.392 on 107 degrees of freedom\n  (42 observations deleted due to missingness)\nMultiple R-squared:  0.6837,    Adjusted R-squared:  0.6748 \nF-statistic: 77.09 on 3 and 107 DF,  p-value: < 2.2e-16\n\n\n변환전 데이터로 회귀분석 기준으로 변수들의 설명력을 볼 경우 Wind, Temp, Solar.R순서이다. 다만, 변환이 이루어지지 않았기 때문에 극단치에 영향을 많이 받았을 가능성이 있다. Sqrt나 Log변환을 진행 한 이후 회귀분석을 진행하면 영향력이 강한 독립변수는 Wind, Temp, Solar.R동일한 순서인 것으로 보인다.\n위에서 상관계수를 계산했을 때 확인했던 것처럼 Wind는 음의 회귀계수, 나머지 두 독립변수는 양의 회귀게수이다.\n(결론)\nOzone 변수에 Sqrt를 취한 값에 대한 적합값의 잔차들을 제곱해서 더할 경우 다음과 같다. Solar.R: 596.0805 Wind: 489.5301 Temp: 332.194\n잔차 제곱합의 기준에서 가장 작은 순서대로 fitting이 잘 되었다고 하였을 때, Temp, Wind, Solar.R 변수들의 순서로 Multiple r-line을 적합해보고자 한다."
  },
  {
    "objectID": "data_analytics/EDA7.html#나-1",
    "href": "data_analytics/EDA7.html#나-1",
    "title": "EDA Assignment 7: Chapter 9",
    "section": "(나)",
    "text": "(나)\n세 X 변수 사이의 종속성(dependency)을 X-Y 그래프로 직선 또는 곡선 관계의 경향이 있는 지 판단하여라. 세 변수가 한꺼번에 종속 관계가 있을 수 있으나 3차원 그래프를 이용해야 하므로 일단 세 변수 중 두 개씩 골라 X-Y 그래프를 그리고 두 변수 사이의 직선 또는 곡선 관계를 파악하여라. 필요한 경우에는 r-line으로 적합하여 판단하여라. (이러한 분석은 다중회귀식으로 모형을 확장할 때 필요한 작업이다)\n\nchoose(3,2)\n\n[1] 3\n\n\n\nWind~Solar.R\n\nattach(airquality)\n\nThe following objects are masked from airquality (pos = 3):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\n\nThe following objects are masked from airquality (pos = 4):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\nplot(Wind~Solar.R,main=\"linearity of Solar.R ~ Wind\")\n\n\n\ncor.test(Wind,Solar.R) # 상관관계가 없음\n\n\n    Pearson's product-moment correlation\n\ndata:  Wind and Solar.R\nt = -0.6826, df = 144, p-value = 0.496\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2172359  0.1066406\nsample estimates:\n        cor \n-0.05679167 \n\ncor.test(Wind,sqrt(Solar.R)) # 상관관계가 없음\n\n\n    Pearson's product-moment correlation\n\ndata:  Wind and sqrt(Solar.R)\nt = -1.1529, df = 144, p-value = 0.2509\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.25413132  0.06787189\nsample estimates:\n        cor \n-0.09563089 \n\ncor.test(Wind,log(Solar.R)) # 상관관계가 없음\n\n\n    Pearson's product-moment correlation\n\ndata:  Wind and log(Solar.R)\nt = -1.4876, df = 144, p-value = 0.139\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.27988233  0.04022473\nsample estimates:\n       cor \n-0.1230276 \n\ncor.test(Wind,log(Solar.R)) # 상관관계가 없음\n\n\n    Pearson's product-moment correlation\n\ndata:  Wind and log(Solar.R)\nt = -1.4876, df = 144, p-value = 0.139\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.27988233  0.04022473\nsample estimates:\n       cor \n-0.1230276 \n\ncor.test(Wind,sqrt(Solar.R)) # 상관관계가 없음\n\n\n    Pearson's product-moment correlation\n\ndata:  Wind and sqrt(Solar.R)\nt = -1.1529, df = 144, p-value = 0.2509\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.25413132  0.06787189\nsample estimates:\n        cor \n-0.09563089 \n\ndetach(airquality)\n\n태양 복사와 바람 변수는 서로 관계가 없는 것으로 보인다.\n\n\nWind~Temp\n\nattach(airquality)\n\nThe following objects are masked from airquality (pos = 3):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\n\nThe following objects are masked from airquality (pos = 4):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\nplot(Wind~Temp,main=\"linearity of Wind ~ Temp\")\n\n(z <- line(x=Temp,y=Wind))\n\n\nCall:\nline(x = Temp, y = Wind)\n\nCoefficients:\n[1]  24.7222  -0.1944\n\nabline(coef(z))\nz.ls <- lm(Wind~Temp)\nabline(z.ls$coef, lty=2,col=\"red\")\nlegend(x = 58, y = 5, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\ncor.test(Wind,Temp,na.rm=T) #음의 상관관계\n\n\n    Pearson's product-moment correlation\n\ndata:  Wind and Temp\nt = -6.3308, df = 151, p-value = 2.642e-09\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5748874 -0.3227660\nsample estimates:\n       cor \n-0.4579879 \n\nairquality4=airquality[order(airquality$Temp),]\n\nmedWind <- as.vector(3)\nmedTemp <- as.vector(3)\nmedWind[1] <- median(airquality4$Wind[1:51],na.rm=T); medTemp[1] <- median(airquality4$Temp[1:51],na.rm=T)\nmedWind[2] <- median(airquality4$Wind[52:102],na.rm=T); medTemp[2] <- median(airquality4$Temp[52:102],na.rm=T)\nmedWind[3] <- median(airquality4$Wind[103:153],na.rm=T); medTemp[3] <- median(airquality4$Temp[103:153],na.rm=T)\nplot(medWind ~ medTemp, type=\"b\") \n\n\n\n#감소하는 Concave 한 곡선형태\n\nplot(y=log(Wind),x=Temp,main=\"Linearity of log Wind and temp\")\n(z1<- line(y=log(Wind),x=(Temp)))\n\n\nCall:\nline(y = log(Wind), x = (Temp))\n\nCoefficients:\n[1]   3.81332  -0.02016\n\nabline(coef(z1))\nz1.ls <- lm(log(Wind) ~ Temp)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 58, y = 1, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(y=sqrt(Wind),x=Temp,main=\"Linearity of sqrt Wind and temp\")\n(z1<- line(y=sqrt(Wind),x=(Temp)))\n\n\nCall:\nline(y = sqrt(Wind), x = (Temp))\n\nCoefficients:\n[1]   5.51706  -0.03126\n\nabline(coef(z1))\nz1.ls <- lm(sqrt(Wind) ~ Temp)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 58, y = 2, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nt2=Temp^2\nplot(y=Wind,x=t2,main=\"Linearity of Wind and temp^2\")\n(z1<- line(y=(Wind),x=t2))\n\n\nCall:\nline(y = (Wind), x = t2)\n\nCoefficients:\n[1]  17.456566  -0.001263\n\nabline(coef(z1))\nz1.ls <- lm(Wind ~ t2)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 3300, y = 5, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline\") #가장 적절해 보인다\nabline(0,0) \n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nplot(residuals(z3) ~ fitted(z3), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nboxplot(residuals(z1)) # 2 outliers\n\n\n\nboxplot(residuals(z2)) # 3 outliers\n\n\n\nboxplot(residuals(z3)) # 3 outliers\n\n\n\nstem(residuals(z1))\n\n\n  The decimal point is at the |\n\n  -8 | 5\n  -7 | \n  -6 | \n  -5 | 864\n  -4 | 44420\n  -3 | 9977766554331\n  -2 | 9999888886433220\n  -1 | 99877643221110000\n  -0 | 9888877554443321111100\n   0 | 0001112333345555557778889\n   1 | 11357899\n   2 | 0111244559\n   3 | 12224446699\n   4 | 1234467999\n   5 | 0357779\n   6 | 6\n   7 | 039\n   8 | \n   9 | 8\n\nstem(residuals(z2))\n\n\n  The decimal point is at the |\n\n  -4 | 0\n  -3 | 911\n  -2 | 6532110\n  -1 | 99888777776544444333222211100\n  -0 | 999888666665322110\n   0 | 0111222333455555566667788889\n   1 | 000122333444456789\n   2 | 11367\n   3 | 0128\n   4 | 03\n   5 | \n   6 | 1\n\nstem(residuals(z3))\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  -4 | 10\n  -3 | 773100\n  -2 | 88754332111\n  -1 | 888877666666655444443211100\n  -0 | 999977654220\n   0 | 011223344567888899999\n   1 | 0002222233344445556889\n   2 | 12238\n   3 | 00128\n   4 | 55\n   5 | \n   6 | \n   7 | 15\n   8 | \n   9 | \n  10 | \n  11 | 8\n\ncor.test(log(Wind),Temp,na.rm=T) #음의 상관관계\n\n\n    Pearson's product-moment correlation\n\ndata:  log(Wind) and Temp\nt = -6.0416, df = 151, p-value = 1.141e-08\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5606394 -0.3038034\nsample estimates:\n       cor \n-0.4412121 \n\ncor.test(sqrt(Wind),Temp,na.rm=T) #음의 상관관계\n\n\n    Pearson's product-moment correlation\n\ndata:  sqrt(Wind) and Temp\nt = -6.3065, df = 151, p-value = 2.992e-09\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5737080 -0.3211886\nsample estimates:\n      cor \n-0.456596 \n\ncor.test(Wind,t2,na.rm=T) #음의 상관관계\n\n\n    Pearson's product-moment correlation\n\ndata:  Wind and t2\nt = -6.3279, df = 151, p-value = 2.681e-09\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5747457 -0.3225764\nsample estimates:\n       cor \n-0.4578206 \n\ndetach(airquality)\n\nTemp와 Wind변수는 서로 음의 상관관계가 나타나는 것으로 보인다. Temp와 log(Wind)변수의 관계는 선형성이 잘 드러나는 것으로 보이며 Boxplot을 통해 확인한 두개의 Outlier들을 제거하면 잔차들도 잘 퍼져있는 것을 확인할 수 있다.\n\n\nTemp~Solar.R\n\nattach(airquality)\n\nThe following objects are masked from airquality (pos = 3):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\n\nThe following objects are masked from airquality (pos = 4):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\nplot(Temp~Solar.R,main=\"linearity of Temp ~ Solar.R\")\n\n(z <- line(x=Solar.R,y=Temp))\n\n\nCall:\nline(x = Solar.R, y = Temp)\n\nCoefficients:\n[1]  75.42051   0.02051\n\nabline(coef(z))\nz.ls <- lm(Temp~Solar.R)\nabline(z.ls$coef, lty=2,col=\"red\")\nlegend(x = 10, y = 95, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\ncor.test(Temp,Solar.R,na.rm=T) #음의 상관관계\n\n\n    Pearson's product-moment correlation\n\ndata:  Temp and Solar.R\nt = 3.4437, df = 144, p-value = 0.0007518\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1187113 0.4194913\nsample estimates:\n      cor \n0.2758403 \n\nairquality5=airquality[order(airquality$Solar.R),]\n\nmedSolar <- as.vector(3)\nmedTemp <- as.vector(3)\nmedSolar[1] <- median(airquality5$Solar.R[1:51],na.rm=T); medTemp[1] <- median(airquality5$Temp[1:51],na.rm=T)\nmedSolar[2] <- median(airquality5$Solar.R[52:102],na.rm=T); medTemp[2] <- median(airquality5$Temp[52:102],na.rm=T)\nmedSolar[3] <- median(airquality5$Solar.R[103:153],na.rm=T); medTemp[3] <- median(airquality5$Temp[103:153],na.rm=T)\nplot(medTemp ~ medSolar, type=\"b\") \n\n\n\n# Concave 한곡선 형태\n\nplot(y=log(Temp),x=Solar.R,main=\"Linearity of log Temp and Solar.R\")\n(z1<- line(y=log(Temp),x=Solar.R))\n\n\nCall:\nline(y = log(Temp), x = Solar.R)\n\nCoefficients:\n[1]  4.323467  0.000263\n\nabline(coef(z1))\nz1.ls <- lm(log(Temp) ~ Solar.R)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 10, y =4.57, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\nplot(y=sqrt(Temp),x=Solar.R,main=\"Linearity of sqrt Temp and Solar.R\")\n(z1<- line(y=sqrt(Temp),x=(Solar.R)))\n\n\nCall:\nline(y = sqrt(Temp), x = (Solar.R))\n\nCoefficients:\n[1]  8.685351  0.001161\n\nabline(coef(z1))\nz1.ls <- lm(sqrt(Temp) ~ Solar.R)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 10, y = 9.8, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\ns2=Solar.R^2\nplot(y=Temp,x=s2,main=\"Linearity of Temp and Solar.R^2\")\n(z1<- line(y=Temp,x=s2))\n\n\nCall:\nline(y = Temp, x = s2)\n\nCoefficients:\n[1]  7.654e+01  5.844e-05\n\nabline(coef(z1))\nz1.ls <- lm(Temp ~ s2)\nabline(z1.ls$coef, lty=2,col=\"red\")\nlegend(x = 100, y =97, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.5)\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline\") # 곡선 모양인 것으로 보인다.\nabline(0,0) \n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nplot(residuals(z3) ~ fitted(z3), main = \"Residual plot by rline\")\nabline(0,0) \n\n\n\nboxplot(residuals(z1)) # 1 outliers\n\n\n\nboxplot(residuals(z2)) # 2 outliers\n\n\n\nboxplot(residuals(z3)) # 3 outliers\n\n\n\nstem(residuals(z1))\n\n\n  The decimal point is at the |\n\n  -22 | 7\n  -20 | 3\n  -18 | 98181\n  -16 | 5800\n  -14 | 866576\n  -12 | 6095\n  -10 | 86644\n   -8 | 75537\n   -6 | 76543\n   -4 | 6643166542\n   -2 | 87765308650\n   -0 | 8766543098766432\n    0 | 24455677711222\n    2 | 02377791233\n    4 | 12344457901134666\n    6 | 189003\n    8 | 44578159\n   10 | 1470138\n   12 | 5682\n   14 | 4554\n   16 | 2\n   18 | 1\n\nstem(residuals(z2))\n\n\n  The decimal point is at the |\n\n  -4 | 0\n  -3 | 911\n  -2 | 6532110\n  -1 | 99888777776544444333222211100\n  -0 | 999888666665322110\n   0 | 0111222333455555566667788889\n   1 | 000122333444456789\n   2 | 11367\n   3 | 0128\n   4 | 03\n   5 | \n   6 | 1\n\nstem(residuals(z3))\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  -4 | 10\n  -3 | 773100\n  -2 | 88754332111\n  -1 | 888877666666655444443211100\n  -0 | 999977654220\n   0 | 011223344567888899999\n   1 | 0002222233344445556889\n   2 | 12238\n   3 | 00128\n   4 | 55\n   5 | \n   6 | \n   7 | 15\n   8 | \n   9 | \n  10 | \n  11 | 8\n\ncor.test(log(Temp),Solar.R,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  log(Temp) and Solar.R\nt = 3.471, df = 144, p-value = 0.0006847\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1208668 0.4212917\nsample estimates:\n      cor \n0.2778595 \n\ncor.test(sqrt(Temp),Solar.R,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  sqrt(Temp) and Solar.R\nt = 3.4587, df = 144, p-value = 0.0007142\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1198963 0.4204814\nsample estimates:\n      cor \n0.2769505 \n\ncor.test(Temp,s2,na.rm=T)\n\n\n    Pearson's product-moment correlation\n\ndata:  Temp and s2\nt = 2.2271, df = 144, p-value = 0.0275\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.0206361 0.3349912\nsample estimates:\n      cor \n0.1824728 \n\ndetach(airquality)\n\nSolar.R변수와 Temp 변수는 서로 양의 상관관계를 가지고 있다. (다만 2차함수 곡선의 관계인 것으로 보인다.) 변환을 통해 그러한 경향성을 완화시키고자 하였는데 log변환의 경우 여전히 Residual Plot에서 곡선의 경향성이 남아있다 반면, Sqrt 변환은 위의 두개의 Outlier을 제외하면 곡선의 경향성이 다소 완화되어진 것으로 보인다.\n정리하면 세개의 변수들을 서로 상관성이 있는 것으로 보이며, multicollinearity issue가 발생할 수 있기 대문에 회귀분석을 진행할 때 유의해야 할 것으로 보인다. (wind <– Temp <– Solar.R, 한단계 거친 상관성)\n결측치 자료를 불완전 자료(incomplete data, missing data)라고 하고 불완전하지만 정보를 갖고 있으니 최대한 살려서 분석하려고 하는 시도는 당연한 것이다. missing 된 부분을 다른 자료들의 패턴을 이용하여 complete로 만들어 사용하려는 방법들이 Sampling (표본조사론) 분야에서 연구되고 있다. 당연히 Bayesian 방법도 가능하다. EDA 분야까지 응용되지는 않고 있다. (말 그대로 E=exploration, 있는 그대로 explore 해야지)"
  },
  {
    "objectID": "data_analytics/EDA7.html#가-2",
    "href": "data_analytics/EDA7.html#가-2",
    "title": "EDA Assignment 7: Chapter 9",
    "section": "(가)",
    "text": "(가)\ntrees 자료를 multiple r-line으로 적합하여라.\n\nattach(trees)\n\ncor.test(log(Height),log(Girth))\n\n\n    Pearson's product-moment correlation\n\ndata:  log(Height) and log(Girth)\nt = 3.3675, df = 29, p-value = 0.002155\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2165351 0.7446400\nsample estimates:\n      cor \n0.5301949 \n\ncor.test(log(Height),log(Volume))\n\n\n    Pearson's product-moment correlation\n\ndata:  log(Height) and log(Volume)\nt = 4.5895, df = 29, p-value = 7.928e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3821245 0.8155363\nsample estimates:\n      cor \n0.6486377 \n\nsummary(lm(log(Height)~log(Girth)+log(Volume),data=trees))\n\n\nCall:\nlm(formula = log(Height) ~ log(Girth) + log(Volume), data = trees)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.08628 -0.03084 -0.00146  0.02622  0.13465 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.91689    0.22497  21.856  < 2e-16 ***\nlog(Girth)  -0.82177    0.19043  -4.315 0.000179 ***\nlog(Volume)  0.46196    0.08454   5.464 7.81e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05234 on 28 degrees of freedom\nMultiple R-squared:  0.6521,    Adjusted R-squared:  0.6273 \nF-statistic: 26.24 on 2 and 28 DF,  p-value: 3.804e-07\n\n# 1) Height ~ Volume --> Girth\nplot(log(Height)~log(Volume),main=\"Linearity of log Height ~ log Volume\")\n(z1 <- line(x=log(Volume),y=log(Height)))\n\n\nCall:\nline(x = log(Volume), y = log(Height))\n\nCoefficients:\n[1]  4.13492  0.06263\n\nabline(coef(z1),lty=2,col=\"red\")\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by multiple rline: log Height ~ log Volume\")\nabline(0,0)\n\n\n\nplot(residuals(z1)~log(Girth),main=\"Linearity of Residuals ~ log Girth\")\n(z2 <- line(x=log(Girth),y=residuals(z1)))\n\n\nCall:\nline(x = log(Girth), y = residuals(z1))\n\nCoefficients:\n[1]  -0.02973   0.01057\n\nabline(coef(z2),lty=2,col=\"red\")\n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by multiple rline: Residual ~ log Girth\")\nabline(0,0)\n\n\n\nstem(residuals(z2)) # 0을 기준으로 대칭적인 종모양\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -1 | 8\n  -1 | 310\n  -0 | 9975\n  -0 | 3332100\n   0 | 0001111234\n   0 | 6689\n   1 | 01\n\nboxplot(residuals(z2)) # outlier 1개\n\n\n\n# 끝에 있는 한 점만 제외하면 전반적으로 Residual들이 적합이 잘 된 것으로 보인다.\n\nsum(residuals(z1)^2)\n\n[1] 0.1480616\n\n# 2) Height ~  Girth --> Volume \n\nplot(log(Height)~log(Girth),main=\"Linearity of log Height ~ log Girth\")\n(z3 <- line(x=log(Girth),y=log(Height)))\n\n\nCall:\nline(x = log(Girth), y = log(Height))\n\nCoefficients:\n[1]  3.987  0.137\n\nabline(coef(z3),lty=2,col=\"red\")\n\n\n\nplot(residuals(z3) ~ fitted(z3), main = \"Residual plot by multiple rline: log Height ~ log Girth\")\nabline(0,0)\n\n\n\nplot(y=residuals(z3),x=log(Volume),main=\"Linearity of Residuals ~ log Volume\")\n(z4 <- line(y=residuals(z3),x=log(Volume)))\n\n\nCall:\nline(y = residuals(z3), x = log(Volume))\n\nCoefficients:\n[1]  -0.037395   0.009474\n\nabline(coef(z4),lty=2,col=\"red\")\n\n\n\nplot(residuals(z4) ~ fitted(z4), main = \"Residual plot by multiple rline: Residual ~ log Volume\")\nabline(0,0)\n\n\n\n# 끝에 있는 한 점만 제외하면 전반적으로 Residual들이 적합이 잘 된 것으로 보인다.\n\nstem(residuals(z4)) #0 을 기준으로 대칭적인 종모양\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  -1 | 8\n  -1 | 31\n  -0 | 99885\n  -0 | 2221000\n   0 | 011122234\n   0 | 6679\n   1 | 122\n\nboxplot(residuals(z4)) # outlier 1개\n\n\n\nsum(residuals(z3)^2)\n\n[1] 0.1667806\n\ndetach(trees)\n\n두가지 방식 중 첫번째 방식이 더 적합해 보이는 것으로 보인다. 잔차 제곱의 합의 값이 첫번째 방식이 더 작게 나타나고 있기 때문이다. . 또한 회귀분석을 같이 놓고 돌렸을 때 계수의 값이 더 크게 나타나는 것을 확인할 수 있다."
  },
  {
    "objectID": "data_analytics/EDA7.html#나-2",
    "href": "data_analytics/EDA7.html#나-2",
    "title": "EDA Assignment 7: Chapter 9",
    "section": "(나)",
    "text": "(나)\nairquality 자료를 multiple r-line으로 적합하여라.\nOzone ~ Temp ==> Wind ==> Solar.R (위에서 이유는 이미 언급함)\n\ndata(airquality)\n\nair2=airquality[!is.na(airquality$Ozone),]\nair2\n\n    Ozone Solar.R Wind Temp Month Day\n1      41     190  7.4   67     5   1\n2      36     118  8.0   72     5   2\n3      12     149 12.6   74     5   3\n4      18     313 11.5   62     5   4\n6      28      NA 14.9   66     5   6\n7      23     299  8.6   65     5   7\n8      19      99 13.8   59     5   8\n9       8      19 20.1   61     5   9\n11      7      NA  6.9   74     5  11\n12     16     256  9.7   69     5  12\n13     11     290  9.2   66     5  13\n14     14     274 10.9   68     5  14\n15     18      65 13.2   58     5  15\n16     14     334 11.5   64     5  16\n17     34     307 12.0   66     5  17\n18      6      78 18.4   57     5  18\n19     30     322 11.5   68     5  19\n20     11      44  9.7   62     5  20\n21      1       8  9.7   59     5  21\n22     11     320 16.6   73     5  22\n23      4      25  9.7   61     5  23\n24     32      92 12.0   61     5  24\n28     23      13 12.0   67     5  28\n29     45     252 14.9   81     5  29\n30    115     223  5.7   79     5  30\n31     37     279  7.4   76     5  31\n38     29     127  9.7   82     6   7\n40     71     291 13.8   90     6   9\n41     39     323 11.5   87     6  10\n44     23     148  8.0   82     6  13\n47     21     191 14.9   77     6  16\n48     37     284 20.7   72     6  17\n49     20      37  9.2   65     6  18\n50     12     120 11.5   73     6  19\n51     13     137 10.3   76     6  20\n62    135     269  4.1   84     7   1\n63     49     248  9.2   85     7   2\n64     32     236  9.2   81     7   3\n66     64     175  4.6   83     7   5\n67     40     314 10.9   83     7   6\n68     77     276  5.1   88     7   7\n69     97     267  6.3   92     7   8\n70     97     272  5.7   92     7   9\n71     85     175  7.4   89     7  10\n73     10     264 14.3   73     7  12\n74     27     175 14.9   81     7  13\n76      7      48 14.3   80     7  15\n77     48     260  6.9   81     7  16\n78     35     274 10.3   82     7  17\n79     61     285  6.3   84     7  18\n80     79     187  5.1   87     7  19\n81     63     220 11.5   85     7  20\n82     16       7  6.9   74     7  21\n85     80     294  8.6   86     7  24\n86    108     223  8.0   85     7  25\n87     20      81  8.6   82     7  26\n88     52      82 12.0   86     7  27\n89     82     213  7.4   88     7  28\n90     50     275  7.4   86     7  29\n91     64     253  7.4   83     7  30\n92     59     254  9.2   81     7  31\n93     39      83  6.9   81     8   1\n94      9      24 13.8   81     8   2\n95     16      77  7.4   82     8   3\n96     78      NA  6.9   86     8   4\n97     35      NA  7.4   85     8   5\n98     66      NA  4.6   87     8   6\n99    122     255  4.0   89     8   7\n100    89     229 10.3   90     8   8\n101   110     207  8.0   90     8   9\n104    44     192 11.5   86     8  12\n105    28     273 11.5   82     8  13\n106    65     157  9.7   80     8  14\n108    22      71 10.3   77     8  16\n109    59      51  6.3   79     8  17\n110    23     115  7.4   76     8  18\n111    31     244 10.9   78     8  19\n112    44     190 10.3   78     8  20\n113    21     259 15.5   77     8  21\n114     9      36 14.3   72     8  22\n116    45     212  9.7   79     8  24\n117   168     238  3.4   81     8  25\n118    73     215  8.0   86     8  26\n120    76     203  9.7   97     8  28\n121   118     225  2.3   94     8  29\n122    84     237  6.3   96     8  30\n123    85     188  6.3   94     8  31\n124    96     167  6.9   91     9   1\n125    78     197  5.1   92     9   2\n126    73     183  2.8   93     9   3\n127    91     189  4.6   93     9   4\n128    47      95  7.4   87     9   5\n129    32      92 15.5   84     9   6\n130    20     252 10.9   80     9   7\n131    23     220 10.3   78     9   8\n132    21     230 10.9   75     9   9\n133    24     259  9.7   73     9  10\n134    44     236 14.9   81     9  11\n135    21     259 15.5   76     9  12\n136    28     238  6.3   77     9  13\n137     9      24 10.9   71     9  14\n138    13     112 11.5   71     9  15\n139    46     237  6.9   78     9  16\n140    18     224 13.8   67     9  17\n141    13      27 10.3   76     9  18\n142    24     238 10.3   68     9  19\n143    16     201  8.0   82     9  20\n144    13     238 12.6   64     9  21\n145    23      14  9.2   71     9  22\n146    36     139 10.3   81     9  23\n147     7      49 10.3   69     9  24\n148    14      20 16.6   63     9  25\n149    30     193  6.9   70     9  26\n151    14     191 14.3   75     9  28\n152    18     131  8.0   76     9  29\n153    20     223 11.5   68     9  30\n\nair2=air2[!is.na(air2$Solar.R),]\n\ndim(air2)\n\n[1] 111   6\n\ncolSums(is.na(air2))\n\n  Ozone Solar.R    Wind    Temp   Month     Day \n      0       0       0       0       0       0 \n\nattach(air2)\n\nThe following objects are masked from airquality (pos = 3):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\n\nThe following objects are masked from airquality (pos = 4):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\n# 결측치들을 Drop해서 중간에 Fit에서 Length가 안 맞아서 생기는 오류를 해결하고자 하였음.\n\nplot(y=sqrt(Ozone),x=Temp,main=\"Linearity of sqrt Ozone ~ Temp\")\n(z <- line(x=Temp,y=sqrt(Ozone)))\n\n\nCall:\nline(x = Temp, y = sqrt(Ozone))\n\nCoefficients:\n[1]  -12.9829    0.2456\n\nabline(coef(z),lty=2,col=\"red\")\n\n\n\nplot(residuals(z) ~ fitted(z), main = \"Residual plot by multiple rline: sqrt Ozone ~ Temp\")\nabline(0,0)\n\n\n\nplot(y=residuals(z),x= Wind, main=\"Linearity of residuals ~ Wind\")\n(z1 <- line(x=Wind,y=residuals(z)))\n\n\nCall:\nline(x = Wind, y = residuals(z))\n\nCoefficients:\n[1]   1.1115  -0.1428\n\nabline(coef(z1),lty=2,col=\"red\")\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by multiple rline: residuals ~ Wind\")\nabline(0,0)\n\n\n\nplot(y=residuals(z1),x=Solar.R,main=\"Linearity of residuals ~ Solar.R\")\n(z2 <- line(x=Solar.R,y=residuals(z1)))\n\n\nCall:\nline(x = Solar.R, y = residuals(z1))\n\nCoefficients:\n[1]  -1.128031   0.005224\n\nabline(coef(z2),lty=2,col=\"red\")\n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by multiple rline: residuals ~ Solar.R\")\nabline(0,0)\n\n\n\nsum(residuals(z2)^2) # 328.3632\n\n[1] 328.3632\n\ndetach(air2)\n\nOzone ~ Wind ==> Temp ==> Solar.R (회귀분석 회귀계수가 큰 순서대로 )\n\ndata(airquality)\n\nair2=airquality[!is.na(airquality$Ozone),]\nair2\n\n    Ozone Solar.R Wind Temp Month Day\n1      41     190  7.4   67     5   1\n2      36     118  8.0   72     5   2\n3      12     149 12.6   74     5   3\n4      18     313 11.5   62     5   4\n6      28      NA 14.9   66     5   6\n7      23     299  8.6   65     5   7\n8      19      99 13.8   59     5   8\n9       8      19 20.1   61     5   9\n11      7      NA  6.9   74     5  11\n12     16     256  9.7   69     5  12\n13     11     290  9.2   66     5  13\n14     14     274 10.9   68     5  14\n15     18      65 13.2   58     5  15\n16     14     334 11.5   64     5  16\n17     34     307 12.0   66     5  17\n18      6      78 18.4   57     5  18\n19     30     322 11.5   68     5  19\n20     11      44  9.7   62     5  20\n21      1       8  9.7   59     5  21\n22     11     320 16.6   73     5  22\n23      4      25  9.7   61     5  23\n24     32      92 12.0   61     5  24\n28     23      13 12.0   67     5  28\n29     45     252 14.9   81     5  29\n30    115     223  5.7   79     5  30\n31     37     279  7.4   76     5  31\n38     29     127  9.7   82     6   7\n40     71     291 13.8   90     6   9\n41     39     323 11.5   87     6  10\n44     23     148  8.0   82     6  13\n47     21     191 14.9   77     6  16\n48     37     284 20.7   72     6  17\n49     20      37  9.2   65     6  18\n50     12     120 11.5   73     6  19\n51     13     137 10.3   76     6  20\n62    135     269  4.1   84     7   1\n63     49     248  9.2   85     7   2\n64     32     236  9.2   81     7   3\n66     64     175  4.6   83     7   5\n67     40     314 10.9   83     7   6\n68     77     276  5.1   88     7   7\n69     97     267  6.3   92     7   8\n70     97     272  5.7   92     7   9\n71     85     175  7.4   89     7  10\n73     10     264 14.3   73     7  12\n74     27     175 14.9   81     7  13\n76      7      48 14.3   80     7  15\n77     48     260  6.9   81     7  16\n78     35     274 10.3   82     7  17\n79     61     285  6.3   84     7  18\n80     79     187  5.1   87     7  19\n81     63     220 11.5   85     7  20\n82     16       7  6.9   74     7  21\n85     80     294  8.6   86     7  24\n86    108     223  8.0   85     7  25\n87     20      81  8.6   82     7  26\n88     52      82 12.0   86     7  27\n89     82     213  7.4   88     7  28\n90     50     275  7.4   86     7  29\n91     64     253  7.4   83     7  30\n92     59     254  9.2   81     7  31\n93     39      83  6.9   81     8   1\n94      9      24 13.8   81     8   2\n95     16      77  7.4   82     8   3\n96     78      NA  6.9   86     8   4\n97     35      NA  7.4   85     8   5\n98     66      NA  4.6   87     8   6\n99    122     255  4.0   89     8   7\n100    89     229 10.3   90     8   8\n101   110     207  8.0   90     8   9\n104    44     192 11.5   86     8  12\n105    28     273 11.5   82     8  13\n106    65     157  9.7   80     8  14\n108    22      71 10.3   77     8  16\n109    59      51  6.3   79     8  17\n110    23     115  7.4   76     8  18\n111    31     244 10.9   78     8  19\n112    44     190 10.3   78     8  20\n113    21     259 15.5   77     8  21\n114     9      36 14.3   72     8  22\n116    45     212  9.7   79     8  24\n117   168     238  3.4   81     8  25\n118    73     215  8.0   86     8  26\n120    76     203  9.7   97     8  28\n121   118     225  2.3   94     8  29\n122    84     237  6.3   96     8  30\n123    85     188  6.3   94     8  31\n124    96     167  6.9   91     9   1\n125    78     197  5.1   92     9   2\n126    73     183  2.8   93     9   3\n127    91     189  4.6   93     9   4\n128    47      95  7.4   87     9   5\n129    32      92 15.5   84     9   6\n130    20     252 10.9   80     9   7\n131    23     220 10.3   78     9   8\n132    21     230 10.9   75     9   9\n133    24     259  9.7   73     9  10\n134    44     236 14.9   81     9  11\n135    21     259 15.5   76     9  12\n136    28     238  6.3   77     9  13\n137     9      24 10.9   71     9  14\n138    13     112 11.5   71     9  15\n139    46     237  6.9   78     9  16\n140    18     224 13.8   67     9  17\n141    13      27 10.3   76     9  18\n142    24     238 10.3   68     9  19\n143    16     201  8.0   82     9  20\n144    13     238 12.6   64     9  21\n145    23      14  9.2   71     9  22\n146    36     139 10.3   81     9  23\n147     7      49 10.3   69     9  24\n148    14      20 16.6   63     9  25\n149    30     193  6.9   70     9  26\n151    14     191 14.3   75     9  28\n152    18     131  8.0   76     9  29\n153    20     223 11.5   68     9  30\n\nair2=air2[!is.na(air2$Solar.R),]\n\ndim(air2)\n\n[1] 111   6\n\ncolSums(is.na(air2))\n\n  Ozone Solar.R    Wind    Temp   Month     Day \n      0       0       0       0       0       0 \n\nattach(air2)\n\nThe following objects are masked from airquality (pos = 3):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\n\nThe following objects are masked from airquality (pos = 4):\n\n    Day, Month, Ozone, Solar.R, Temp, Wind\n\n# 결측치들을 Drop해서 중간에 Fit에서 Length가 안 맞아서 생기는 오류를 해결하고자 하였음.\n\nplot(y=sqrt(Ozone),x=(Wind),main=\"Linearity of sqrt Ozone ~ Wind\")\n(z <- line(x=(Wind),y=sqrt(Ozone)))\n\n\nCall:\nline(x = (Wind), y = sqrt(Ozone))\n\nCoefficients:\n[1]  11.5705  -0.5507\n\nabline(coef(z),lty=2,col=\"red\")\n\n\n\nplot(residuals(z) ~ fitted(z), main = \"Residual plot by multiple rline: sqrt Ozone ~ Wind\")\nabline(0,0)\n\n\n\nplot(y=residuals(z),x=Temp,main=\"Linearity of residuals ~ Temp\")\n(z1 <- line(x=Temp,y=residuals(z)))\n\n\nCall:\nline(x = Temp, y = residuals(z))\n\nCoefficients:\n[1]  -9.2509   0.1155\n\nabline(coef(z1),lty=2,col=\"red\")\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by multiple rline: residuals ~ Temp\")\nabline(0,0)\n\n\n\nplot(y=residuals(z1),x=Solar.R,main=\"Linearity of residuals ~ Solar.R\")\n(z2 <- line(x=Solar.R,y=residuals(z1)))\n\n\nCall:\nline(x = Solar.R, y = residuals(z1))\n\nCoefficients:\n[1]  -1.212414   0.005828\n\nabline(coef(z2),lty=2,col=\"red\")\n\n\n\nplot(residuals(z2) ~ fitted(z2), main = \"Residual plot by multiple rline: residuals ~ Solar.R\")\nabline(0,0)\n\n\n\nsum(residuals(z2)^2) #360.3426\n\n[1] 360.3426\n\ndetach(air2)\n\n아래의 방식보다 위의 방식에서 잔차제곱의 합이 작게 나타난다. 따라서 위의 방식에서의 적합이 더 잘 이루어졌음을 확인해볼 수 있다.\n주의: multiple R-line은 sequential 방법이다. simultaneous 방법으로 하면 다른 결과 나올 수 있다."
  },
  {
    "objectID": "data_analytics/EDA8_Final.html",
    "href": "data_analytics/EDA8_Final.html",
    "title": "EDA Assignment 8: Final Exam",
    "section": "",
    "text": "작업한 부분은 기한 이내에 제출하여야 그 부분만이라도 감점없이 점수를 받을 수 있다.\n\n1.\n다음 자료는 사춘기 여성의 신경성 식욕 감퇴증에 대하여 일정 기간 동안 세 가지 방법으로 치료한 결과이다. 어느 방법이 가장 큰 효과를 보았나? [ANOREXIA.DAT]\nI Cognitive behavioral treatment\nII Control; standard treatment\nIII Family therapy\nWeights in Kg\n전처리 후 정리\n\n# weights \n\n# I Cognitive behavioral treatment \ncbt=read.delim(file=\"C://r/ANOREXIA.DAT\",header=F)[c(1,2)]\nnames(cbt)=c(\"before\",\"after\")\nhead(cbt,5)\n\n  before after\n1   80.5  82.2\n2   84.9  85.6\n3   81.5  81.4\n4   82.6  81.9\n5   79.9  76.4\n\ndim(cbt)\n\n[1] 29  2\n\n# II Control; standard treatment\ncontrol=read.delim(file=\"C://r/ANOREXIA.DAT\",header=F)[c(3,4)][c(1:26),]\nnames(control)=c(\"before\",\"after\")\nhead(control,5)\n\n  before after\n1   80.7  80.2\n2   89.4  80.1\n3   91.8  86.4\n4   74.0  86.3\n5   78.1  76.1\n\ndim(control)\n\n[1] 26  2\n\n# III Family therapy\nfamily=read.delim(file=\"C://r/ANOREXIA.DAT\",header=F)[c(5,6)][c(1:17),]\nnames(family)=c(\"before\",\"after\")\nhead(family,5)\n\n  before after\n1   83.8  95.2\n2   83.3  94.3\n3   86.0  91.5\n4   82.5  91.9\n5   86.7 100.3\n\ndim(family)\n\n[1] 17  2\n\n\n항목의 수가 Cognitive behavioral treatment: 29 Control group: 26 Family Therapy: 17로 서로 다르다. 따라서 결측치를 처리하여 각각을 나누어서 표현하였다.\nTreatment별로 기술통계량을 제시하고 시각화 한 후 자료의 특성을 확인하고 각 Sample에 대한 paired t-Test를 진행할 예정이다.\n먼저, Cognitive behavioral treatment의 분석이다.\n\nsummary(cbt)\n\n     before          after      \n Min.   :70.00   Min.   : 71.3  \n 1st Qu.:80.40   1st Qu.: 81.9  \n Median :82.60   Median : 83.9  \n Mean   :82.69   Mean   : 85.7  \n 3rd Qu.:85.00   3rd Qu.: 90.9  \n Max.   :94.90   Max.   :103.6  \n\n85.7-82.69\n\n[1] 3.01\n\n83.9-82.60\n\n[1] 1.3\n\n# Cognitive behavioral treatment를 시행하기 이전 집단과 이후집단의 평균은 약 3kg정도 차이나고, median값은 1.3kg정도 차이나는 것으로 보인다.\n# 성장기의 식용 감퇴증이 다소 완화되어진 것을 확인할 수 있다.\nfivenum(cbt$before)\n\n[1] 70.0 80.4 82.6 85.0 94.9\n\nfivenum(cbt$after)\n\n[1]  71.3  81.9  83.9  90.9 103.6\n\n# Stem and leaf Plot을 통해서 두 집단의 분포를 비교해 보았는데 treament 이전 집단의 경우 stem 8*을 기준으로 leaf들이 어느정도 종모양의 대칭적 분포를 이루고 있는데, 반면 treatment 이후 집단의 경우 stem 8*이 중심이 되어지는 것은 맞지만 다소 퍼지게 된 것을 확인할 수 있다. \nlibrary(aplpack)\nstem.leaf.backback(cbt$before,cbt$after,rule.line = \"Sturges\")\n\n_____________________________________________________\n  1 | 2: represents 12, leaf unit: 1 \n             cbt$before       cbt$after          \n_____________________________________________________\n    1                 0|  7* |123                3   \n    6             99666|  7. |56                 5   \n  (15)  444333211100000|  8* |11122222334      (11)  \n    8           9877765|  8. |55569             13   \n    1                 4|  9* |03                 8   \n                       |  9. |5668               6   \n                       | 10* |03                 2   \n_____________________________________________________\nn:                   29       29                 \n_____________________________________________________\n\n# Boxplot\nboxplot(cbt,main=\"Boxplot of before and after Cognitive behavioral treatment\")\n\n\n\nboxplot(cbt)$out #처리 이전 집단의 총 두개의 Outlier: lower fence인 76.3 밖의 값과 outer fence인 89.2 밖의 두개의 값\n\n\n\n\n[1] 94.9 70.0\n\nboxplot(cbt)$stats\n\n     [,1]  [,2]\n[1,] 76.3  71.3\n[2,] 80.4  81.9\n[3,] 82.6  83.9\n[4,] 85.0  90.9\n[5,] 89.2 103.6\n\n# Skewness\nskewness = function(x) {\n  hl=fivenum(x)[2]\n  median=fivenum(x)[3]\n  hu=fivenum(x)[4]\n  skew=((hu-median)-(median-hl))/((hu-median)+(median-hl))\n  return(skew)\n}\nskewness(cbt$before) # 거의 Skewed 되어지지 않음 (매우 미세하게 skewed to the right)\n\n[1] 0.04347826\n\nskewness(cbt$after) # Boxplot에서 확인하였듯이 Skewed to the right 되어 있음.\n\n[1] 0.5555556\n\n# Letter Value Display\nsource(\"http://mgimond.github.io/ES218/es218.R\")\nlvd1=(lsum(cbt$before,6))\nlvd2=(lsum(cbt$after,6))\nlvd1\n\n  letter depth lower    mid upper spread\n1      M  15.0 82.60 82.600 82.60   0.00\n2      H   8.0 80.40 82.700 85.00   4.60\n3      E   4.5 78.10 82.925 87.75   9.65\n4      D   2.5 76.40 82.675 88.95  12.55\n5      C   1.5 73.15 82.600 92.05  18.90\n6      B   1.0 70.00 82.450 94.90  24.90\n\nlvd2\n\n  letter depth lower    mid  upper spread\n1      M  15.0 83.90 83.900  83.90   0.00\n2      H   8.0 81.90 86.400  90.90   9.00\n3      E   4.5 76.05 86.250  96.45  20.40\n4      D   2.5 72.95 86.175  99.40  26.45\n5      C   1.5 71.90 86.950 102.00  30.10\n6      B   1.0 71.30 87.450 103.60  32.30\n\n# H-Spread\nlsum(cbt$before)[2,5]-lsum(cbt$before)[2,3]\n\n[1] 4.6\n\nlsum(cbt$after)[2,5]-lsum(cbt$after)[2,3] #더 넓게 퍼져있는 것을 확인할 수 있음. \n\n[1] 9\n\n# Kurtosis (E-spread / H-spread - 1.705)\n(lvd1[3,5]-lvd1[3,3])/(lvd1[2,5]-lvd1[2,3])-1.705 # more peaked than normal\n\n[1] 0.3928261\n\n(lvd2[3,5]-lvd2[3,3])/(lvd2[2,5]-lvd2[2,3])-1.705 # more peaked than normal (Kurtosis값도 더 크게 나타남)\n\n[1] 0.5616667\n\n# 정규성\nqqnorm(cbt$before, ylab=\"before quantiles\",main=\"before\");qqline(cbt$before, col='red',lty=2,lwd=2) #위에서 언급했던 두개의 Outlier들만 제외하면 대부분 정규분포를 잘 따르고 있는 것이 확인되어지고 있다. \nfiv1=fivenum(cbt$before)\n(pseudosigma1 = (fiv1[4]-fiv1[2])/1.34)\n\n[1] 3.432836\n\nsd(cbt$before) # 약 1.4정도의 차이\n\n[1] 4.845495\n\nabline(fiv1[3],pseudosigma1,col=\"blue\",lty=2,lwd=2)\nlegend(x = -2, y = 92, c(\"qqline\", \"robustline\"), \n       lty=2,lwd=2,col = c(\"red\",\"blue\")) # 거의 일치중\n\n\n\nqqnorm(cbt$after, ylab=\"after quantiles\", main=\"after\");qqline(cbt$after, col='red',lty=2,lwd=2) #정규분포를 따른다고 보기 어려운 이유가 값들이 직선을 따르기 보다는 곡선의 형태를 띄고 있음을 확인할 수 있다.  \nfiv2=fivenum(cbt$after)\n(pseudosigma2 = (fiv2[4]-fiv2[2])/1.34)\n\n[1] 6.716418\n\nsd(cbt$after) # 약 1.6정도의 차이\n\n[1] 8.351924\n\nabline(fiv2[3],pseudosigma2,col=\"blue\",lty=2,lwd=2)\nlegend(x = -2, y = 100, c(\"qqline\", \"robustline\"), \n       lty=2,lwd=2,col = c(\"red\",\"blue\")) # 약간차이를 보임\n\n\n\n# Paired T-test\n# H0: cbt$after-cbt$before=0  H1: cbt$after-cbt$before>0 \ncbt_test<-t.test(cbt$after,cbt$before, paired=TRUE, alternative=\"greater\",conf.level=0.05)\ncbt_test # reject null hypothesis, the weight of after treatment is heavier\n\n\n    Paired t-test\n\ndata:  cbt$after and cbt$before\nt = 2.2156, df = 28, p-value = 0.01751\nalternative hypothesis: true mean difference is greater than 0\n5 percent confidence interval:\n 5.315595      Inf\nsample estimates:\nmean difference \n       3.006897 \n\n\n다음으로는 통제집단의 분석이다.\n\nsummary(control)\n\n     before          after      \n Min.   :70.50   Min.   :73.00  \n 1st Qu.:77.72   1st Qu.:77.58  \n Median :80.65   Median :80.70  \n Mean   :81.56   Mean   :81.11  \n 3rd Qu.:85.88   3rd Qu.:84.67  \n Max.   :91.80   Max.   :89.60  \n\nmean(control$after)-mean(control$before)\n\n[1] -0.45\n\nmedian(control$after)-median(control$before)\n\n[1] 0.05\n\n# 통제집단의 경우 실험 시행하기 이전 집단과 실험 이후 집단의 평균은 0.45kg정도 차이를 보이며 중위값은 큰 차이가 없다.\n# Cognitive behavioral treatment에서 보였던 차이보다 적은 차이를 보이고 있는 것을 확인할 수 있다.\n\nfivenum(control$before)\n\n[1] 70.50 77.60 80.65 86.00 91.80\n\nfivenum(control$after)\n\n[1] 73.0 77.4 80.7 84.7 89.6\n\n# Stem and leaf Plot을 통해서 두 집단의 분포를 비교해 보았는데 처치 이전 집단의 경우 stem 7. stem 8. 두개의 축을 기준으로 Cluster를 가지고 있는데 비해 처치 이후의 집단의 경우 stem 7., stem8*두개의 stem을 기준으로 어느정도 대칭적으로 종모양을 보이고 있는 것이 확인된다.\nstem.leaf.backback(control$before,control$after,rule.line = \"Sturge\")\n\n_______________________________________\n  1 | 2: represents 12, leaf unit: 1 \n    control$before       control$after\n_______________________________________\n   3         420|  7* |33          2   \n  12   998887775|  7. |556778899  11   \n  (5)      44100|  8* |001111444  (9)  \n   9    99887655|  8. |666889      6   \n   1           1|  9* |                \n                |  9. |                \n                | 10* |                \n_______________________________________\nn:            26       26          \n_______________________________________\n\n# Boxplot\nboxplot(control,main=\"Boxplot of before and after standard treatment\")\n\n\n\nboxplot(control)$out #처리 이전 이후 둘다 outlier는 없는 것으로 보인다. \n\n\n\n\nnumeric(0)\n\nboxplot(control)$stats\n\n      [,1] [,2]\n[1,] 70.50 73.0\n[2,] 77.60 77.4\n[3,] 80.65 80.7\n[4,] 86.00 84.7\n[5,] 91.80 89.6\n\n# Skewness\nskewness(control$before) # skewed to the right\n\n[1] 0.2738095\n\nskewness(control$after) # 거의 Skewed 되어지지 않음 (매우 미세하게 skewed to the right)\n\n[1] 0.09589041\n\n# Letter Value Display\nsource(\"http://mgimond.github.io/ES218/es218.R\")\nlvd3=(lsum(control$before,6))\nlvd4=(lsum(control$after,6))\nlvd3\n\n  letter depth lower    mid upper spread\n1      M  13.5 80.65 80.650 80.65   0.00\n2      H   7.0 77.60 81.800 86.00   8.40\n3      E   4.0 75.10 81.900 88.70  13.60\n4      D   2.5 73.15 81.175 89.20  16.05\n5      C   1.5 71.40 81.000 90.60  19.20\n6      B   1.0 70.50 81.150 91.80  21.30\n\nlvd4\n\n  letter depth lower    mid upper spread\n1      M  13.5 80.70 80.700 80.70   0.00\n2      H   7.0 77.40 81.050 84.70   7.30\n3      E   4.0 75.40 81.050 86.70  11.30\n4      D   2.5 74.30 81.275 88.25  13.95\n5      C   1.5 73.25 81.100 88.95  15.70\n6      B   1.0 73.00 81.300 89.60  16.60\n\n# H-Spread\nlsum(control$before)[2,5]-lsum(control$before)[2,3]\n\n[1] 8.4\n\nlsum(control$after)[2,5]-lsum(control$after)[2,3] # 처치 이후 spread의 크기가 더 줄어들었음 \n\n[1] 7.3\n\n# Kurtosis (E-spread / H-spread - 1.705)\n(lvd3[3,5]-lvd3[3,3])/(lvd3[2,5]-lvd3[2,3])-1.705 # less peaked than normal\n\n[1] -0.08595238\n\n(lvd4[3,5]-lvd4[3,3])/(lvd4[2,5]-lvd4[2,3])-1.705 # less peaked than normal (Kurtosis값은 after집단에서 더 작게 나타남)\n\n[1] -0.1570548\n\n# 정규성\nqqnorm(control$before, ylab=\"before quantiles\",main=\"before\");qqline(control$before, col='red',lty=2) # 점들이 완벽히 qqline을 따르기 보다는 곡선의 형태를 이루고 있는 것을 확인할 수 있다.\nfiv3=fivenum(control$before)\n(pseudosigma3 = (fiv3[4]-fiv3[2])/1.34)\n\n[1] 6.268657\n\nsd(control$before) # 약 0.5정도의 차이\n\n[1] 5.70706\n\nabline(fiv3[3],pseudosigma3,col=\"blue\",lty=2)\nlegend(x = -2, y = 92, c(\"qqline\", \"robustline\"), \n       lty=2,lwd=2,col = c(\"red\",\"blue\")) # 약간차이를 보임\n\n\n\nqqnorm(control$after, ylab=\"after quantiles\", main=\"after\");qqline(control$after, col='red',lty=2) # 처치 이전에 비해서 처치 이후의 데이터들이 직선을 따르기 때문에 정규분포를 조금 더 따르고 있다.  \nfiv4=fivenum(control$after)\n(pseudosigma4 = (fiv4[4]-fiv4[2])/1.34)\n\n[1] 5.447761\n\nsd(control$after) # 약 0.7정도의 차이\n\n[1] 4.744253\n\nabline(fiv4[3],pseudosigma4,col=\"blue\",lty=2)\nlegend(x = -2, y = 88, c(\"qqline\", \"robustline\"), \n       lty=2,lwd=2,col = c(\"red\",\"blue\")) # 거의 차이가 없음\n\n\n\n# Paired T-test\n# H0: 처지 이전의 집단과 처치 이후의 집단의 몸무게 차이는 없다. H1: 처치 이후의 집단의 몸무게가 처지 이전의 집단보다 더 무겁다.\ncontrol_test<-t.test(control$after,control$before, paired=TRUE, alternative=\"greater\",conf.level=0.05)\ncontrol_test # do not reject null hypothesis.\n\n\n    Paired t-test\n\ndata:  control$after and control$before\nt = -0.28723, df = 25, p-value = 0.6118\nalternative hypothesis: true mean difference is greater than 0\n5 percent confidence interval:\n 2.226168      Inf\nsample estimates:\nmean difference \n          -0.45 \n\n\n마지막으로 Family therapy에 대한 분석이다.\n\nsummary(family)\n\n     before          after       \n Min.   :73.40   Min.   : 75.20  \n 1st Qu.:80.50   1st Qu.: 90.70  \n Median :83.30   Median : 92.50  \n Mean   :83.23   Mean   : 90.49  \n 3rd Qu.:86.00   3rd Qu.: 95.20  \n Max.   :94.20   Max.   :101.60  \n\nmean(family$after)-mean(family$before)\n\n[1] 7.264706\n\nmedian(family$after)-median(family$before)\n\n[1] 9.2\n\n# Family Therapy의 경우 실험 시행하기 이전 집단과 실험 이후 집단의 평균은 7.2kg정도 차이를 보이며 중위값은 9.2kg정도 차이가 나타난다.\n# Cognitive behavioral treatment에서 보였던 차이보다 적은 차이를 보이고 있는 것을 확인할 수 있다.\n\nfivenum(family$before)\n\n[1] 73.4 80.5 83.3 86.0 94.2\n\nfivenum(family$after)\n\n[1]  75.2  90.7  92.5  95.2 101.6\n\n# Stem and leaf Plot을 통해서 두 집단의 분포를 비교해 보았는데 처치 이전 집단의 경우  stem 8*을 기준으로 대칭적인 종모양을 보이는데 비해 처치 이후의 집단의 경우 stem 9*이 가장 많고 대칭적이지 않으며 중간에 빈 부분이 보인다.\nstem.leaf.backback(family$before,family$after,rule.line = \"Sturge\")\n\n_____________________________________\n  1 | 2: represents 12, leaf unit: 1 \n    family$before       family$after\n_____________________________________\n   1          3|  7* |               \n   4        976|  7. |5667       4   \n  (7)   3332210|  8* |               \n   6      97666|  8. |               \n   1          4|  9* |01112344  (8)  \n               |  9. |558        5   \n               | 10* |01         2   \n               | 10. |               \n               | 11* |               \n_____________________________________\nn:           17       17         \n_____________________________________\n\n# Boxplot\nboxplot(family,main=\"Boxplot of before and after family treatment\")\n\n\n\nboxplot(family)$out #처리 이후의 집단에서 4개의 outlier 확인됨. (아까 Stem and leaf에서 확인 한 부분 재확인)\n\n\n\n\n[1] 76.7 76.8 75.2 77.8\n\nboxplot(family)$stats # lower fence=lower hinge\n\n     [,1]  [,2]\n[1,] 73.4  90.7\n[2,] 80.5  90.7\n[3,] 83.3  92.5\n[4,] 86.0  95.2\n[5,] 94.2 101.6\n\n# Skewness\nskewness(family$before) # skewed to the left (but 매우 미세함)\n\n[1] -0.01818182\n\nskewness(family$after) # skewed to the right\n\n[1] 0.2\n\n# Letter Value Display\nsource(\"http://mgimond.github.io/ES218/es218.R\")\nlvd5=(lsum(family$before,6))\nlvd6=(lsum(family$after,6))\nlvd5\n\n  letter depth lower   mid upper spread\n1      M   9.0 83.30 83.30 83.30    0.0\n2      H   5.0 80.50 83.25 86.00    5.5\n3      E   3.0 77.60 82.45 87.30    9.7\n4      D   2.0 76.90 83.40 89.90   13.0\n5      C   1.5 75.15 83.60 92.05   16.9\n6      B   1.0 73.40 83.80 94.20   20.8\n\nlvd6\n\n  letter depth lower   mid  upper spread\n1      M   9.0 92.50 92.50  92.50    0.0\n2      H   5.0 90.70 92.95  95.20    4.5\n3      E   3.0 76.80 87.40  98.00   21.2\n4      D   2.0 76.70 88.50 100.30   23.6\n5      C   1.5 75.95 88.45 100.95   25.0\n6      B   1.0 75.20 88.40 101.60   26.4\n\n# H-Spread\nlvd5[2,5]-lvd5[2,3]\n\n[1] 5.5\n\nlvd6[2,5]-lvd6[2,3] # 처치 이전이후의 차이가 1정도로 크지 않음.\n\n[1] 4.5\n\n# Kurtosis (E-spread / H-spread - 1.705)\n(lvd5[3,5]-lvd5[3,3])/(lvd5[2,5]-lvd5[2,3])-1.705 # 정규분포와 거의 차이가 없음\n\n[1] 0.05863636\n\n(lvd6[3,5]-lvd6[3,3])/(lvd6[2,5]-lvd6[2,3])-1.705 # more peaked than normal (Kurtosis값은 after집단에서 더 작게 나타남) \n\n[1] 3.006111\n\n# 다만 after집단의 분포가 17개의 자료중 4개의 outlier로 인해서 왜곡되었을 가능성이 있다.\n\n# 정규성\nqqnorm(family$before, ylab=\"before quantiles\",main=\"before\");qqline(family$before, col='red',lty=2) # 점들이 직선을 잘 따르고 있는 것으로 보인다. \nfiv5=fivenum(family$before)\n(pseudosigma5 = (fiv5[4]-fiv5[2])/1.34)\n\n[1] 4.104478\n\nsd(family$before) # 약 0.9정도의 차이\n\n[1] 5.016693\n\nabline(fiv5[3],pseudosigma5,col=\"blue\",lty=2)\nlegend(x = -1.8, y = 92, c(\"qqline\", \"robustline\"), \n       lty=2,lwd=2,col = c(\"red\",\"blue\")) # 거의 차이가 없음\n\n\n\nqqnorm(family$after, ylab=\"after quantiles\", main=\"after\");qqline(family$after, col='red',lty=2) # 이상치 4개를 제외하면 나머지들이 직선을 잘 따르는 것으로 보이나 표본이 작아 신뢰성이 낮다.   \nfiv6=fivenum(family$after)\n(pseudosigma6 = (fiv6[4]-fiv6[2])/1.34)\n\n[1] 3.358209\n\nsd(family$after) # 약 5 정도의 차이 - 매우 큼\n\n[1] 8.475072\n\nabline(fiv6[3],pseudosigma6,col=\"blue\",lty=2)\nlegend(x = -1.8, y = 99, c(\"qqline\", \"robustline\"), \n       lty=2,lwd=2,col = c(\"red\",\"blue\")) # 거의 차이가 없음 \n\n\n\n# Paired T-test\n# H0: family$after-family$before=0 H1:family$after-family$before>0\nfamily_test<-t.test(family$after,family$before, paired=TRUE, alternative=\"greater\",conf.level=0.05)\nfamily_test # Reject Null Hypothesis. The weight of treated group is larger than the group without treatment.\n\n\n    Paired t-test\n\ndata:  family$after and family$before\nt = 4.1849, df = 16, p-value = 0.0003501\nalternative hypothesis: true mean difference is greater than 0\n5 percent confidence interval:\n 10.29544      Inf\nsample estimates:\nmean difference \n       7.264706 \n\n\n세집단의 차이에 대해 일원분산분석을 진행하고자 한다.\n\ncbt_diff=cbt$after-cbt$before\ncon_diff=control$after-control$before\nfam_diff=family$after-family$before\n\nboxplot(cbt_diff,con_diff,fam_diff,names=c(\"Cognitive\",\"Control\",\"Family\"))$out #Cognitive Behavior Treament 7개의 outlier\n\n[1] 14.9 17.1 11.7 20.9 -9.1 12.6 15.4\n\nnaming=c(rep(\"cbt\",length(cbt_diff)),rep(\"control\",length(con_diff)),rep(\"family\",length(fam_diff)))\nvalue=c(cbt_diff,con_diff,fam_diff)\ndiffs=data.frame(naming,value)\n\naov1=aov(value~naming,data=diffs)\nsummary(aov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)   \nnaming       2    615  307.32   5.422 0.0065 **\nResiduals   69   3911   56.68                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#H0: 각 집단간 평균은 차이가 없다. #H1: 각 집단간 평균은 차이가 없지 않다.\n# Reject Null Hypothesis. 신뢰수준 95% 수준에서 사춘기 여성의 신경성 식욕 감퇴증의 각 치료 방법(Cognitive behavior, control, family treatment)을 적용할 경우 각 집단간 몸무게에서 차이를 보인다. \n\nbartlett.test(value~naming, data = diffs) #H0: 오차의 등분산성, 유의수준 10%에서 Select Null Hypothesis. (오차의 등분산성 만족)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  value by naming\nBartlett's K-squared = 0.30428, df = 2, p-value = 0.8589\n\ntapply(value,naming,mean)  \n\n      cbt   control    family \n 3.006897 -0.450000  7.264706 \n\nTukeyHSD(aov1) # Tukey multiple comparisons of means 95% family-wise\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = value ~ naming, data = diffs)\n\n$naming\n                    diff       lwr       upr     p adj\ncontrol-cbt    -3.456897 -8.327276  1.413483 0.2124428\nfamily-cbt      4.257809 -1.250554  9.766173 0.1607461\nfamily-control  7.714706  2.090124 13.339288 0.0045127\n\n# install.packages(\"agricolae\")\nlibrary(agricolae)\n\n\nAttaching package: 'agricolae'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    skewness\n\n\n\n\nHSD.test(aov1, \"naming\", group=TRUE,console=TRUE)\n\n\nStudy: aov1 ~ \"naming\"\n\nHSD Test for value \n\nMean Square Error:  56.67743 \n\nnaming,  means\n\n            value      std  r   Min  Max\ncbt      3.006897 7.308504 29  -9.1 20.9\ncontrol -0.450000 7.988705 26 -12.2 15.9\nfamily   7.264706 7.157421 17  -5.3 21.5\n\nAlpha: 0.05 ; DF Error: 69 \nCritical Value of Studentized Range: 3.387483 \n\nGroups according to probability of means differences and alpha level( 0.05 )\n\nTreatments with the same letter are not significantly different.\n\n            value groups\nfamily   7.264706      a\ncbt      3.006897     ab\ncontrol -0.450000      b\n\nLSD.test(aov1, \"naming\", group=TRUE,console=TRUE)\n\n\nStudy: aov1 ~ \"naming\"\n\nLSD t Test for value \n\nMean Square Error:  56.67743 \n\nnaming,  means and individual ( 95 %) CI\n\n            value      std  r       LCL       UCL   Min  Max\ncbt      3.006897 7.308504 29  0.217970  5.795823  -9.1 20.9\ncontrol -0.450000 7.988705 26 -3.395435  2.495435 -12.2 15.9\nfamily   7.264706 7.157421 17  3.622105 10.907307  -5.3 21.5\n\nAlpha: 0.05 ; DF Error: 69\nCritical Value of t: 1.994945 \n\nGroups according to probability of means differences and alpha level( 0.05 )\n\nTreatments with the same letter are not significantly different.\n\n            value groups\nfamily   7.264706      a\ncbt      3.006897     ab\ncontrol -0.450000      b\n\n\n통제집단에 비해서 cognitive behavior treatemnt는 3.46kg정도 높음. cognitive behavior treatment 집단에 비해서 family treatemnt 집단의 경우 4.26kg 정도 높음. 따라서 가장 효과가 좋은 순서대로 family treatment, cognitive behavior treatment, control 순이다.\n그러나 cognitive behavior treatment집단이 다른 집단에 비해서 크거나 작다라고 보기에는 HSD, LSD test를 통해서 확인할 경우 신뢰구간이 겹쳐 다소 모호한 부분이 있다. 실제 Boxplot을 통해 확인할 경우 outlier들이 넓게 퍼져있어서 cognitive behavior treatment집단의 몸무게가 유의수준 5%수준에서 두 집단의 몸무게와 완전히 다르다고 보기 어렵다.\n\n# 이원분산분석 \n\nlibrary(reshape2)\n\ncontrol2=melt(control)\n\nNo id variables; using all as measure variables\n\ncontrol2=cbind(rep(\"control\",dim(control2)[1]),control2)\nnames(control2)=c(\"treatment\",\"ba\",\"value\")\n\ncbt2=melt(cbt)\n\nNo id variables; using all as measure variables\n\ncbt2=cbind(rep(\"cognitive\",dim(cbt2)[1]),cbt2)\nnames(cbt2)=c(\"treatment\",\"ba\",\"value\")\n\nfamily2=melt(family)\n\nNo id variables; using all as measure variables\n\nfamily2=cbind(rep(\"family\",dim(family2)[1]),family2)\nnames(family2)=c(\"treatment\",\"ba\",\"value\")\nfamily2\n\n   treatment     ba value\n1     family before  83.8\n2     family before  83.3\n3     family before  86.0\n4     family before  82.5\n5     family before  86.7\n6     family before  79.6\n7     family before  76.9\n8     family before  94.2\n9     family before  73.4\n10    family before  80.5\n11    family before  81.6\n12    family before  82.1\n13    family before  77.6\n14    family before  83.5\n15    family before  89.9\n16    family before  86.0\n17    family before  87.3\n18    family  after  95.2\n19    family  after  94.3\n20    family  after  91.5\n21    family  after  91.9\n22    family  after 100.3\n23    family  after  76.7\n24    family  after  76.8\n25    family  after 101.6\n26    family  after  94.9\n27    family  after  75.2\n28    family  after  77.8\n29    family  after  95.5\n30    family  after  90.7\n31    family  after  92.5\n32    family  after  93.8\n33    family  after  91.7\n34    family  after  98.0\n\naov2=rbind(control2,cbt2,family2)\naov3=aov(value~treatment+ba,data=aov2) \nsummary(aov3)\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \ntreatment     2    644   322.1   7.713 0.000664 ***\nba            1    275   275.0   6.585 0.011335 *  \nResiduals   140   5847    41.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(doBy)\nsummaryBy(value ~ treatment, data=aov2, FUN = c(mean, sd, min, max))\n\n  treatment value.mean value.sd value.min value.max\n1 cognitive   84.19310 6.935337      70.0     103.6\n2   control   81.33269 5.201045      70.5      91.8\n3    family   86.86176 7.785963      73.4     101.6\n\nHSD.test(aov3, \"treatment\", group=TRUE,console=TRUE) # family cognitive standard 순이지만 cognitive behavior treatment는 a그룹 b그룹 모두에 속하므로 해석에 유의해야 한다. \n\n\nStudy: aov3 ~ \"treatment\"\n\nHSD Test for value \n\nMean Square Error:  41.76232 \n\ntreatment,  means\n\n             value      std  r  Min   Max\ncognitive 84.19310 6.935337 58 70.0 103.6\ncontrol   81.33269 5.201045 52 70.5  91.8\nfamily    86.86176 7.785963 34 73.4 101.6\n\nAlpha: 0.05 ; DF Error: 140 \nCritical Value of Studentized Range: 3.350136 \n\nGroups according to probability of means differences and alpha level( 0.05 )\n\nTreatments with the same letter are not significantly different.\n\n             value groups\nfamily    86.86176      a\ncognitive 84.19310     ab\ncontrol   81.33269      b\n\nHSD.test(aov3, \"ba\", group=TRUE,console=TRUE) # 전반적으로 더 높다 treatment 취한 그룹에서 \n\n\nStudy: aov3 ~ \"ba\"\n\nHSD Test for value \n\nMean Square Error:  41.76232 \n\nba,  means\n\n          value      std  r  Min   Max\nafter  85.17222 8.035173 72 71.3 103.6\nbefore 82.40833 5.182466 72 70.0  94.9\n\nAlpha: 0.05 ; DF Error: 140 \nCritical Value of Studentized Range: 2.795976 \n\nMinimun Significant Difference: 2.129411 \n\nTreatments with the same letter are not significantly different.\n\n          value groups\nafter  85.17222      a\nbefore 82.40833      b\n\n# Interaction Plot\n\nid=(1:dim(aov2)[1])\naov2=cbind(id,aov2)\naov2\n\n     id treatment     ba value\n1     1   control before  80.7\n2     2   control before  89.4\n3     3   control before  91.8\n4     4   control before  74.0\n5     5   control before  78.1\n6     6   control before  88.3\n7     7   control before  87.3\n8     8   control before  75.1\n9     9   control before  80.6\n10   10   control before  78.4\n11   11   control before  77.6\n12   12   control before  88.7\n13   13   control before  81.3\n14   14   control before  78.1\n15   15   control before  70.5\n16   16   control before  77.3\n17   17   control before  85.2\n18   18   control before  86.0\n19   19   control before  84.1\n20   20   control before  79.7\n21   21   control before  85.5\n22   22   control before  84.4\n23   23   control before  79.6\n24   24   control before  77.5\n25   25   control before  72.3\n26   26   control before  89.0\n27   27   control  after  80.2\n28   28   control  after  80.1\n29   29   control  after  86.4\n30   30   control  after  86.3\n31   31   control  after  76.1\n32   32   control  after  78.1\n33   33   control  after  75.1\n34   34   control  after  86.7\n35   35   control  after  73.5\n36   36   control  after  84.6\n37   37   control  after  77.4\n38   38   control  after  79.5\n39   39   control  after  89.6\n40   40   control  after  81.4\n41   41   control  after  81.8\n42   42   control  after  77.3\n43   43   control  after  84.2\n44   44   control  after  75.4\n45   45   control  after  79.5\n46   46   control  after  73.0\n47   47   control  after  88.3\n48   48   control  after  84.7\n49   49   control  after  81.4\n50   50   control  after  81.2\n51   51   control  after  88.2\n52   52   control  after  78.8\n53   53 cognitive before  80.5\n54   54 cognitive before  84.9\n55   55 cognitive before  81.5\n56   56 cognitive before  82.6\n57   57 cognitive before  79.9\n58   58 cognitive before  88.7\n59   59 cognitive before  94.9\n60   60 cognitive before  76.3\n61   61 cognitive before  81.0\n62   62 cognitive before  80.5\n63   63 cognitive before  85.0\n64   64 cognitive before  89.2\n65   65 cognitive before  81.3\n66   66 cognitive before  76.5\n67   67 cognitive before  70.0\n68   68 cognitive before  80.4\n69   69 cognitive before  83.3\n70   70 cognitive before  83.0\n71   71 cognitive before  87.7\n72   72 cognitive before  84.2\n73   73 cognitive before  86.4\n74   74 cognitive before  76.5\n75   75 cognitive before  80.2\n76   76 cognitive before  87.8\n77   77 cognitive before  83.3\n78   78 cognitive before  79.7\n79   79 cognitive before  84.5\n80   80 cognitive before  80.8\n81   81 cognitive before  87.4\n82   82 cognitive  after  82.2\n83   83 cognitive  after  85.6\n84   84 cognitive  after  81.4\n85   85 cognitive  after  81.9\n86   86 cognitive  after  76.4\n87   87 cognitive  after 103.6\n88   88 cognitive  after  98.4\n89   89 cognitive  after  93.4\n90   90 cognitive  after  73.4\n91   91 cognitive  after  82.1\n92   92 cognitive  after  96.7\n93   93 cognitive  after  95.3\n94   94 cognitive  after  82.4\n95   95 cognitive  after  72.5\n96   96 cognitive  after  90.9\n97   97 cognitive  after  71.3\n98   98 cognitive  after  85.4\n99   99 cognitive  after  81.6\n100 100 cognitive  after  89.1\n101 101 cognitive  after  83.9\n102 102 cognitive  after  82.7\n103 103 cognitive  after  75.7\n104 104 cognitive  after  82.6\n105 105 cognitive  after 100.4\n106 106 cognitive  after  85.2\n107 107 cognitive  after  83.6\n108 108 cognitive  after  84.6\n109 109 cognitive  after  96.2\n110 110 cognitive  after  86.7\n111 111    family before  83.8\n112 112    family before  83.3\n113 113    family before  86.0\n114 114    family before  82.5\n115 115    family before  86.7\n116 116    family before  79.6\n117 117    family before  76.9\n118 118    family before  94.2\n119 119    family before  73.4\n120 120    family before  80.5\n121 121    family before  81.6\n122 122    family before  82.1\n123 123    family before  77.6\n124 124    family before  83.5\n125 125    family before  89.9\n126 126    family before  86.0\n127 127    family before  87.3\n128 128    family  after  95.2\n129 129    family  after  94.3\n130 130    family  after  91.5\n131 131    family  after  91.9\n132 132    family  after 100.3\n133 133    family  after  76.7\n134 134    family  after  76.8\n135 135    family  after 101.6\n136 136    family  after  94.9\n137 137    family  after  75.2\n138 138    family  after  77.8\n139 139    family  after  95.5\n140 140    family  after  90.7\n141 141    family  after  92.5\n142 142    family  after  93.8\n143 143    family  after  91.7\n144 144    family  after  98.0\n\naov2$treatment=as.factor(aov2$treatment)\naov2$ba=as.factor(aov2$ba)\naov2$id=as.factor(aov2$id)\nstr(aov2)\n\n'data.frame':   144 obs. of  4 variables:\n $ id       : Factor w/ 144 levels \"1\",\"2\",\"3\",\"4\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ treatment: Factor w/ 3 levels \"cognitive\",\"control\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ ba       : Factor w/ 2 levels \"before\",\"after\": 1 1 1 1 1 1 1 1 1 1 ...\n $ value    : num  80.7 89.4 91.8 74 78.1 88.3 87.3 75.1 80.6 78.4 ...\n\naov4=aov(value~treatment*ba,data=aov2)\nsummary(aov4)\n\n              Df Sum Sq Mean Sq F value   Pr(>F)    \ntreatment      2    644   322.1   8.025 0.000505 ***\nba             1    275   275.0   6.851 0.009847 ** \ntreatment:ba   2    307   153.7   3.828 0.024097 *  \nResiduals    138   5539    40.1                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ninteraction.plot(aov2$ba, aov2$treatment, aov2$value,main=\"Interaction plot\")\n\n\n\nHSD.test(aov4, \"treatment\", group=T,console=TRUE)\n\n\nStudy: aov4 ~ \"treatment\"\n\nHSD Test for value \n\nMean Square Error:  40.1406 \n\ntreatment,  means\n\n             value      std  r  Min   Max\ncognitive 84.19310 6.935337 58 70.0 103.6\ncontrol   81.33269 5.201045 52 70.5  91.8\nfamily    86.86176 7.785963 34 73.4 101.6\n\nAlpha: 0.05 ; DF Error: 138 \nCritical Value of Studentized Range: 3.350657 \n\nGroups according to probability of means differences and alpha level( 0.05 )\n\nTreatments with the same letter are not significantly different.\n\n             value groups\nfamily    86.86176      a\ncognitive 84.19310     ab\ncontrol   81.33269      b\n\nHSD.test(aov4, \"ba\", group=T,console=TRUE)\n\n\nStudy: aov4 ~ \"ba\"\n\nHSD Test for value \n\nMean Square Error:  40.1406 \n\nba,  means\n\n          value      std  r  Min   Max\nafter  85.17222 8.035173 72 71.3 103.6\nbefore 82.40833 5.182466 72 70.0  94.9\n\nAlpha: 0.05 ; DF Error: 138 \nCritical Value of Studentized Range: 2.796329 \n\nMinimun Significant Difference: 2.087921 \n\nTreatments with the same letter are not significantly different.\n\n          value groups\nafter  85.17222      a\nbefore 82.40833      b\n\n\n\n\n2.\n근육 피로도의 지표로 쓰이는 혈중젖산농도의 참값과 계측기에서의 값의 자료이다. 계측기가 정확하다면 두 자료의 직선식은 원점을 지나는 45도 직선이어야 한다. 분석하여라.\n\ntrue_val=c(rep(1,4),rep(3,5),rep(5,3),rep(10,4),rep(15,4))\nest_val=c(1.1,0.7,1.8,0.4,3.0,1.4,4.9,4.4,4.5,7.3,8.2,6.2,12,13.1,12.6,13.2,18.7,19.7,17.4,17.1)\n\nlactic=data.frame(true_val,est_val)\nlactic\n\n   true_val est_val\n1         1     1.1\n2         1     0.7\n3         1     1.8\n4         1     0.4\n5         3     3.0\n6         3     1.4\n7         3     4.9\n8         3     4.4\n9         3     4.5\n10        5     7.3\n11        5     8.2\n12        5     6.2\n13       10    12.0\n14       10    13.1\n15       10    12.6\n16       10    13.2\n17       15    18.7\n18       15    19.7\n19       15    17.4\n20       15    17.1\n\ndim(lactic)\n\n[1] 20  2\n\nsummary(lactic) #평균 실제 젖산값은 6.7, 평균 측정 젖산값은 8.385로 실제 값에 비해서 높게 측정되었다.\n\n    true_val       est_val      \n Min.   : 1.0   Min.   : 0.400  \n 1st Qu.: 3.0   1st Qu.: 2.700  \n Median : 5.0   Median : 6.750  \n Mean   : 6.7   Mean   : 8.385  \n 3rd Qu.:10.0   3rd Qu.:13.125  \n Max.   :15.0   Max.   :19.700  \n\nmedtrue <- as.vector(3)\nmedest <- as.vector(3)\n\nmedtrue[1] <- median(lactic$true_val[1:6]); medest[1] <- median(lactic$est_val[1:6])\nmedtrue[2] <- median(lactic$true_val[7:14]); medest[2] <- median(lactic$est_val[7:14])\nmedtrue[3] <- median(lactic$true_val[15:20]); medest[3] <- median(lactic$est_val[15:20])\nplot(medest~medtrue, type=\"b\",main=\"True value와 Estimation Value 사이의 관계\")   # 다소 Concave 한 관계인 것으로 보인다.\n\n\n\nplot(lactic$est_val~lactic$true_val,main=\"relationship of truevalue and estimatedvalue\")\n(z <- line(x=lactic$true_val,y=lactic$est_val))\n\n\nCall:\nline(x = lactic$true_val, y = lactic$est_val)\n\nCoefficients:\n[1]  -0.9026   1.4053\n\nabline(coef(z))\nresiduals(z)\n\n [1]  0.59736842  0.19736842  1.29736842 -0.10263158 -0.31315789 -1.91315789\n [7]  1.58684211  1.08684211  1.18684211  1.17631579  2.07631579  0.07631579\n[13] -1.15000000 -0.05000000 -0.55000000  0.05000000 -1.47631579 -0.47631579\n[19] -2.77631579 -3.07631579\n\nz.ls <- lm(lactic$est_val ~ lactic$true_val)\nabline(z.ls$coef, lty=2,col=\"red\")\n\nlegend(x = 2, y = 18, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)\n\n\n\n# 잔차제곱합\nsum(residuals(z))\n\n[1] -2.552632\n\nsum(residuals(z)^2)\n\n[1] 37.86429\n\nattach(lactic)\n\nThe following objects are masked _by_ .GlobalEnv:\n\n    est_val, true_val\n\n# 두 자료가 같은 분포에서 온게 맞을까?\nqqplot(true_val,est_val,main=\"qqplot\")\nabline(line(qqplot(true_val,est_val,main=\"qqplot\"))$coef) # 전반적으로 Tukey's robust line estimation 직선위에 잘 존재하는 것으로 보인다.\n\n\n\n# 분포 예측하기\nlibrary(aplpack)\nstem.leaf.backback(true_val,est_val,rule.line=\"Sturges\") # 두 자료 모두 정규분포보다는 Skewed to the right 되어 있는 것을 어느정도 예측할 수 있다. \n\n______________________________________\n  1 | 2: represents 12, leaf unit: 1 \n        true_val      est_val     \n______________________________________\n   9   333331111| 0* |001113444   9   \n  (3)        555| 0. |678        (3)  \n   8        0000| 1* |2233        8   \n   4        5555| 1. |7789        4   \n                | 2* |                \n______________________________________\nn:            20      20          \n______________________________________\n\nskewness(true_val) # skewed to the right \n\n[1] 0.4285714\n\nskewness(est_val) # 실제 자료에 비해서 덜 skewed 되어있다 (skewed to the right)\n\n[1] 0.1906977\n\n# Letter Value Display\nlvd7=(lsum(true_val,6))\nlvd8=(lsum(est_val,6))\nlvd7\n\n  letter depth lower mid upper spread\n1      M  10.5     5 5.0     5      0\n2      H   5.5     3 6.5    10      7\n3      E   3.0     1 8.0    15     14\n4      D   2.0     1 8.0    15     14\n5      C   1.5     1 8.0    15     14\n6      B   1.0     1 8.0    15     14\n\nlvd8\n\n  letter depth lower    mid upper spread\n1      M  10.5  6.75  6.750  6.75   0.00\n2      H   5.5  2.40  7.775 13.15  10.75\n3      E   3.0  1.10  9.250 17.40  16.30\n4      D   2.0  0.70  9.700 18.70  18.00\n5      C   1.5  0.55  9.875 19.20  18.65\n6      B   1.0  0.40 10.050 19.70  19.30\n\n# H-Spread\nlvd7[2,5]-lvd7[2,3]\n\n[1] 7\n\nlvd8[2,5]-lvd8[2,3] # H Spread의 경우 예측값에서 더 길게 나타나고 있다.\n\n[1] 10.75\n\n# Kurtosis (E-spread / H-spread - 1.705)\n(lvd7[3,5]-lvd7[3,3])/(lvd7[2,5]-lvd7[2,3])-1.705 # more peaked than normal\n\n[1] 0.295\n\n(lvd8[3,5]-lvd8[3,3])/(lvd8[2,5]-lvd8[2,3])-1.705 # less peaked than normal \n\n[1] -0.1887209\n\n# 두 데이터를 합치고 해당 데이터들이 동일한 분포를 따르고 있는지 확인하기 \nlactic2=c(true_val,est_val)\nlactic2\n\n [1]  1.0  1.0  1.0  1.0  3.0  3.0  3.0  3.0  3.0  5.0  5.0  5.0 10.0 10.0 10.0\n[16] 10.0 15.0 15.0 15.0 15.0  1.1  0.7  1.8  0.4  3.0  1.4  4.9  4.4  4.5  7.3\n[31]  8.2  6.2 12.0 13.1 12.6 13.2 18.7 19.7 17.4 17.1\n\nqqnorm(lactic2);qqline(lactic2,col=\"red\",lty=2) \n\n\n\n#점들이 Tukey's robust line estimation위를 따르기 보다는 역s자 형태의 곡선의 형태를 띄고 있는 것을 확인할 수 있다.\n#허명회교수님의 책 113pg에 보면 혼합정규분포에서의 모의생성자료가 역 S자 형태를 띄고 있는데 현재 Plot도 그러한 것으로 보아 실제 데이터와 측정치 데이터가 서로 다른 분포를 따르고 있지 않을까 추측할 수 있다.\n#또한, 꼬리가 짧은 분포일때의 형태와 비슷하게 왼쪽 끝 자료들이 직선을 벗어나있다. \n\n# 두 데이터는 서로 다른 분포에서 왔다고 추정할 수 있다. 그러나 눈대중으로 판단하는 것은 한계가 있기 때문에 이 판단을 재확인하기 위해서는 Tuckey의 Mean-Difference Plot을 활용해야한다. \nqqplot(x=true_val,y=est_val,xlim=c(min(true_val,est_val),max(true_val,est_val)),\n       ylim=c(min(true_val,est_val),max(true_val,est_val))\n       ,main=\"QQ_plot of true value and estimated value\")\nabline(0,1,lty=2,col=\"darkgreen\",lwd=2) #초반의 일부 데이터를 제외하면 대부분이 주대각선 위에 존재하고 있다. \n\n\n\n# 따라서 두 Estimation의 평균은 같다고 보기 힘들다.\n\nqq.x <- qqplot(x=true_val,y=est_val)$x\nqq.y <- qqplot(x=true_val,y=est_val)$y\n\n\n\nplot((qq.x+qq.y)/2, qq.y-qq.x, main=\"Tukey mean difference plot\", \n     ylab=\"est_val - true_val\", xlab=\"mean\")\nabline(0,0)\n\n\n\n# mean difference plot을 통해서 확인하더라도 몇몇자료를 제외하면 대부분의 자료가 x축보다 위에 존재하는 것으로 보인다.\n\nqqplot을 통해서 처음 확인하였을 때 자료들이 전부 직선위에 존재하는 것 처럼 보였으나 실제로 자료들을 합쳐서 qqplot을 그릴경우 역s자 형태로 나타나서 동일한 분포에서 나온 데이터가 아닐 수도 있음을 확인할 수 있었고 mean-difference plot을 통해서 이를 재 확인할 수 있었다. 따라서 어떤 자료를 측정하는 경우 계측기가 정확하다면 두 자료는 동일한 분포를 따르는 것이 맞겠지만, 계측기가 정확하지 않기 때문에 두 자료들이 서로 다른 분포를 따르고 있다는 것을 확인할 수 있었다. 시각적으로 예측해보는 것은 항상 정확하지 않기 때문에 지금처럼 검증이 필요하다고 생각한다.\n\nattach(lactic)\n\nThe following objects are masked _by_ .GlobalEnv:\n\n    est_val, true_val\n\n\nThe following objects are masked from lactic (pos = 3):\n\n    est_val, true_val\n\ncor.test(true_val,est_val) #매우 높은 상관관계가 존재함.\n\n\n    Pearson's product-moment correlation\n\ndata:  true_val and est_val\nt = 26.107, df = 18, p-value = 9.278e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9668337 0.9949756\nsample estimates:\n      cor \n0.9870507 \n\nplot(est_val~true_val)\n(z <- line(x=true_val,y=est_val))\n\n\nCall:\nline(x = true_val, y = est_val)\n\nCoefficients:\n[1]  -0.9026   1.4053\n\nabline(coef(z),lty=2,col=\"red\")\n\n\n\nplot(residuals(z) ~ fitted(z), main = \"Residual plot by rline\")\nabline(0,0) # 잔차들이 우하향하는 듯하게 보인다.\n\n\n\nplot(sqrt(est_val)~(true_val))\n(z1 <- line(x=(true_val),y=sqrt(est_val)))\n\n\nCall:\nline(x = (true_val), y = sqrt(est_val))\n\nCoefficients:\n[1]  0.9012  0.2676\n\nabline(coef(z1),lty=2,col=\"red\")\n\n\n\nplot(residuals(z1) ~ fitted(z1), main = \"Residual plot by rline\")\nabline(0,0) #다소 완화되었다 그러나 자료들이 곡선의 경향성을 보여준다는 점에서 변환은 부적절하다. \n\n\n\ndetach(lactic)\n\n상관관계가 매우 높게 나타나서, r-line을 활용해 두 자료를 적합시키려고 하였는데 변환을 진행하기전 자료가 더 적합해보인다.\n\n\n3.\n취학아동의 정신 장애 상태와 부모의 사회경제적 지위(1=낮음, 6=높음)에 대한 표이다. 분석하여라.\n\nordered(1:6)\n\n[1] 1 2 3 4 5 6\nLevels: 1 < 2 < 3 < 4 < 5 < 6\n\nsoseco=as.data.frame(matrix(c(64,57,57,72,36,21,94,94,105,141,97,71,58,54,65,77,54,54,46,40,60,94,78,71),nrow=4,ncol=6,byrow=T))\ncolnames(soseco)=ordered(1:6)\nrownames(soseco)=c(\"Well\",\"Mild\",\"Moderate\",\"Impaired\")\n\n# median polish\nsoseco_polished=medpolish(soseco)\n\n1: 219\n2: 202.75\n3: 200\nFinal: 200\n\n# maxiter를 설정하지 않고 분석한 결과 maxiter=3에서 결과 값이 나오는 것을 확인하였다.\nsoseco_polished\n\n\nMedian Polish Results (Dataset: \"soseco\")\n\nOverall: 56.375\n\nRow Effects:\n    Well     Mild Moderate Impaired \n -11.875   39.375   -0.625    0.625 \n\nColumn Effects:\n      1       2       3       4       5       6 \n  0.250  -1.750   9.250  32.250  -0.250 -12.625 \n\nResiduals:\n              1      2     3      4     5       6\nWell      19.25  14.25  3.25  -4.75 -8.25 -10.875\nMild      -2.00   0.00  0.00  13.00  1.50 -12.125\nModerate   2.00   0.00  0.00 -11.00 -1.50  10.875\nImpaired -11.25 -15.25 -6.25   4.75 21.25  26.625\n\nplot(soseco_polished)\n#x축과 y축위에 데이터가 많이 있는 것으로 보인다. outlier로 보이는 4개의 점을 제외하면 전반적으로 residual들이 안정적이다.\nplot(soseco_polished)\nabline(0,1) #나름 점들이 경향성을 가지고 있는 것으로 보인다.\n\nz7=lm(as.vector(soseco_polished$residuals) ~ \n     as.vector(outer(soseco_polished$row,soseco_polished$col, \"*\")/soseco_polished$overall))[1]\nabline(z7,col=\"red\")\n\n\n\n# 기울기가 0.5665495이므로 1과는 다르므로 log변환의 필요성이 떨어져 보인다.\n# 직선을 그리기 어렵고 의미있는 패턴이 보이지 않기 때문에 변환이 요구되어보이지는 않는다. \n\nboxplot(soseco_polished$residuals) # Boxplot그릴경우 Outlier가 확인되어지지는 않는다.\n\n\n\n# 행 효과 크기 순으로 재정렬한 잔차표\nround(soseco_polished$residuals[order(soseco_polished$row),],1)\n\n             1     2    3     4    5     6\nWell      19.2  14.2  3.2  -4.8 -8.2 -10.9\nModerate   2.0   0.0  0.0 -11.0 -1.5  10.9\nImpaired -11.2 -15.2 -6.2   4.8 21.2  26.6\nMild      -2.0   0.0  0.0  13.0  1.5 -12.1\n\n# Check Decomposition\ndecomposed=(soseco_polished$overall + outer(soseco_polished$row,soseco_polished$col, \"+\") + soseco_polished$residuals)\ndecomposed\n\n          1  2   3   4  5  6\nWell     64 57  57  72 36 21\nMild     94 94 105 141 97 71\nModerate 58 54  65  77 54 54\nImpaired 46 40  60  94 78 71\n\nall(decomposed==soseco) \n\n[1] TRUE\n\n# 가법성 모형이 확인되어지고 있다.\n\n# Comparison Values\nround(outer(soseco_polished$row,soseco_polished$col, \"*\")/soseco_polished$overall,2)\n\n             1     2     3     4     5     6\nWell     -0.05  0.37 -1.95 -6.79  0.05  2.66\nMild      0.17 -1.22  6.46 22.52 -0.17 -8.82\nModerate  0.00  0.02 -0.10 -0.36  0.00  0.14\nImpaired  0.00 -0.02  0.10  0.36  0.00 -0.14\n\n# Comparison value 기준으로 0값이 총 4개 확인됨. 그런데 더 많은 값들이 Additivity Plot의 x축과 y축 근처에 존재하는 것으로 보아 몇몇 피팅에서 벗어난 값을 제외하면 대부분 0근처에서 존재하고 있는 것이 확인된다. \n\n#stem and leaf plot\nstem(soseco_polished$residuals) # stem 0이 가장 높음 (낮은 잔차인 stem -1의 잔차들이 다소 많이 나타나고 있음)\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  -1 | 52111\n  -0 | 86522\n   0 | 00002235\n   1 | 1349\n   2 | 17\n\n# Row Effect \nbarplot(soseco_polished$row,ylim=c(-15,40), main=\"정신상태의 효과\")\n\n\n\nsoseco_polished$row\n\n    Well     Mild Moderate Impaired \n -11.875   39.375   -0.625    0.625 \n\n# Row Effect에 대해서 먼저 분석을 진행해 보았다. 정신상태가 Mild인 경우 부모님의 사회경제적 지위가 가장 높아졌고, Well인경우 부모님의 사회경제적 지위가 낮은 것으로 보인다. \n\n# Column Effect\nbarplot(soseco_polished$col, ylim=c(-20,40) , main=\"부모님 사회경제적 지위의 효과\")\n\n\n\nsoseco_polished$col\n\n      1       2       3       4       5       6 \n  0.250  -1.750   9.250  32.250  -0.250 -12.625 \n\n# Column Effect에 대해서 분석을 진행해 보았다. 부모님의 사회경제적 지위가 4인 경우에 정신상태가 나빠질 가능성이 많은 편이다. 부모님의 사회경제적 지위가 6인경우 정신상태가 다른 집단들에 비해서 긍정적으로 나타나는 것이 확인되어진다. \n\n\npar(mfrow=c(2,2))\nfor (i in 1:4) {barplot(soseco_polished$residuals[i,],main=rownames(soseco)[i])}\n\n\n\n# 정신상태가 Well과 Impaired 된 집단을 기준으로 볼 경우 부모님의 사회경제적 지위가 높을수록 정신상태가 나쁜 Case가 많고, 낮을수록 정신상태가 좋은 Case가 많다. \n\npar(mfrow=c(2,3))\nfor (i in 1:6) {barplot(soseco_polished$residuals[,i],main=names(soseco)[i])}\n\n\n\n# 부모님의 사회경제적 지위가 높을 수록 정신상태가 나쁜 경향성을 보이고, 사회 경제적 지위가 낮을 때 정신상태가 좋게 나타나고 있다.\n\npar(mfrow=c(1,1))\n\n# twoway plot\nlibrary(\"twoway\")\ntwoway(soseco, method=\"median\")\n\n\nMedian polish decomposition (Dataset: \"soseco\"; Response: Value)\nResiduals bordered by row effects, column effects, and overall\n\n           1       2       3       4       5       6         roweff \n         + ------- ------- ------- ------- ------- ------- + -------\nWell     |  19.250  14.250   3.250  -4.750  -8.250 -10.875 : -11.875\nMild     |  -2.000   0.000   0.000  13.000   1.500 -12.125 :  39.375\nModerate |   2.000   0.000   0.000 -11.000  -1.500  10.875 :  -0.625\nImpaired | -11.250 -15.250  -6.250   4.750  21.250  26.625 :   0.625\n         + ....... ....... ....... ....... ....... ....... + .......\ncoleff   |   0.250  -1.750   9.250  32.250  -0.250 -12.625 :  56.375\n\nplot(twoway(soseco, method=\"median\"))\n\n\n\n# mosaic plot\nlibrary(ghibli)\npal=ghibli_palette(\"PonyoMedium\",n=6)\npal\n\n\n\nmosaicplot(soseco,color=pal,main=\"mosaic plot of sosioeconomic data\")\n\n\n\n#부모님의 사회 경제적 위치가 높을수록 정신 상태가 안 좋은 사람들의 비율이 올라가는 듯한 경향성이 보이는 듯 하다. \n\n# coded plot\nresid=soseco_polished$residuals\nstandard=as.vector(resid)\nfivenum(standard)\n\n[1] -15.2500  -7.2500   0.0000   7.8125  26.6250\n\nHspread=fivenum(standard)[4]-fivenum(standard)[2]\ninner=c(fivenum(standard)[4]+1.5*Hspread,fivenum(standard)[2]-1.5*Hspread)\nouter=c(fivenum(standard)[4]+3*Hspread,fivenum(standard)[2]-3*Hspread)\n\nresid=as.data.frame(resid)\n# 교과서 기준과 동일하게 \"M\" - Far outside low, \"=\"- below low inner fence(outise), \"-\" - Below lower hinge but within inner fence\n# \".\" - Between Hinges , \"+\"- Above upper hinge, \"#\" - Above High inner fence (outside), \"F\" - Far outside high\nresid_coded=ifelse(resid >= outer[1], \"F\",\n                        ifelse(resid>= inner[1], \"#\",\n                               ifelse(resid >= fivenum(standard)[4],\"+\",\n                                      ifelse(resid >=fivenum(standard)[2] ,\".\",\n                                             ifelse(resid>= inner[2],\"-\",\n                                                    ifelse(resid >= outer[2],\"=\",\"M\"))))))\nresid_coded=as.data.frame(resid_coded)\nresid_coded #위에서 확인하였던 경향성이 다시한번 확인된다 (부모의 사회경제적 위치가 올라갈수록 정신질환을 가지는 경우가 높아짐)\n\n         1 2 3 4 5 6\nWell     + + . . - -\nMild     . . . + . -\nModerate . . . - . +\nImpaired - - . . + +\n\n\n\n\n4.\n자료는 정상적인 쥐, 알록산(alloxan)에 의해 당뇨병이 유발된 쥐, 당뇨병이 유발된 후 인슐린으로 치료한 쥐에서의 알부민양이다. 세 자료의 분포가 같은 지 분석하여라. 자료를 재표현하여 대칭형으로 만들고 분포가 같은 지 다시 분석하여라. [DIABETIC.DAT]\n\ndiabetes=read.delim(\"C:/r/DIABETIC.DAT\",header=F)\nnames(diabetes)=c(\"normal\",\"alloxan\",\"insulin\")\n\ndim(diabetes)\n\n[1] 20  3\n\nsummary(diabetes)\n\n     normal         alloxan          insulin     \n Min.   : 14.0   Min.   : 13.00   Min.   : 18.0  \n 1st Qu.:104.0   1st Qu.: 76.25   1st Qu.: 45.0  \n Median :124.5   Median :139.50   Median : 82.0  \n Mean   :186.1   Mean   :181.83   Mean   :112.9  \n 3rd Qu.:260.2   3rd Qu.:251.00   3rd Qu.:132.0  \n Max.   :655.0   Max.   :499.00   Max.   :465.0  \n                 NA's   :2        NA's   :1      \n\n# 결측치의 확인 \ncolSums(is.na(diabetes)) # alloxan에서 2개 insulin에서 1개\n\n normal alloxan insulin \n      0       2       1 \n\n# Stem and leaf를 활용하여 각 집단의 분포를 비교\nattach(diabetes)\nlibrary(aplpack)\nstem.leaf.backback(normal,alloxan,rule.line=\"Sturges\") \n\n_____________________________________\n  1 | 2: represents 120, leaf unit: 10 \n          normal     alloxan     \n_____________________________________\n   5       86221| 0 |145678      6   \n  (9)  954222111| 1 |0234677    (7)  \n   6         985| 2 |77          5   \n   3           4| 3 |9           3   \n   2           5| 4 |69          2   \n                | 5 |                \n_____________________________________\nHI: 655                              \nn:            20     20          \nNAs:           0     2           \n_____________________________________\n\n# normal data와 alloxan data모두 skewed to the right 되어 있는 자료로 stem 1에서 가장 많은 데이터를 보인다.\nstem.leaf.backback(normal,insulin,rule.line=\"Sturges\")\n\n__________________________________\n  1 | 2: represents 120, leaf unit: 10 \n        normal      insulin   \n__________________________________\n   3       221| 0* |123444    6   \n   5        86| 0. |67789    (5)  \n  (7)  4222111| 1* |0033      8   \n   8        95| 1. |5         4   \n              | 2* |24        3   \n   6       985| 2. |              \n   3         4| 3* |              \n__________________________________\nHI: 455 655         HI: 465       \nn:          20      20        \nNAs:         0      1         \n__________________________________\n\n# normal data의 경우 stem 1*을 중심으로 하고 있으며 stem 2*의 경우 중간에 비어 있는 모습을 확인할 수 있다. (Outlier의 가능성)\n# insulin data의 경우 stem 0*에서 가장 많은 자료가 있고 해당 자료도 skewed to the right 되어 있는 것을 확인할 수 있다.\nstem.leaf.backback(alloxan,insulin,rule.line=\"Sturges\")\n\n________________________________\n  1 | 2: represents 120, leaf unit: 10 \n      alloxan      insulin  \n________________________________\n   2       41| 0* |123444   6   \n   6     8765| 0. |67789   (5)  \n  (4)    4320| 1* |0033     8   \n   8      776| 1. |5        4   \n             | 2* |24       3   \n   5       77| 2. |             \n             | 3* |             \n________________________________\nHI: 391 469        HI: 465      \n499                             \nn:         20      20       \nNAs:        2      1        \n________________________________\n\n# 첫번째 stem and leaf에서는 alloxan data가 종모양을 이루고 있지 않은 것으로 보였으나 조금더 확대하였더니 어느정도 종모양을 띄고 있는 것이 확인된다.\n\n\nfivenum(normal)\n\n[1]  14.0  98.0 124.5 267.5 655.0\n\nfivenum(alloxan)\n\n[1]  13.0  73.0 139.5 276.0 499.0\n\nfivenum(insulin)\n\n[1]  18  45  82 132 465\n\n# Boxplot\nboxplot(diabetes,main=\"Comparison of groups\")\n\n\n\nboxplot(diabetes)$out #2개의 outlier 확인됨. (아까 Stem and leaf에서 확인 한 부분 재확인)\n\n\n\n\n[1] 655 465\n\n# normal data에서 655의 outlier, insulin 투여 쥐에서 465의 outlier 확인\nboxplot(diabetes)$stats \n\n      [,1]  [,2] [,3]\n[1,]  14.0  13.0   18\n[2,]  98.0  73.0   45\n[3,] 124.5 139.5   82\n[4,] 267.5 276.0  132\n[5,] 455.0 499.0  243\n\n# Skewness\nskewness(normal) # skewed to the right\n\n[1] 0.6873156\n\nskewness(alloxan) # skewed to the right\n\n[1] 0.3448276\n\nskewness(insulin) # skewed to the right\n\n[1] 0.1494253\n\n# Letter Value Display\nsource(\"http://mgimond.github.io/ES218/es218.R\")\nlvd9=(lsum(normal,6))\nlvd10=(lsum(alloxan,6))\nlvd11=(lsum(insulin,6))\nlvd9\n\n  letter depth lower    mid upper spread\n1      M  10.5 124.5 124.50 124.5    0.0\n2      H   5.5  98.0 182.75 267.5  169.5\n3      E   3.0  29.0 189.00 349.0  320.0\n4      D   2.0  26.0 240.50 455.0  429.0\n5      C   1.5  20.0 287.50 555.0  535.0\n6      B   1.0  14.0 334.50 655.0  641.0\n\nlvd10\n\n  letter depth lower    mid upper spread\n1      M   9.5 139.5 139.50 139.5    0.0\n2      H   5.0  73.0 174.50 276.0  203.0\n3      E   3.0  50.0 220.50 391.0  341.0\n4      D   2.0  46.0 257.50 469.0  423.0\n5      C   1.5  29.5 256.75 484.0  454.5\n6      B   1.0  13.0 256.00 499.0  486.0\n\nlvd11\n\n  letter depth lower   mid upper spread\n1      M  10.0    82  82.0    82      0\n2      H   5.5    45  88.5   132     87\n3      E   3.0    34 131.0   228    194\n4      D   2.0    20 131.5   243    223\n5      C   1.5    19 186.5   354    335\n6      B   1.0    18 241.5   465    447\n\n# H-Spread\nlvd9[2,5]-lvd9[2,3]\n\n[1] 169.5\n\nlvd10[2,5]-lvd10[2,3] \n\n[1] 203\n\nlvd11[2,5]-lvd11[2,3]\n\n[1] 87\n\n# alloxan 집단에서 spread가 가장 크게 나타나며, normal 집단이 그다음, insulin 투여 집단의 분포는 좁게 나타나고 있다.\n\n# Kurtosis (E-spread / H-spread - 1.705)\n(lvd9[3,5]-lvd9[3,3])/(lvd9[2,5]-lvd9[2,3])-1.705 # more peaked than normal\n\n[1] 0.1829056\n\n(lvd10[3,5]-lvd10[3,3])/(lvd10[2,5]-lvd10[2,3])-1.705 # less peaked than normal\n\n[1] -0.02519704\n\n(lvd11[3,5]-lvd11[3,3])/(lvd11[2,5]-lvd11[2,3])-1.705 # more peaked than normal\n\n[1] 0.5248851\n\n# 정규성\nqqnorm(normal, ylab=\"normal group quantiles\",main=\"normal group\");qqline(normal, col='red',lty=2)\n# 점들이 직선을 잘 따르고 있지 않다. 앞에서 언급했던 outlier을 재확인하였으며, 점들이 convex한 곡선을 띄고 있는 것을 확인할 있다. \nfiv9=fivenum(normal)\n(pseudosigma9 = (fiv9[4]-fiv9[2])/1.34)\n\n[1] 126.4925\n\nsd(normal) # 약 32정도의 차이\n\n[1] 158.8349\n\nabline(fiv9[3],pseudosigma9,col=\"blue\",lty=2)\nlegend(x = -1.8, y = 600, c(\"qqline\", \"robustline\"), \n       lty=2,lwd=2,col = c(\"red\",\"blue\")) # 차이 존재\n\n\n\nqqnorm(alloxan, ylab=\"alloxan group quantiles\",main=\"alloxan group\");qqline(alloxan, col='red',lty=2)\n# 점들이 직선을 잘 따르고 있지 않다. 점들이 곡선을 띄고 있는 것을 확인할 있다. \nfiv10=fivenum(alloxan)\n(pseudosigma10 = (fiv10[4]-fiv10[2])/1.34)\n\n[1] 151.4925\n\nsd(alloxan,na.rm=T) # 약 7정도의 차이\n\n[1] 144.8493\n\nabline(fiv10[3],pseudosigma10,col=\"blue\",lty=2)\nlegend(x = -1.8, y = 500, c(\"qqline\", \"robustline\"), \n       lty=2,lwd=2,col = c(\"red\",\"blue\")) # 차이 존재\n\n\n\nqqnorm(insulin, ylab=\"insulin group quantiles\",main=\"insulin group\");qqline(insulin, col='red',lty=2)\n# oulier와 몇몇 2~3개의 점을 제외하면 점들이 직선을 잘 따르고 있는 것으로 보인다. \nfiv11=fivenum(insulin)\n(pseudosigma11 = (fiv11[4]-fiv11[2])/1.34)\n\n[1] 64.92537\n\nsd(insulin,na.rm=T) # 약 41정도의 차이\n\n[1] 105.7896\n\nabline(fiv11[3],pseudosigma11,col=\"blue\",lty=2)\nlegend(x = -1.8, y = 450, c(\"qqline\", \"robustline\"), \n       lty=2,lwd=2,col = c(\"red\",\"blue\")) # 거의 비슷함.\n\n\n\n#전반적으로 자료들이 skewed to the right되어있고 정규분포를 잘 따르지 않는 것으로 보인다. \n\n# 두 데이터를 합치고 해당 데이터들이 동일한 분포를 따르고 있는지 확인하기 \ndiabetes2=c(normal,alloxan,insulin)\ndiabetes2\n\n [1] 156 282 197 297 116 127 119  29 253 122 349 110 143  64  26  86 122 455 655\n[20]  14 391  46 469  86 174 133  13 499 168  62 127 276 176 146 108 276  50  73\n[39]  NA  NA  82 100  98 150 243  68 228 131  73  18  20 100  72 133 465  40  46\n[58]  34  44  NA\n\nqqnorm(diabetes2);qqline(diabetes2,col=\"red\",lty=2) \n\n\n\n#자료들이 Convex한 곡선의 형태를 띄고 있다 따라서 변환을 통해서 동일한 분포를 따르고 있는지 재확인해야 한다.\n#큰 값쪽으로 긴 꼬리를 뻗은 기울어진 분포\n\n# 자료의 재표현 - 일반적으로 많이 사용하는 재표현 방식의 사용\nboxplot(log(diabetes))\n\n\n\nboxplot(sqrt(diabetes))\n\n\n\nboxplot(-1/(diabetes))\n\n\n\nboxplot(-1/sqrt(diabetes))\n\n\n\n# Spread-versus-level Plot\ndiabetes_spread=c(lvd9[2,5]-lvd9[2,3],lvd10[2,5]-lvd10[2,3],lvd11[2,5]-lvd11[2,3])\ndiabetes_med=c(median(normal),median(alloxan,na.rm=T),median(insulin,na.rm=T))\n\nplot(log(diabetes_med), log(diabetes_spread), main=\"Spread vs. Level plot\")\n\nlogspread=log(diabetes_spread)\nlogmed=log(diabetes_med)\n(RegrLine <- lm(logspread~logmed))     \n\n\nCall:\nlm(formula = logspread ~ logmed)\n\nCoefficients:\n(Intercept)       logmed  \n     -2.564        1.595  \n\nabline(coef(RegrLine))\n\n\n\n1 - coef(RegrLine)[2] #-0.5853975 \n\n    logmed \n-0.5953067 \n\n# -0.5에 가까움\n\nboxplot(-(diabetes)^-0.5,main=\"-0.5 transformation\")\nboxplot(-(diabetes)^-0.5,main=\"-0.5 transformation\")$out # 총 4개의 outlier\n\n\n\n\n[1] -0.1856953 -0.1961161 -0.2672612 -0.2773501\n\nskewness_transformed1=c(skewness((-(diabetes)^-0.5)[,1]), skewness((-(diabetes)^-0.5)[,2]), skewness((-(diabetes)^-0.5)[,3]))\nskewness_transformed1\n\n[1]  0.4079370 -0.1365476 -0.2461638\n\nmean(skewness_transformed1) # skewness가 가장적음\n\n[1] 0.008408507\n\nboxplot(log(diabetes),main=\"log transformation\")\nboxplot(log(diabetes),main=\"log transformation\")$out # 총 3개의 outlier\n\n\n\n\n[1] 2.639057\n\nskewness_transformed2=c(skewness(log(diabetes)[,1]), skewness(log(diabetes)[,2]), skewness(log(diabetes)[,3]))\nskewness_transformed2     \n\n[1]  0.51161785  0.02774901 -0.11543537\n\nmean(skewness_transformed2)\n\n[1] 0.1413105\n\ndiabetes3=-(c(normal,alloxan,insulin))^-0.5\nqqnorm(diabetes3,main=\"minus sqrt inverse qqplot\");qqline(diabetes3,col=\"red\",lty=2) \n\n\n\ndiabetes4=log(c(normal,alloxan,insulin))\nqqnorm(diabetes4,main=\"log qqplot\");qqline(diabetes4,col=\"red\",lty=2) \n\n\n\ndiabetes5=sqrt(c(normal,alloxan,insulin))\nqqnorm(diabetes5,main=\"sqrt qqplot\");qqline(diabetes5,col=\"red\",lty=2) \n\n\n\ndiabetes6=-(c(normal,alloxan,insulin))^-1\nqqnorm(diabetes6,main=\"minus inverseqqplot\");qqline(diabetes6,col=\"red\",lty=2) \n\n\n\n# 전반적으로 log 나 sqrt변환 이후 자료들이 직선을 더 잘 따르고 있는 것을 확인할 수 있다. \n# QQplot 하에서 양 극단의 일부 데이터를 제외한 나머지 데이터들은 전부 qqline위에 있다는 점에서 변환이후 데이터들은 동일한 정규분포에서 나타난 것을 확인할 수 있다.\n\n# 가장 정규분포를 잘 따르고 있는 것으로 보이는 log변환을 활용해 Tuckey_Mean_Difference_Plot\n\nnor_log=log(diabetes)[,1];alo_log=log(diabetes)[,2];ins_log=log(diabetes)[,3]\nalo_log=alo_log[!is.na(alo_log)]\nins_log=ins_log[!is.na(ins_log)]\n\nqqplot(nor_log,alo_log,xlim=c(min(nor_log,alo_log),max(nor_log,alo_log)),\n       ylim=c(min(nor_log,alo_log),max(nor_log,alo_log))\n       ,main=\"QQ_plot of logged normal group and alloxan group\")\nabline(0,1,lty=2,col=\"darkgreen\",lwd=2) # 대부분의 자료들이 주대각선을 따르는 것으로 보인다.\n\n\n\nqqplot(nor_log,ins_log,xlim=c(min(nor_log,ins_log),max(nor_log,ins_log)),\n       ylim=c(min(nor_log,ins_log),max(nor_log,ins_log))\n       ,main=\"QQ_plot of logged normal group and insulin group\")\nabline(0,1,lty=2,col=\"darkgreen\",lwd=2) # 대부분의 자료들이 주대각선 밑에 있는 것으로 보인다. 따라서 같은 분포에서 나오지 않았을 가능성이 있다.\n\n\n\nqqplot(alo_log,ins_log,xlim=c(min(alo_log,ins_log),max(alo_log,ins_log)),\n       ylim=c(min(alo_log,ins_log),max(alo_log,ins_log))\n       ,main=\"QQ_plot of logged alloxan group and insulin group\")\nabline(0,1,lty=2,col=\"darkgreen\",lwd=2)  # 대부분의 자료들이 주대각선 밑에 있는 것으로 보인다. 따라서 같은 분포에서 나오지 않았을 가능성이 있다.\n\n\n\n#정리하면 Normal Group과 Alloxan Group의 경우는 같은 분포에서 나왔을 가능성이 높지만, insulin 투여 그룹은 다른 분포를 따르고 있을 가능성이 높다. \n\nqq.x1 <- qqplot(nor_log,alo_log)$x\nqq.y1 <- qqplot(nor_log,alo_log)$y\n\n\n\nplot((qq.x1+qq.y1)/2, qq.y1-qq.x1, main=\"Tukey mean difference plot\", \n     ylab=\"alo_log-nor_log\", xlab=\"mean\")\nabline(0,0)\n\n\n\nqq.x2 <- qqplot(nor_log,ins_log)$x\nqq.y2 <- qqplot(nor_log,ins_log)$y\n\n\n\nplot((qq.x2+qq.y2)/2, qq.y2-qq.x2, main=\"Tukey mean difference plot\", \n     ylab=\"ins_log-nor_log\", xlab=\"mean\")\nabline(0,0) # 대부분의 자료들이 X축의 밑에 있다.\n\n\n\nqq.x3 <- qqplot(alo_log,ins_log)$x\nqq.y3 <- qqplot(alo_log,ins_log)$y\n\n\n\nplot((qq.x3+qq.y3)/2, qq.y3-qq.x3, main=\"Tukey mean difference plot\", \n     ylab=\"ins_log-alo_log\", xlab=\"mean\")\nabline(0,0) # 대부분의 자료들이 X축의 밑에 있다.\n\n\n\n# 변환 이후 각 자료는 정규분포를 따르는가?\nqqnorm(nor_log);qqline(nor_log,col=\"red\") # outlier들을 제외하면 정규분포를 잘 따르는 것으로 보인다. (곡선의 흔적이 있으나 완화됨)\n\n\n\nqqnorm(alo_log);qqline(alo_log,col=\"red\") # 한두개의 점을 제외하면 정규분포를 잘 따르는 것으로 보인다.\n\n\n\nqqnorm(ins_log);qqline(ins_log,col=\"red\") # 가장 정규분포를 잘 따른다\n\n\n\n# 결론: 변환이후 각 자료들은 정규분포를 따르고 있는 것으로 보이나 그 각각의 평균은 다른 것으로 보이기에 서로 다른 분포를 따르고 있다고 보는 것이 타당하다. \n\n# 각 집단별 평균차이를 확인하기 위해서 일원분산분석을 진행하고자 한다.\nlibrary(reshape2)\ndia_melt=melt(diabetes)\n\nNo id variables; using all as measure variables\n\ndia_melt=dia_melt[!is.na(dia_melt$value),]\naov4=aov(value~variable,data=dia_melt)\nsummary(aov4) #H0: 각 집단간 평균차이는 없다. H1: 각 집단간 평균차이는 있다. \n\n            Df  Sum Sq Mean Sq F value Pr(>F)\nvariable     2   64357   32178   1.675  0.197\nResiduals   54 1037470   19212               \n\n# Do not reject null hypothesis\n\nlibrary(doBy)\nsummaryBy(value ~ variable, data=dia_melt, FUN = c(mean, sd, min, max))\n\n  variable value.mean value.sd value.min value.max\n1   normal   186.1000 158.8349        14       655\n2  alloxan   181.8333 144.8493        13       499\n3  insulin   112.8947 105.7896        18       465\n\nlibrary(agricolae)\nHSD.test(aov4, \"variable\", group=TRUE,console=TRUE) # 각집단간 차이가 명확하게 드러나지 않는다\n\n\nStudy: aov4 ~ \"variable\"\n\nHSD Test for value \n\nMean Square Error:  19212.41 \n\nvariable,  means\n\n           value      std  r Min Max\nalloxan 181.8333 144.8493 18  13 499\ninsulin 112.8947 105.7896 19  18 465\nnormal  186.1000 158.8349 20  14 655\n\nAlpha: 0.05 ; DF Error: 54 \nCritical Value of Studentized Range: 3.408232 \n\nGroups according to probability of means differences and alpha level( 0.05 )\n\nTreatments with the same letter are not significantly different.\n\n           value groups\nnormal  186.1000      a\nalloxan 181.8333      a\ninsulin 112.8947      a\n\ndia_melt2=dia_melt\ndia_melt2$value=log(dia_melt$value)\naov5=aov(value~variable,data=dia_melt2)\nsummary(aov5)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nvariable     2   2.75  1.3751   1.665  0.199\nResiduals   54  44.61  0.8261               \n\n\n\n\n5.\n1974년부터 1979년 까지 영국에서 기관지염, 폐기종, 천식의 폐 질환에 의한 월별 사망자 수이다. 분석하라. [MONTHLY.DAT]\n\nlung=as.matrix(read.delim(\"C:/r/MONTHLY.DAT\",header=F,)[,c(2:13)])\nlung\n\n       V2   V3   V4   V5   V6   V7   V8   V9  V10  V11  V12  V13\n[1,] 3035 2552 2704 2554 2014 1655 1721 1524 1596 2074 2199 2512\n[2,] 2933 2889 2938 2497 1870 1726 1607 1545 1396 1787 2076 2837\n[3,] 2787 3891 3179 2011 1636 1580 1489 1300 1356 1653 2013 2823\n[4,] 2996 2523 2540 2520 1994 1641 1691 1479 1596 1877 2032 2484\n[5,] 2899 2990 2890 2379 1933 1734 1617 1495 1440 1777 1970 2745\n[6,] 2841 3535 3010 2091 1667 1589 1518 1349 1392 1619 1954 2633\n\nlung2=as.vector(c(lung[1,],lung[2,],lung[3,],lung[4,],lung[5,],lung[6,]))\nlung_ts=ts(lung2,frequency=12,start = c(1974,1), end=c(1979,12))\n\nsummary(lung_ts) #최소값은 1300, 최대값은 3891, 평균은 2002이다.\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1300    1618    2002    2144    2651    3891 \n\n# 결측치와 outlier의 존재여부를 체크하고자 한다.\nboxplot(lung_ts, main=\"Lung Disease Deaths\")  # Outlier는 없다. Upper Whisker의 길이가 및의 Whisker에 비해서 길게 나타나진다. \n\n\n\nsum(is.na(lung_ts)) # 결측치 없음.\n\n[1] 0\n\n# Steam and leaf plot을 활용해서 자료의 분포를 예측해보고자 했다.\nstem(lung_ts,1)\n\n\n  The decimal point is 3 digit(s) to the right of the |\n\n  1 | 334444\n  1 | 555555666666666777777788999\n  2 | 000000011124\n  2 | 55555566677888899999\n  3 | 00002\n  3 | 59\n\n# 쌍봉분포의 경향. 두개의 Cluster가 존재하는 것 처럼 보인다. \nstem(lung_ts,2)\n\n\n  The decimal point is 2 digit(s) to the right of the |\n\n  12 | 0569\n  14 | 0489022589\n  16 | 0012244567923389\n  18 | 783579\n  20 | 1113789\n  22 | 08\n  24 | 80122455\n  26 | 3059\n  28 | 244990349\n  30 | 0148\n  32 | \n  34 | 4\n  36 | \n  38 | 9\n\n#자료들이 Skewed to the right 되어 있는 것으로 보인다. Stem 16에서 가장 높게 나타나고 있으며 대칭적으로 보이지는 않는다. \n#중간에 빈칸이 있어서 두개의 Outlier가 있을 것으로 예상되었지만 Boxplot을 통해 보았듯이 따로 Outlier는 나타나지 않는 것으로 보인다.\n\n#skewness\nskewness(lung_ts) #Skewed to the right되어 있음.\n\n[1] 0.2679676\n\nskewness(log(lung_ts))\n\n[1] 0.1476176\n\nboxplot(log(lung_ts)) # log 변환을 하면 다소 완화됨\n\n\n\n# letter value display\nsource(\"http://mgimond.github.io/ES218/es218.R\")\n(lvd12=lsum(lung_ts,9)) # mid 값이 점차 커지는 중\n\n  letter depth  lower     mid  upper spread\n1      M  36.5 2002.5 2002.50 2002.5    0.0\n2      H  18.5 1618.0 2143.25 2668.5 1050.5\n3      E   9.5 1506.5 2211.25 2916.0 1409.5\n4      D   5.0 1396.0 2203.00 3010.0 1614.0\n5      C   3.0 1356.0 2267.50 3179.0 1823.0\n6      B   2.0 1349.0 2442.00 3535.0 2186.0\n7      A   1.5 1324.5 2518.75 3713.0 2388.5\n8      Z   1.0 1300.0 2595.50 3891.0 2591.0\n\n# Kurtosis (E-spread) / (H-spread) - 1.705\n(lvd12[3,5]-lvd12[3,3])/(lvd12[2,5]-lvd12[2,3])-1.705 # less peaked than normal\n\n[1] -0.363258\n\n# H-Spread\nHspread=fivenum(lung_ts)[4]-fivenum(lung_ts)[2]\nHspread\n\n[1] 1050.5\n\n# 자료들이 정규성 따르냐?\nqqnorm(lung_ts, ylab=\"Lung Disease Deaths Quantiles\");qqline(lung_ts, col='red',lty=2) #역 S자 모양\n\n\n\nqqnorm(log(lung_ts), ylab=\"Logged Lung Disease Deaths Quantiles\");qqline(log(lung_ts), col='red',lty=2) #역 S자 모양\n\n\n\n# 데이터들이 혼합 분포에서 나오지 않았을까하고 추측되어진다. (단일 정규분포를 따르지 않으므로 정규성은 X)\n\nlibrary(forecast)\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nts.plot(lung_ts, main = \"Time-Series Plot: Lung Diseases Deaths\") #1976년과 1979년의 봉우리에 두번의 특이값이 확인됨\n\n\n\nts.plot(diff(lung_ts), main = \"Time-Series Plot: Lung Diseases Deaths\") #차분데이터에 대해서 시계열자료는 다음과 같다. \n\n\n\n# 6년동안 6개의 봉우리가 있으므로 매년 이러한 계절성이 존재한다는 것을 확인할 수 있다. \n\n# Box-Cox Transformation을 통해서 데이터를 변환하였다. (계절변동을 확인하기 위해서, 데이터의 정규성을 개선하기 위해)\nlambda <- forecast::BoxCox.lambda(lung_ts)\nlung_ts_new <- forecast::BoxCox(lung_ts, lambda)\n\n# 데이터가 0인 경우가 없기 때문에 Boxcox transforamtion을 진행해도 문제 없다.\nplot(lung_ts_new, main = \"Box-Cox : Lung Diseases Deaths\")\n\n\n\nplot(diff(lung_ts_new), main = \"Difference & Box-Cox : Lung Diseases Deaths\")\n\n\n\n# 계절요인 분해시계열\nlung_ts.decompose <- decompose(lung_ts)       # 데이터에서 4가지 요인을 분해\nlung_ts.decompose$seasonal                     # 계절요인으로 분해된 부분이다.\n\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n1974  732.1972 1009.7472  758.7056  152.3972 -321.3694 -486.3361 -530.4278\n1975  732.1972 1009.7472  758.7056  152.3972 -321.3694 -486.3361 -530.4278\n1976  732.1972 1009.7472  758.7056  152.3972 -321.3694 -486.3361 -530.4278\n1977  732.1972 1009.7472  758.7056  152.3972 -321.3694 -486.3361 -530.4278\n1978  732.1972 1009.7472  758.7056  152.3972 -321.3694 -486.3361 -530.4278\n1979  732.1972 1009.7472  758.7056  152.3972 -321.3694 -486.3361 -530.4278\n           Aug       Sep       Oct       Nov       Dec\n1974 -693.4028 -695.9444 -337.8361 -106.6861  518.9556\n1975 -693.4028 -695.9444 -337.8361 -106.6861  518.9556\n1976 -693.4028 -695.9444 -337.8361 -106.6861  518.9556\n1977 -693.4028 -695.9444 -337.8361 -106.6861  518.9556\n1978 -693.4028 -695.9444 -337.8361 -106.6861  518.9556\n1979 -693.4028 -695.9444 -337.8361 -106.6861  518.9556\n\nplot(lung_ts.decompose)\n\n\n\nts.plot(lung_ts.decompose$seasonal,main=\"The Plot of Seasoal Decomposition\")\n\n\n\n# 계절요인 제외시키기\nlung_ts.decompose_new <- lung_ts - lung_ts.decompose$seasonal\nts.plot(lung_ts.decompose_new, main=\"Time-Series without Seasonal Effect\")\n\n\n\n# 계절성을 제외한 나머지 요인들을 분석할 경우 1976,1979년도의 Random한 요인에 의해서 데이터가 늘어난 것을 확인 할 수 있다.\n# 또한 1974년 1977년 두번의 Random한 요인에 의해서 데이터가 줄어듦\n\nlung_1974=ts(lung_ts[1:12],start=1)\nlung_1975=ts(lung_ts[13:24],start=1)\nlung_1976=ts(lung_ts[25:36],start=1)\nlung_1977=ts(lung_ts[37:48],start=1)  \nlung_1978=ts(lung_ts[49:60],start=1)\nlung_1979=ts(lung_ts[61:72],start=1)\nyr=paste(\"lung\",\"_\",1974:1979,sep=\"\")\nxat=seq(0,12,by=1)\n\npar(mfrow=c(2,3))\n\nfor (i in yr) {ts.plot(as.name(i),main=i,ylab=\"Deaths by lung diseases\")\n  axis(side=1,at=xat)}\n\n\n\n#각 년도별 계절성을 비교하기 위해서 이런식으로 그래프를 연도별로 쪼개서 그렸다. 연도별로 그러한 경향성이 비슷하게 드러나고 있는 것으로 보인다.\n\nlibrary(\"ghibli\")\npal=ghibli_palette(\"PonyoMedium\",n=6)\nas.character(pal)\n\n[1] \"#4C413FFF\" \"#5A6F80FF\" \"#278B9AFF\" \"#E75B64FF\" \"#DE7862FF\" \"#D8AF39FF\"\n\npar(mfrow=c(1,1))\n\n\nts.plot(lung_1974,main=\"Deaths by lung diseases\",xlab=\"Month\",ylab=\"# of Deaths\",col=pal[1],lwd=2,ylim=c(1000,4000))\naxis(side=1,at=xat)\nlines(lung_1975,lwd=2,col=pal[2])\nlines(lung_1976,lwd=2,col=pal[3])\nlines(lung_1977,lwd=2,col=pal[4])\nlines(lung_1978,lwd=2,col=pal[5])\nlines(lung_1979,lwd=2,col=pal[6])\n\nlegend(x = 10, y = 4000, c(1974:1979), \n       lty=c(rep(1,6)),lwd=2,col = c(as.character(pal)),cex=0.6)\n\n\n\n# 전체데이터와 월별데이터에 평활을 진행하고자 한다. 평활법은 교수님께서 추천하셨던 3RSSH Twice, 4253H Twice에 더해 Hanning이 이루어지기 전 평활법인 3RS3R Twice를 추가하고자 한다.\n\n# 3RSSH Twice\nsmooth_3RSSH=function(data){\n  smooth3RSS=smooth(data, kind=\"3RSS\")\n  \n  n=length(data)\n  smooth3RSSH=smooth3RSS\n  \n  \n  for (i in 2:(n-1)) {smooth3RSSH[i] <- smooth3RSS[i-1]/4 + smooth3RSS[i]/2 + smooth3RSS[i+1]/4}\n  smooth3RSSH[1] <- smooth3RSS[1]; smooth3RSSH[n] <- smooth3RSS[n]\n  rough=data-smooth3RSSH\n  roughH=rough\n  \n  smooth3RSS2=smooth(rough,kind=\"3RSS\")\n  \n  for (i in 2:(n-1)) roughH[i] <- smooth3RSS2[i-1]/4 + smooth3RSS2[i]/2 + smooth3RSS2[i+1]/4\n  roughH[1] <- smooth3RSS2[1]; roughH[n] <- smooth3RSS2[n]\n  out=smooth3RSSH+roughH\n  out=as.vector(out)\n  return(out)\n}\n\nlibrary(sleekts)\npal2=as.vector(ghibli_palette(\"MononokeMedium\")[c(1,3,5,6)])\nts.plot(lung_ts,main=\"Raw Data:All\",ylab=\"# of deaths\",lty=2,col=pal2[1])\nlines(ts(smooth(lung_ts, kind=\"3RS3R\",twiceit=T),frequency = 12,start=c(1974,1),end=c(1979,12)),col=pal2[2],lwd=2)\nlines(ts(smooth_3RSSH(lung_ts),frequency = 12,start=c(1974,1),end=c(1979,12)),col=pal2[3],lwd=2)\nlines(ts(sleek(lung_ts),frequency = 12,start=c(1974,1),end=c(1979,12)),col=pal2[4],lwd=2)\n\nlegend(x =1974, y = 3900, c(\"Default\", \"3RS3R Twice\", \"3RSSH Twice\",\"4253H Twice\"), \n       lty=c(2,1,1,1),lwd=2,col = pal2,cex=0.7)\n\n\n\n#평활법을 적용하여 확인할 경우 원 자료에 비해 최댓값과 최솟값의 폭이 많이 줄어들었음을 확인할 수 있다. 작은 값에서는 크게 변화가 없지만 값이 큰 자료들의 경우 많이 깎여나갔다.\n#시계열을 확인하는데 있어서 그 계절성을 확인하기 좋은 형태로 평활이 된 것은 사실이지만, 위에서 언급한 1976, 1979년도의 특이값이 사라지게 되었고 그 특이값을 해석하는데 있어서 주의를 기울여야 할 것으로 보인다. 3RS3R Twice 기법의 경우 Hanning이 진행되지 않았기 때문에 다소 각진 부분이 남아있지만, 전반적으로 계절성이 나타나는 형태로 데이터를 변화시켰다. 나머지 Hanning을 사용한 2가지 평활법의 차이를 분석하면 4253H방법에서 큰 값들의 감소폭이 크게 나타나고 있다. 3가지 평활법의 양 끝자료의 경우 실제 존재하는 데이터를 가지고 만든 것이 아니기 때문에 그 추세를 해석하는데 있어서 용이하지만 실제 데이터와 차이가 있으므로 해석에 유의해야 할 것이다.\n# 앞에서 시계열 Decompose를 통해서 그렸던 계절성 그래프의 모양과 4253H Twice의 그래프가 상당히 유사한 것으로 보인다. 1년을 주기로 폐질환 사망자수가 Fluctuate 하고 있는데 겨울철에 전반적으로 증가하고 여름철에 감소하는 경향성을 가지는 것이 확인된다. 각 주기는 거의 대칭적으로 증감을 반복하고 있으며 1976, 1977년도를 제외하면 사망건수는 거의 비슷하게 유지 되는 것을 확인할 수 있다. 따라서 시계열 자료를 해석할 때 1976년도와 1977년도 자료는 유의해서 해석해야 할 것으로 보인다.\n\n# Raw Data\nts.plot(lung_1974,main=\"Deaths by lung diseases\",xlab=\"Month\",ylab=\"# of Deaths\",col=pal[1],lwd=2,ylim=c(1000,4000))\naxis(side=1,at=xat)\nlines(lung_1975,lwd=2,col=pal[2])\nlines(lung_1976,lwd=2,col=pal[3])\nlines(lung_1977,lwd=2,col=pal[4])\nlines(lung_1978,lwd=2,col=pal[5])\nlines(lung_1979,lwd=2,col=pal[6])\nlegend(x = 10, y = 4000, c(1974:1979), \n       lty=c(rep(1,6)),lwd=2,col = c(as.character(pal)),cex=0.6)\n\n\n\n### 3RS3R Twice\nts.plot(ts(smooth(lung_1974, kind=\"3RS3R\",twiceit=T),start=1, end=12),main=\"3RS3R TwicC: Deaths by lung diseases\",xlab=\"Month\",ylab=\"# of Deaths\",col=pal[1],lwd=2,ylim=c(1000,4000))\naxis(side=1,at=xat)\nlines(ts(smooth(lung_1975, kind=\"3RS3R\",twiceit=T),start=1, end=12),lwd=2,col=pal[2])\nlines(ts(smooth(lung_1976, kind=\"3RS3R\",twiceit=T),start=1, end=12),lwd=2,col=pal[3])\nlines(ts(smooth(lung_1977, kind=\"3RS3R\",twiceit=T),start=1, end=12),lwd=2,col=pal[4])\nlines(ts(smooth(lung_1978, kind=\"3RS3R\",twiceit=T),start=1, end=12),lwd=2,col=pal[5])\nlines(ts(smooth(lung_1979, kind=\"3RS3R\",twiceit=T),start=1, end=12),lwd=2,col=pal[6])\nlegend(x = 10, y = 4000, c(1974:1979), \n       lty=c(rep(1,6)),lwd=2,col = c(as.character(pal)),cex=0.6)\n\n\n\n### 3RSSH Twice\nts.plot(ts(smooth_3RSSH(lung_1974),start=1, end=12),main=\"3RSSH TwicC: Deaths by lung diseases\",xlab=\"Month\",ylab=\"# of Deaths\",col=pal[1],lwd=2,ylim=c(1000,4000))\naxis(side=1,at=xat)\nlines(ts(smooth_3RSSH(lung_1975),start=1, end=12),lwd=2,col=pal[2])\nlines(ts(smooth_3RSSH(lung_1976),start=1, end=12),lwd=2,col=pal[3])\nlines(ts(smooth_3RSSH(lung_1977),start=1, end=12),lwd=2,col=pal[4])\nlines(ts(smooth_3RSSH(lung_1978),start=1, end=12),lwd=2,col=pal[5])\nlines(ts(smooth_3RSSH(lung_1979),start=1, end=12),lwd=2,col=pal[6])\nlegend(x = 10, y = 4000, c(1974:1979), \n       lty=c(rep(1,6)),lwd=2,col = c(as.character(pal)),cex=0.6)\n\n\n\n### 4253H Twice\n\nts.plot(ts(sleek(lung_1974),start=1, end=12),main=\"4253H TwicC: Deaths by lung diseases\",xlab=\"Month\",ylab=\"# of Deaths\",col=pal[1],lwd=2,ylim=c(1000,4000))\naxis(side=1,at=xat)\nlines(ts(sleek(lung_1975),start=1, end=12),lwd=2,col=pal[2])\nlines(ts(sleek(lung_1976),start=1, end=12),lwd=2,col=pal[3])\nlines(ts(sleek(lung_1977),start=1, end=12),lwd=2,col=pal[4])\nlines(ts(sleek(lung_1978),start=1, end=12),lwd=2,col=pal[5])\nlines(ts(sleek(lung_1979),start=1, end=12),lwd=2,col=pal[6])\nlegend(x = 10, y = 4000, c(1974:1979), \n       lty=c(rep(1,6)),lwd=2,col = c(as.character(pal)),cex=0.6)\n\n\n\n# 원자료 --> 3RS3R Twice --> 3RSSH Twice--> 4253H Twice순으로 시계열의 추세가 유사해지고 있는것을 확인할 수 있다.\n# Hanning을 사용하여 3RSSH Twice, 4253H Twice는 평평한 구간 없이 부드럽게 넘어가고 있으며 1976,1979년도 평활법을 통해서 최대값이 줄어들어 다른 년도와 유사한 계절성을 확인할 수 있게 되었다.\n# 다만 4253H Twice 방법보다는 3RSSH Twice 방법이 더 적절한 것으로 보인다. 왜냐하면 11월~12월의 값이 서로 같게 나타나고 있기 때문이다. \n\nlibrary(forecast)\naTSA::adf.test(lung_ts, nlag = NULL, output = TRUE) # p-value<=0.01 귀무가설을 기각하여 정상시계열\n\nAugmented Dickey-Fuller Test \nalternative: stationary \n \nType 1: no drift no trend \n     lag    ADF p.value\n[1,]   0 -0.922   0.347\n[2,]   1 -0.938   0.341\n[3,]   2 -1.067   0.295\n[4,]   3 -0.926   0.345\nType 2: with drift no trend \n     lag   ADF p.value\n[1,]   0 -3.12  0.0328\n[2,]   1 -4.71  0.0100\n[3,]   2 -5.93  0.0100\n[4,]   3 -6.96  0.0100\nType 3: with drift and trend \n     lag   ADF p.value\n[1,]   0 -3.02   0.159\n[2,]   1 -4.67   0.010\n[3,]   2 -5.85   0.010\n[4,]   3 -6.89   0.010\n---- \nNote: in fact, p.value = 0.01 means p.value <= 0.01 \n\nfit <- auto.arima(lung_ts)\nplot(forecast(fit, level=c(75, 95), h=12),col='black') \n\n\n\n# 다음 1년간의 변화를 예측할 경우 이전의 자료들과 비슷한 추세를 가지고 있는 것이 확인되어 진다.\n\n\n\n6.\n헬멧의 충돌 실험에서 충돌 이후 머리의 가속(g)과 시간의 경과(milliseconds)에 대한 자료이다. 자료를 평활하고 특징을 설명하여라. [HELMETS.DAT]\n\nhelmet=(read.delim(\"C:/r/HELMETS.DAT\",header=F,))\nh1=helmet[c(1,2)]\nnames(h1)=c(\"imptime\",\"accel\")\nh2=helmet[c(3,4)]\nnames(h2)=c(\"imptime\",\"accel\")\nh3=helmet[c(5,6)]\nnames(h3)=c(\"imptime\",\"accel\")\n\nhelmet=rbind(h1,h2,h3)\ndim(helmet)\n\n[1] 135   2\n\nplot(helmet$accel~helmet$imptime,main=\"scatter plot of impact time and head\") # 두 좌표간의 관계를 보면 곡선의 관계를 띄고 있는 것을 확인할 수 있다.\n\n\n\n# 결측치와 outlier의 존재여부를 체크하고자 한다.\nboxplot(helmet, main=\"Helmet\")  # Outlier는 없다. 충돌 후 시간의 경우 median이 lower hinge쪽으로 기울어 있고, 머리의 가속의 경우 median이 upper hinge쪽으로 기울어 있다. \n\n\n\ncolSums(is.na(helmet)) # 결측치 각각 두개씩\n\nimptime   accel \n      2       2 \n\nhelmet=helmet[ifelse(!is.na(helmet)[,1]==F|!is.na(helmet)[,2]==F,F,T),]\nhead(helmet,5) # 결측치 제거 후 분석 시작\n\n  imptime accel\n1     2.4   0.0\n2     2.6  -1.3\n3     3.2  -2.7\n4     3.6   0.0\n5     4.0  -2.7\n\ndim(helmet)\n\n[1] 133   2\n\nattach(helmet)\nsummary(imptime) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.40   15.60   23.40   25.18   34.80   57.60 \n\nsummary(accel) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-134.00  -54.90  -13.30  -25.55    0.00   75.00 \n\n# Steam and leaf plot을 활용해서 자료의 분포를 예측해보고자 했다.\nstem(imptime,1) # stem 1을 기준으로 skewed 된 종모양\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  0 | 23344\n  0 | 6778899\n  1 | 000111344\n  1 | 5555555555566666666666777788888899999\n  2 | 000112233444\n  2 | 55555666667777888899\n  3 | 011223344\n  3 | 555566668899\n  4 | 0022233344\n  4 | 57889\n  5 | 123\n  5 | 5558\n\nstem(accel,0.5) # stem -0을 기준으로 skewed 종모양\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  -12 | 49733333\n  -10 | 83387422\n   -8 | 9516620\n   -6 | 8221642\n   -4 | 9855441116430\n   -2 | 882777433222222\n   -0 | 76665533311955555533333333333333311111\n    0 | 000000014580111111256\n    2 | 3912568\n    4 | 677785\n    6 | 055\n\n#skewness\nskewness(imptime) #Skewed to the right되어 있음.\n\n[1] 0.1875\n\nskewness(accel) #Skewed to the left되어 있음\n\n[1] -0.5154827\n\n# letter value display\nsource(\"http://mgimond.github.io/ES218/es218.R\")\n(lvd13=lsum(imptime,9)) # mid 값이 점차 커지는 중\n\n  letter depth lower  mid upper spread\n1      M  67.0  23.4 23.4  23.4    0.0\n2      H  34.0  15.6 25.2  34.8   19.2\n3      E  17.5  11.2 26.9  42.6   31.4\n4      D   9.0   7.8 27.8  47.8   40.0\n5      C   5.0   4.0 28.6  53.2   49.2\n6      B   3.0   3.2 29.1  55.0   51.8\n7      A   2.0   2.6 29.0  55.4   52.8\n8      Z   1.5   2.5 29.5  56.5   54.0\n9      Y   1.0   2.4 30.0  57.6   55.2\n\n(lvd14=lsum(accel,9))\n\n  letter depth   lower     mid  upper spread\n1      M  67.0  -13.30 -13.300 -13.30   0.00\n2      H  34.0  -54.90 -27.450   0.00  54.90\n3      E  17.5  -97.10 -40.875  15.35 112.45\n4      D   9.0 -117.90 -36.150  45.60 163.50\n5      C   5.0 -123.10 -37.450  48.20 171.30\n6      B   3.0 -127.20 -28.800  69.60 196.80\n7      A   2.0 -128.50 -26.750  75.00 203.50\n8      Z   1.5 -131.25 -28.125  75.00 206.25\n9      Y   1.0 -134.00 -29.500  75.00 209.00\n\n# Kurtosis (E-spread) / (H-spread) - 1.705\n(lvd13[3,5]-lvd13[3,3])/(lvd13[2,5]-lvd13[2,3])-1.705 # less peaked than normal\n\n[1] -0.06958333\n\n(lvd14[3,5]-lvd14[3,3])/(lvd14[2,5]-lvd14[2,3])-1.705 # more peaked than normal\n\n[1] 0.3432696\n\n# H-Spread\n(lvd13[2,5]-lvd13[2,3]) \n\n[1] 19.2\n\n(lvd14[2,5]-lvd14[2,3]) \n\n[1] 54.9\n\n# 자료들이 정규성 따르냐?\nqqnorm(imptime, ylab=\"Impact Time Quantiles\");qqline(imptime, col='red',lty=2) # 자료들이 정규분포를 잘 따르고 있는 것으로 보인다. (꼬리부분에서 다소 벗어나 보이나)\n\n\n\nqqnorm(accel, ylab=\"Head Acceleration Quantiles\");qqline(accel, col='red',lty=2) # 자료들이 qqline을 잘 따르기 보다는 역s자 곡선의 형태를 띄고 있는 것으로 보인다.\n\n\n\n# 시계열 분석이 아니라 산점도 평활법을 적용해 분석을 진행해보고자 한다. \nplot(helmet$accel~helmet$imptime,main=\"scatter plot of impact time and head acceleration\")\nlines(lowess(accel~imptime,f=2/3), col = \"Red\")\nlines(lowess(accel~imptime,f=1/2), col = \"blue\")\nlines(lowess(accel~imptime,f=1/3), col = \"darkgreen\")\nlegend(3, 75, c(paste(\"f = \", c(\"2/3\", \"1/2\",\"1/3\"))), lty = 1, col = c(\"red\",\"blue\",\"darkgreen\"), cex=0.7)\n\n\n\n# f=1/3일때 가장 이상적으로 보인다.\n\n# residuals with the default span f = 2/3\nresiduals <- helmet$accel - lowess(helmet)$y\nplot(residuals ~ helmet$imptime, main = \"Residuals with f = 2/3\")\nlines(lowess(helmet$imptime, residuals, f=0.3))\n\n\n\n#여전히 잔차들이 경향성을 가지는 것으로 보인다.\n\n\n# residuals with span f = 1/2\nresiduals <- helmet$accel - lowess(helmet,f=0.5)$y\nplot(residuals ~ helmet$imptime, main = \"Residuals with f = 1/2\")\nlines(lowess(helmet$imptime, residuals, f=0.3))\n\n\n\n#여전히 잔차들이 경향성을 가지는 것으로 보인다.\n\n# residuals with span f = 1/3\nresiduals <- helmet$accel - lowess(helmet,f=1/3)$y\nplot(residuals ~ helmet$imptime, main = \"Residuals with f = 1/3\")\nlines(lowess(helmet$imptime, residuals, f=1))\n\n\n\n# 잔차들의 경향성이 완화되었다.\n\nplot(helmet, main = \"loess(cars)\")\n\nhelmet.lo <- loess(accel ~ imptime, helmet)\nhelmet.lo.pred <- predict(helmet.lo, data.frame(imptime=seq(0, 60, length=133)), se=TRUE)\nlines(helmet.lo.pred$fit ~ seq(0, 60, length=133), col = 2)\n\n\n\n\n\n\n7.\n어린 아이들의 나이별 평균 사용 단어 수이다. 분석하여라.\n\nage=c(1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0,6.0)\nwords=c(3,22,272,446,896,1222,1540,1870,2072,2562)\n\nlength(words) #총 10개의 자료\n\n[1] 10\n\nsummary(age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   2.125   3.250   3.300   4.375   6.000 \n\nsummary(words)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    3.0   315.5  1059.0  1090.5  1787.5  2562.0 \n\nboxplot(age,main=\"age\")\n\n\n\nboxplot(words,main=\"words\") #outlier는 없다.\n\n\n\nmedage <- as.vector(3)\nmedwords <- as.vector(3)\nmedage[1] <- median(age[1:3],na.rm=T); medwords[1] <- median(words[1:3],na.rm=T)\nmedage[2] <- median(age[4:7],na.rm=T); medwords[2] <- median(words[4:7],na.rm=T)\nmedage[3] <- median(age[8:10],na.rm=T); medwords[3] <- median(words[8:10],na.rm=T)\nplot(medwords ~ medage, type=\"b\") \n\n\n\n# 선형 관계로 나타나는 것을 확인할 수 있다. \n\ncor.test(words,age)\n\n\n    Pearson's product-moment correlation\n\ndata:  words and age\nt = 23.134, df = 8, p-value = 1.294e-08\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9678822 0.9983153\nsample estimates:\n      cor \n0.9926087 \n\nlmfit=lm(words~age)\nlmfit2=lm(words~age+0)\nsummary(lmfit) #단순회귀에서는 상관계수/회귀값 모두 두 변수가 상관정도가 높게 나타나고 있다.\n\n\nCall:\nlm(formula = words ~ age)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-194.959  -54.200   -3.404   48.670  204.931 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -763.86      88.25  -8.656 2.47e-05 ***\nage           561.93      24.29  23.134 1.29e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 116.7 on 8 degrees of freedom\nMultiple R-squared:  0.9853,    Adjusted R-squared:  0.9834 \nF-statistic: 535.2 on 1 and 8 DF,  p-value: 1.294e-08\n\n# 나이가 한살 많아질수록 알고 있는 단어의 수는 561.93개로 나타남. \n\nsummary(lmfit2) #모르는 단어가 음수일 수는 없기 때문에 절편을 원점으로 고정하고 회귀분석을 진행할 경우 나이 한살이 많아질 수록 370.96개의 단어를 추가적으로 알 것이다라고 추론 할 수 있다. \n\n\nCall:\nlm(formula = words ~ age + 0)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-534.4 -444.4 -146.6  164.5  336.2 \n\nCoefficients:\n    Estimate Std. Error t value Pr(>|t|)    \nage   370.96      30.84   12.03 7.55e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 354.4 on 9 degrees of freedom\nMultiple R-squared:  0.9414,    Adjusted R-squared:  0.9349 \nF-statistic: 144.7 on 1 and 9 DF,  p-value: 7.551e-07\n\nplot(words~age,main=\"linearity of words ~ age\")\n(z5<-line(x=age,y=words))\n\n\nCall:\nline(x = age, y = words)\n\nCoefficients:\n[1]  -917   608\n\nabline(coef(z5))\nz5.ls <- lm(words~age)\nabline(z5.ls$coef, lty=2,col=\"red\")\nlegend(x = 1, y = 2300, c(\"R - Line\", \"Regression\"), \n       lty=c(1,2),lwd=2,col = c(\"black\",\"red\"),cex=0.7)       \n\n\n\nplot(residuals(z5) ~ fitted(z5), main = \"Residual plot by rline\") \nabline(0,0) \n\n\n\n# 1살에서의 단어의 수를 제외하면 대부분의 데이터들이 0 근처에 있는 것이 확인되어 진다.\n\nboxplot(residuals(z5))\nboxplot(residuals(z5))$out #lower fence 밖의 oulier -169, upper fence 밖의 outlier 312\n\n\n\n\n[1]  312 -169\n\nstem(residuals(z5)) # Outlier 재확인 가능\n\n\n  The decimal point is 2 digit(s) to the right of the |\n\n  -1 | 76\n  -0 | 531\n   0 | 1335\n   1 | \n   2 | \n   3 | 1\n\nsum(residuals(z5)^2)\n\n[1] 158081\n\n\n\n\n8.\n다음 자료는 권투선수 Mike Tyson과 Frank Bruno의 1989년 World Heavyweight Championship match의 자료이다. 타이슨이 이겼다. connected는 펀치를 정확히 맞힌 것이다. 누가 펀치를 많이 날렸는지? 누가 정확히 맞혔는지? 누가 잽(작은 펀치)을 많이 했는지? 누가 파워펀치를 많이 했는지? 등등을 분석하여 보아라.\n\ntyson=as.data.frame(matrix(c(43,39,28,37,55,13,14,13,15,34,6,9,5,13,8,0,1,1,3,3,37,30,23,24,47,13,13,12,12,31,1,0,0,0,0),nrow=7,byrow=T))\nnames(tyson)=1:5\nrownames(tyson)=c(\"Total punches\",\"Punches connected\",\"Jabs thrown\",\"Jabs conneted\",\"Power punches\",\"Power connected\",\"Knockdowns\")\ntyson\n\n                   1  2  3  4  5\nTotal punches     43 39 28 37 55\nPunches connected 13 14 13 15 34\nJabs thrown        6  9  5 13  8\nJabs conneted      0  1  1  3  3\nPower punches     37 30 23 24 47\nPower connected   13 13 12 12 31\nKnockdowns         1  0  0  0  0\n\nbruno=as.data.frame(matrix(c(55,42,35,18,20,14,8,5,3,7,14,24,16,8,6,2,1,0,0,1,41,18,19,10,14,12,7,5,3,6,0,0,0,0,0),nrow=7,byrow=T))           \nnames(bruno)=1:5              \nrownames(bruno)=c(\"Total punches\",\"Punches connected\",\"Jabs thrown\",\"Jabs conneted\",\"Power punches\",\"Power connected\",\"Knockdowns\")                   \nbruno   \n\n                   1  2  3  4  5\nTotal punches     55 42 35 18 20\nPunches connected 14  8  5  3  7\nJabs thrown       14 24 16  8  6\nJabs conneted      2  1  0  0  1\nPower punches     41 18 19 10 14\nPower connected   12  7  5  3  6\nKnockdowns         0  0  0  0  0\n\n\n\nlibrary(ghibli)\npal=ghibli_palette(\"PonyoMedium\",5)\nmosaicplot(tyson,col=pal,main=\"mosaic plot of tyson\")\n\n\n\nmosaicplot(bruno,col=pal,main=\"mosaic plot of bruno\")\n\n\n\n\n\nPunch\n\n\n# connected는 펀치를 정확히 맞힌 것이다. \n# 누가 펀치를 많이 했는지         \ntotalpunch=rbind(tyson[1,],bruno[1,])\nrownames(totalpunch)=c(\"tyson\",\"bruno\")\ntotalpunch\n\n       1  2  3  4  5\ntyson 43 39 28 37 55\nbruno 55 42 35 18 20\n\nchisq.test(totalpunch)\n\n\n    Pearson's Chi-squared test\n\ndata:  totalpunch\nX-squared = 22.67, df = 4, p-value = 0.0001473\n\n# Null hypothesis (H0): the row and the column variables of the contingency table are independent.\n# Alternative hypothesis (H1): row and column variables are dependent\n# 따라서, tyson의 round별 파워펀치 수와 bruno의 round별 파워펀치 수는 차이가 있다.\n\ntotalpunch_polished=medpolish(totalpunch)\n\n1: 80\n2: 73\nFinal: 73\n\ntotalpunch_polished\n\n\nMedian Polish Results (Dataset: \"totalpunch\")\n\nOverall: 37.5\n\nRow Effects:\ntyson bruno \n -1.5   1.5 \n\nColumn Effects:\n    1     2     3     4     5 \n 11.5   3.0  -6.0 -10.0   0.0 \n\nResiduals:\n         1 2  3   4   5\ntyson -4.5 0 -2  11  19\nbruno  4.5 0  2 -11 -19\n\nbarplot(totalpunch_polished$col) # 1라운드에서 펀치가 가장 많고 4라운드에서 펀치가 적다\n\n\n\nbarplot(totalpunch_polished$row) # Bruno가 Tyson에 비해 펀치를 많이 한 것으로 보인다.\n\n\n\nbarplot(totalpunch_polished$residuals)\n\n\n\nlibrary(reshape2)\ntotalpunch2=cbind(c(\"tyson\",\"bruno\"),totalpunch)\ntotalpunch2=melt(totalpunch2)\n\nUsing c(\"tyson\", \"bruno\") as id variables\n\nnames(totalpunch2)=c(\"player\",\"round\",\"value\")\ntotalpunch2\n\n   player round value\n1   tyson     1    43\n2   bruno     1    55\n3   tyson     2    39\n4   bruno     2    42\n5   tyson     3    28\n6   bruno     3    35\n7   tyson     4    37\n8   bruno     4    18\n9   tyson     5    55\n10  bruno     5    20\n\nlibrary(doBy)\nsummaryBy(value ~player, data=totalpunch2, FUN = c(mean,sum,min,max)) #평균적으로 bruno가 펀치의 횟수가 많았다.\n\n  player value.mean value.sum value.min value.max\n1  bruno       34.0       170        18        55\n2  tyson       40.4       202        28        55\n\nsummaryBy(value ~round, data=totalpunch2, FUN = c(mean,sum,min,max)) #라운드별로 보았을 때에는 1라운드에서 펀치횟수가 가장 많고 4라운드에서 펀치횟수가 가장 적다. \n\n  round value.mean value.sum value.min value.max\n1     1       49.0        98        43        55\n2     2       40.5        81        39        42\n3     3       31.5        63        28        35\n4     4       27.5        55        18        37\n5     5       37.5        75        20        55\n\nlibrary(ggplot2)\nggplot(totalpunch2,aes(x=as.factor(round),y=value))+\n  geom_bar(stat=\"identity\",position=\"dodge\",fill=rep(pal,2))+\n  facet_wrap(~ player, nrow=1)+\n  geom_text(aes(label=value), vjust=-0.4, size=3.5)+\n  theme_classic()+\n  ggtitle(\"Bruno & Tyson Total Punch Comparison\")+\n  xlab(\"round\")+\n  ylab(\"value\")\n\n\n\nggplot(totalpunch2, aes(round, value, fill=player))+\n  geom_bar(stat='identity', position = 'dodge')+\n  geom_text(aes(label= value),vjust=-0.4, size=3,position = position_dodge(width = 1))+\n  theme_classic()+\n  ggtitle(\"Bruno & Tyson Total Punch Comparison\")+\n  xlab(\"round\")+\n  ylab(\"value\")\n\n\n\naov10=aov(value~player+round,data=totalpunch2)\nsummary(aov10)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nplayer       1  102.4   102.4   0.517  0.512\nround        4  553.6   138.4   0.699  0.631\nResiduals    4  791.6   197.9               \n\nlibrary(agricolae)\nHSD.test(aov10, \"round\", group=T,console=TRUE)\n\n\nStudy: aov10 ~ \"round\"\n\nHSD Test for value \n\nMean Square Error:  197.9 \n\nround,  means\n\n  value       std r Min Max\n1  49.0  8.485281 2  43  55\n2  40.5  2.121320 2  39  42\n3  31.5  4.949747 2  28  35\n4  27.5 13.435029 2  18  37\n5  37.5 24.748737 2  20  55\n\nAlpha: 0.05 ; DF Error: 4 \nCritical Value of Studentized Range: 6.287027 \n\nMinimun Significant Difference: 62.53933 \n\nTreatments with the same letter are not significantly different.\n\n  value groups\n1  49.0      a\n2  40.5      a\n5  37.5      a\n3  31.5      a\n4  27.5      a\n\nHSD.test(aov10, \"player\", group=T,console=TRUE)\n\n\nStudy: aov10 ~ \"player\"\n\nHSD Test for value \n\nMean Square Error:  197.9 \n\nplayer,  means\n\n      value       std r Min Max\nbruno  34.0 15.475788 5  18  55\ntyson  40.4  9.838699 5  28  55\n\nAlpha: 0.05 ; DF Error: 4 \nCritical Value of Studentized Range: 3.926503 \n\nMinimun Significant Difference: 24.70267 \n\nTreatments with the same letter are not significantly different.\n\n      value groups\ntyson  40.4      a\nbruno  34.0      a\n\nlibrary(twoway)\ntwoway(totalpunch)\n\n\nMean decomposition (Dataset: \"totalpunch\"; Response: Value)\nResiduals bordered by row effects, column effects, and overall\n\n         1     2     3     4     5       roweff\n       + ----- ----- ----- ----- ----- + ----- \ntyson  |  -9.2  -4.7  -6.7   6.3  14.3 :   3.2 \nbruno  |   9.2   4.7   6.7  -6.3 -14.3 :  -3.2 \n       + ..... ..... ..... ..... ..... + ..... \ncoleff |  11.8   3.3  -5.7  -9.7   0.3 :  37.2 \n\nplot(twoway(totalpunch))\n\n\n\n# 누가 정확히 맞혔는지? \npunch_accu=cbind((tyson[2,]/tyson[1,]),sum(tyson[2,])/sum(tyson[1,]))\nnames(punch_accu)=c(1:5,\"total\")\nrownames(punch_accu)=\"tyson_connect\"\npunch_accu=round(punch_accu*100,2)\n\npunch_accu1=cbind((bruno[2,]/bruno[1,]),sum(bruno[2,])/sum(bruno[1,]))\nnames(punch_accu1)=c(1:5,\"total\")\nrownames(punch_accu1)=\"bruno_connect\"\npunch_accu1=round(punch_accu1*100,2)\npunch_accu1\n\n                  1     2     3     4  5 total\nbruno_connect 25.45 19.05 14.29 16.67 35 21.76\n\nconnect_prob=rbind(punch_accu,punch_accu1)\nconnect_prob\n\n                  1     2     3     4     5 total\ntyson_connect 30.23 35.90 46.43 40.54 61.82 44.06\nbruno_connect 25.45 19.05 14.29 16.67 35.00 21.76\n\n# 전반적으로 정확히 맞춘 비율의 경우 Tyson이 Bruno에 비해서 높은 것으로 보인다.\n# Punch가 Connected될 비율은 모든 라운드에서 tyson이 bruno에 비해 높은 것으로 나타났으며 전체 비율의 경우에도 tyson이 bruno에 비해서 높게 나타난 것을 확인할 수 있다. \n\nconnect_prob=cbind(c(\"tyson_connect\",\"bruno_connect\"),connect_prob)\nconnect_prob2=melt(connect_prob)\n\nUsing c(\"tyson_connect\", \"bruno_connect\") as id variables\n\nnames(connect_prob2)=c(\"player\",\"round\",\"value\")\nggplot(connect_prob2, aes(round, value, fill=player))+\n  geom_bar(stat='identity', position = 'dodge')+\n  geom_text(aes(label= paste(sprintf(\"%2.1f\", value),\"%\",sep=\"\")),vjust=-0.4, size=3,position = position_dodge(width = 1))+\n  theme_classic()+\n  ggtitle(\"Bruno & Tyson Punch Connect Comparison\")+\n  xlab(\"round\")+\n  ylab(\"value(prop(%)\")\n\n\n\n# tyson이 bruno에 비해서 punch를 더 정확하게 하였다.\n\n\nJab\n\n\n# 누가 잽(작은 펀치)을 많이 했는지? \ntotaljab=rbind(tyson[3,],bruno[3,])\nrownames(totaljab)=c(\"tyson\",\"bruno\")\ntotaljab\n\n       1  2  3  4 5\ntyson  6  9  5 13 8\nbruno 14 24 16  8 6\n\nchisq.test(totaljab)\n\n\n    Pearson's Chi-squared test\n\ndata:  totaljab\nX-squared = 11.259, df = 4, p-value = 0.0238\n\n# Null hypothesis (H0): the row and the column variables of the contingency table are independent.\n# Alternative hypothesis (H1): row and column variables are dependent\n# 따라서, tyson의 round별 jab수와 bruno의 round별 jab수는 차이가 있다.\n\ntotaljab_polished=medpolish(totaljab)\n\n1: 35\n2: 33\nFinal: 33\n\ntotaljab_polished\n\n\nMedian Polish Results (Dataset: \"totaljab\")\n\nOverall: 10.5\n\nRow Effects:\ntyson bruno \n   -4     4 \n\nColumn Effects:\n   1    2    3    4    5 \n-0.5  6.0  0.0  0.0 -3.5 \n\nResiduals:\n      1    2    3    4  5\ntyson 0 -3.5 -1.5  6.5  5\nbruno 0  3.5  1.5 -6.5 -5\n\nbarplot(totaljab_polished$col) # 2라운드에서 Jab이 가장 많고 5라운드에서 Jab이 적게 나타난다. (5라운드에서 punch가 많았던 것에 비교하면 약간의 차이를 보인다) \n\n\n\nbarplot(totaljab_polished$row) # Bruno가 Tyson에 비해 Jab을 많이 한 것으로 보인다.\n\n\n\nbarplot(totaljab_polished$residuals)\n\n\n\ntotaljab2=cbind(c(\"tyson\",\"bruno\"),totaljab)\ntotaljab2=melt(totaljab2)\n\nUsing c(\"tyson\", \"bruno\") as id variables\n\nnames(totaljab2)=c(\"player\",\"round\",\"value\")\ntotaljab2\n\n   player round value\n1   tyson     1     6\n2   bruno     1    14\n3   tyson     2     9\n4   bruno     2    24\n5   tyson     3     5\n6   bruno     3    16\n7   tyson     4    13\n8   bruno     4     8\n9   tyson     5     8\n10  bruno     5     6\n\nlibrary(doBy)\nsummaryBy(value ~player, data=totaljab2, FUN = c(mean,sum,min,max)) #평균적으로 Bruno가 잽을 많이 했다.\n\n  player value.mean value.sum value.min value.max\n1  bruno       13.6        68         6        24\n2  tyson        8.2        41         5        13\n\nsummaryBy(value ~round, data=totaljab2, FUN = c(mean,sum,min,max)) #라운드별로 보았을 때에는 2라운드에서 Jab이 가장 많고 5라운드에서 Jab이 가장 적다. \n\n  round value.mean value.sum value.min value.max\n1     1       10.0        20         6        14\n2     2       16.5        33         9        24\n3     3       10.5        21         5        16\n4     4       10.5        21         8        13\n5     5        7.0        14         6         8\n\nggplot(totaljab2,aes(x=as.factor(round),y=value))+\n  geom_bar(stat=\"identity\",position=\"dodge\",fill=rep(pal,2))+\n  facet_wrap(~ player, nrow=1)+\n  geom_text(aes(label=value), vjust=-0.4, size=3.5)+\n  theme_classic()+\n  ggtitle(\"Bruno & Tyson Total Jab Comparison\")+\n  xlab(\"round\")+\n  ylab(\"value\")\n\n\n\nggplot(totaljab2, aes(round, value, fill=player))+\n  geom_bar(stat='identity', position = 'dodge')+\n  geom_text(aes(label= value),vjust=-0.4, size=3,position = position_dodge(width = 1))+\n  theme_classic()+\n  ggtitle(\"Bruno & Tyson Total Jab Comparison\")+\n  xlab(\"round\")+\n  ylab(\"value\")\n\n\n\naov11=aov(value~player+round,data=totaljab2)\nsummary(aov11)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nplayer       1   72.9   72.90   1.989  0.231\nround        4   95.4   23.85   0.651  0.656\nResiduals    4  146.6   36.65               \n\nHSD.test(aov11, \"round\", group=T,console=TRUE)\n\n\nStudy: aov11 ~ \"round\"\n\nHSD Test for value \n\nMean Square Error:  36.65 \n\nround,  means\n\n  value       std r Min Max\n1  10.0  5.656854 2   6  14\n2  16.5 10.606602 2   9  24\n3  10.5  7.778175 2   5  16\n4  10.5  3.535534 2   8  13\n5   7.0  1.414214 2   6   8\n\nAlpha: 0.05 ; DF Error: 4 \nCritical Value of Studentized Range: 6.287027 \n\nMinimun Significant Difference: 26.91332 \n\nTreatments with the same letter are not significantly different.\n\n  value groups\n2  16.5      a\n3  10.5      a\n4  10.5      a\n1  10.0      a\n5   7.0      a\n\nHSD.test(aov11, \"player\", group=T,console=TRUE)\n\n\nStudy: aov11 ~ \"player\"\n\nHSD Test for value \n\nMean Square Error:  36.65 \n\nplayer,  means\n\n      value      std r Min Max\nbruno  13.6 7.127412 5   6  24\ntyson   8.2 3.114482 5   5  13\n\nAlpha: 0.05 ; DF Error: 4 \nCritical Value of Studentized Range: 3.926503 \n\nMinimun Significant Difference: 10.6306 \n\nTreatments with the same letter are not significantly different.\n\n      value groups\nbruno  13.6      a\ntyson   8.2      a\n\nlibrary(twoway)\ntwoway(totaljab)\n\n\nMean decomposition (Dataset: \"totaljab\"; Response: Value)\nResiduals bordered by row effects, column effects, and overall\n\n         1    2    3    4    5      roweff\n       + ---- ---- ---- ---- ---- + ----  \ntyson  | -1.3 -4.8 -2.8  5.2  3.7 : -2.7  \nbruno  |  1.3  4.8  2.8 -5.2 -3.7 :  2.7  \n       + .... .... .... .... .... + ....  \ncoleff | -0.9  5.6 -0.4 -0.4 -3.9 : 10.9  \n\nplot(twoway(totaljab))\n\n\n\n# 누가 정확히 맞혔는지? \njab_accu=cbind((tyson[4,]/tyson[3,]),sum(tyson[4,])/sum(tyson[3,]))\nnames(jab_accu)=c(1:5,\"total\")\nrownames(jab_accu)=\"tyson_connect\"\njab_accu=round(jab_accu*100,2)\n\njab_accu1=cbind((bruno[4,]/bruno[3,]),sum(bruno[4,])/sum(bruno[3,]))\nnames(jab_accu1)=c(1:5,\"total\")\nrownames(jab_accu1)=\"bruno_connect\"\njab_accu1=round(jab_accu1*100,2)\njab_accu1\n\n                  1    2 3 4     5 total\nbruno_connect 14.29 4.17 0 0 16.67  5.88\n\njconnect_prob=rbind(jab_accu,jab_accu1)\njconnect_prob\n\n                  1     2  3     4     5 total\ntyson_connect  0.00 11.11 20 23.08 37.50 19.51\nbruno_connect 14.29  4.17  0  0.00 16.67  5.88\n\n# 전반적으로 정확히 맞춘 비율의 경우 Tyson이 Bruno에 비해서 높은 것으로 보인다.\n# Punch의 Connected될 비율은 1라운드를 제외하면 tyson이 bruno에 비해 높은 것으로 나타났으며 전체 비율의 경우에도 tyson이 bruno에 비해서 높게 나타난 것을 확인할 수 있다. \n\njconnect_prob=cbind(c(\"tyson_connect\",\"bruno_connect\"),jconnect_prob)\njconnect_prob2=melt(jconnect_prob)\n\nUsing c(\"tyson_connect\", \"bruno_connect\") as id variables\n\nnames(jconnect_prob2)=c(\"player\",\"round\",\"value\")\nggplot(jconnect_prob2, aes(round, value, fill=player))+\n  geom_bar(stat='identity', position = 'dodge')+\n  geom_text(aes(label= paste(sprintf(\"%2.1f\", value),\"%\",sep=\"\")),vjust=-0.4, size=3,position = position_dodge(width = 1))+\n  theme_classic()+\n  ggtitle(\"Bruno & Tyson Jab Punch Connect Comparison\")+\n  xlab(\"round\")+\n  ylab(\"value(prop(%)\")\n\n\n\n# tyson이 bruno에 비해서 더 정확한 Jab 펀치를 하였다.\n\n\npower punch\n\n\n# 누가 파워펀치를 많이 했는지         \ntotalpower=rbind(tyson[5,],bruno[5,])\nrownames(totalpower)=c(\"tyson\",\"bruno\")\ntotalpower\n\n       1  2  3  4  5\ntyson 37 30 23 24 47\nbruno 41 18 19 10 14\n\nchisq.test(totalpower)\n\n\n    Pearson's Chi-squared test\n\ndata:  totalpower\nX-squared = 14.708, df = 4, p-value = 0.005348\n\n# Null hypothesis (H0): the row and the column variables of the contingency table are independent.\n# Alternative hypothesis (H1): row and column variables are dependent\n# 따라서, tyson의 round별 파워펀치 수와 bruno의 round별 파워펀치 수는 차이가 있다.\n\ntotalpower_polished=medpolish(totalpower)\n\n1: 47\nFinal: 47\n\ntotalpower_polished\n\n\nMedian Polish Results (Dataset: \"totalpower\")\n\nOverall: 24\n\nRow Effects:\ntyson bruno \n    6    -6 \n\nColumn Effects:\n   1    2    3    4    5 \n15.0  0.0 -3.0 -7.0  6.5 \n\nResiduals:\n       1 2  3  4     5\ntyson -8 0 -4  1  10.5\nbruno  8 0  4 -1 -10.5\n\nbarplot(totalpower_polished$col) # 1라운드에서 파워펀치가 가장 많고 점점 줄다가 5라운드에서 다시 늘어남 \n\n\n\nbarplot(totalpower_polished$row) # Tyson이 Bruno에 비해 파워펀치를 많이 한 것으로 보인다.\n\n\n\nbarplot(totalpower_polished$residuals)\n\n\n\ntotalpower2=cbind(c(\"tyson\",\"bruno\"),totalpower)\ntotalpower2=melt(totalpower2)\n\nUsing c(\"tyson\", \"bruno\") as id variables\n\nnames(totalpower2)=c(\"player\",\"round\",\"value\")\ntotalpower2\n\n   player round value\n1   tyson     1    37\n2   bruno     1    41\n3   tyson     2    30\n4   bruno     2    18\n5   tyson     3    23\n6   bruno     3    19\n7   tyson     4    24\n8   bruno     4    10\n9   tyson     5    47\n10  bruno     5    14\n\nlibrary(doBy)\nsummaryBy(value ~player, data=totalpower2, FUN = c(mean,sum,min,max)) #평균적으로 tyson이 파워펀치가 많았다.\n\n  player value.mean value.sum value.min value.max\n1  bruno       20.4       102        10        41\n2  tyson       32.2       161        23        47\n\nsummaryBy(value ~round, data=totalpower2, FUN = c(mean,sum,min,max)) #라운드별로 보았을 때에는 1라운드에서 파워펀치가 가장 많고 4라운드에서 파워펀치가 가장 적다. \n\n  round value.mean value.sum value.min value.max\n1     1       39.0        78        37        41\n2     2       24.0        48        18        30\n3     3       21.0        42        19        23\n4     4       17.0        34        10        24\n5     5       30.5        61        14        47\n\nggplot(totalpower2,aes(x=as.factor(round),y=value))+\n  geom_bar(stat=\"identity\",position=\"dodge\",fill=rep(pal,2))+\n  facet_wrap(~ player, nrow=1)+\n  geom_text(aes(label=value), vjust=-0.4, size=3.5)+\n  theme_classic()+\n  ggtitle(\"Bruno & Tyson Total Power Punch Comparison\")+\n  xlab(\"round\")+\n  ylab(\"value\")\n\n\n\nggplot(totalpower2, aes(round, value, fill=player))+\n  geom_bar(stat='identity', position = 'dodge')+\n  geom_text(aes(label= value),vjust=-0.4, size=3,position = position_dodge(width = 1))+\n  theme_classic()+\n  ggtitle(\"Bruno & Tyson Total Power Punch Comparison\")+\n  xlab(\"round\")+\n  ylab(\"value\")\n\n\n\naov12=aov(value~player+round,data=totalpower2)\nsummary(aov12)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nplayer       1  348.1   348.1   3.641  0.129\nround        4  597.6   149.4   1.563  0.338\nResiduals    4  382.4    95.6               \n\nHSD.test(aov12, \"round\", group=T,console=TRUE)\n\n\nStudy: aov12 ~ \"round\"\n\nHSD Test for value \n\nMean Square Error:  95.6 \n\nround,  means\n\n  value       std r Min Max\n1  39.0  2.828427 2  37  41\n2  24.0  8.485281 2  18  30\n3  21.0  2.828427 2  19  23\n4  17.0  9.899495 2  10  24\n5  30.5 23.334524 2  14  47\n\nAlpha: 0.05 ; DF Error: 4 \nCritical Value of Studentized Range: 6.287027 \n\nMinimun Significant Difference: 43.46696 \n\nTreatments with the same letter are not significantly different.\n\n  value groups\n1  39.0      a\n5  30.5      a\n2  24.0      a\n3  21.0      a\n4  17.0      a\n\nHSD.test(aov12, \"player\", group=T,console=TRUE)\n\n\nStudy: aov12 ~ \"player\"\n\nHSD Test for value \n\nMean Square Error:  95.6 \n\nplayer,  means\n\n      value       std r Min Max\nbruno  20.4 12.054045 5  10  41\ntyson  32.2  9.984989 5  23  47\n\nAlpha: 0.05 ; DF Error: 4 \nCritical Value of Studentized Range: 3.926503 \n\nMinimun Significant Difference: 17.16919 \n\nTreatments with the same letter are not significantly different.\n\n      value groups\ntyson  32.2      a\nbruno  20.4      a\n\nlibrary(twoway)\ntwoway(totalpower)\n\n\nMean decomposition (Dataset: \"totalpower\"; Response: Value)\nResiduals bordered by row effects, column effects, and overall\n\n         1     2     3     4     5       roweff\n       + ----- ----- ----- ----- ----- + ----- \ntyson  |  -7.9   0.1  -3.9   1.1  10.6 :   5.9 \nbruno  |   7.9  -0.1   3.9  -1.1 -10.6 :  -5.9 \n       + ..... ..... ..... ..... ..... + ..... \ncoleff |  12.7  -2.3  -5.3  -9.3   4.2 :  26.3 \n\nplot(twoway(totalpower))\n\n\n\n# 누가 정확히 맞혔는지? \npower_accu=cbind((tyson[6,]/tyson[5,]),sum(tyson[6,])/sum(tyson[5,]))\nnames(power_accu)=c(1:5,\"total\")\nrownames(power_accu)=\"tyson_connect\"\npower_accu=round(power_accu*100,2)\n\npower_accu1=cbind((bruno[6,]/bruno[5,]),sum(bruno[6,])/sum(bruno[5,]))\nnames(power_accu1)=c(1:5,\"total\")\nrownames(power_accu1)=\"bruno_connect\"\npower_accu1=round(power_accu1*100,2)\npower_accu1\n\n                  1     2     3  4     5 total\nbruno_connect 29.27 38.89 26.32 30 42.86 32.35\n\npconnect_prob=rbind(power_accu,power_accu1)\npconnect_prob\n\n                  1     2     3  4     5 total\ntyson_connect 35.14 43.33 52.17 50 65.96 50.31\nbruno_connect 29.27 38.89 26.32 30 42.86 32.35\n\n# 전반적으로 정확히 맞춘 비율의 경우 Tyson이 Bruno에 비해서 높은 것으로 보인다.\n# Punch의 Connected될 비율은 1라운드를 제외하면 tyson이 bruno에 비해 높은 것으로 나타났으며 전체 비율의 경우에도 tyson이 bruno에 비해서 높게 나타난 것을 확인할 수 있다. \n\npconnect_prob=cbind(c(\"tyson_connect\",\"bruno_connect\"),pconnect_prob)\npconnect_prob2=melt(pconnect_prob)\n\nUsing c(\"tyson_connect\", \"bruno_connect\") as id variables\n\nnames(pconnect_prob2)=c(\"player\",\"round\",\"value\")\nggplot(pconnect_prob2, aes(round, value, fill=player))+\n  geom_bar(stat='identity', position = 'dodge')+\n  geom_text(aes(label= paste(sprintf(\"%2.1f\", value),\"%\",sep=\"\")),vjust=-0.4, size=3,position = position_dodge(width = 1))+\n  theme_classic()+\n  ggtitle(\"Bruno & Tyson Power Punch Connect Comparison\")+\n  xlab(\"round\")+\n  ylab(\"value(prop(%)\")\n\n\n\n# tyson이 bruno에 비해서 power punch를 더 정확하게 하였다."
  },
  {
    "objectID": "data_analytics/VNR-Text Mining.html",
    "href": "data_analytics/VNR-Text Mining.html",
    "title": "Text-mining on SDG VNRs of ROK, Germany, Finland",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\n\na = np.array([1, 2, 3])\nb = np.array([10, 20, 30])\nprint(2 * a + b)\n\n\n[12 24 36]\n\n\nCode\npenguins=pd.DataFrame(r.penguins)\nc= penguins.head(5)\nprint(c.to_markdown(index=False))\n\n\n| species   | island    |   bill_length_mm |   bill_depth_mm |   flipper_length_mm |   body_mass_g | sex    |   year |\n|:----------|:----------|-----------------:|----------------:|--------------------:|--------------:|:-------|-------:|\n| Adelie    | Torgersen |             39.1 |            18.7 |                 181 |          3750 | male   |   2007 |\n| Adelie    | Torgersen |             39.5 |            17.4 |                 186 |          3800 | female |   2007 |\n| Adelie    | Torgersen |             40.3 |            18   |                 195 |          3250 | female |   2007 |\n| Adelie    | Torgersen |            nan   |           nan   |         -2147483648 |   -2147483648 | nan    |   2007 |\n| Adelie    | Torgersen |             36.7 |            19.3 |                 193 |          3450 | female |   2007 |\n\n\n\n\nCode\nx <- 5  # radius of a circle\n\n\nFor a circle with the radius 5, its area is 78.5398163.\n\n\nCode\npy$a\n\n\n[1] 1 2 3\n\n\nCode\npy$b\n\n\n[1] 10 20 30"
  }
]